\documentclass[11pt]{report}

% relevant packages
\usepackage[parfill]{parskip} % begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathrsfs }
\usepackage{amsthm}
\usepackage{epstopdf}
\usepackage{enumerate}
\usepackage{tikz}
\usetikzlibrary{matrix}
\usepackage{listings}
\usepackage{color}
\usepackage[all]{xy}
\usepackage[english]{babel}
\usepackage{setspace}
\usepackage{soul}

\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

% stylistic environment
\definecolor{grau}{rgb}{0.3,0.3,0.3}
\usepackage{color}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    urlcolor=blue,
    linktoc=all
}
\urlstyle{same}
\usepackage[top=1.3in, bottom=1.6in, left=1.3in, right=1.3in]{geometry}
\frenchspacing
\sloppy
\usepackage{booktabs}
\usepackage[ruled,vlined]{algorithm2e}
\onehalfspacing

% relevant environments
\newtheorem{theorem}{Theorem}[section]
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{properties}[theorem]{Properties}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{question}[theorem]{Question}

\theoremstyle{definition}
\newtheorem{Algorithm}[theorem]{Algorithm}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}

\renewcommand{\chapterautorefname}{Chapter}
\renewcommand{\sectionautorefname}{Section}
\renewcommand{\subsectionautorefname}{Section}
\renewcommand{\subsubsectionautorefname}{Section}

% math operators
\DeclareMathOperator{\ord}{ord}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\Cl}{Cl}
\DeclareMathOperator{\Gal}{Gal}

% code environment
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{%frame=tb,
  language=Java,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

% new commands
\newcommand{\eps}{\varepsilon}
\newcommand{\edit}[1]{\textcolor{blue}{#1}}

%---------------------------------------------------------------------------------------------%
%---------------------------------------------------------------------------------------------%

\title{TM Algorithm Background}

\author{}
\date{\today}

\begin{document}
\maketitle
\tableofcontents

%---------------------------------------------------------------------------------------------%
%---------------------------------------------------------------------------------------------%

\chapter{To do list}
\label{cha:do-list}

All to do items for the Thue-Mahler code background, Magma code, and subsequent paper that we will hopefully, eventually publish.

%---------------------------------------------------------------------------------------------%

\section{Theory}
\label{sec:theory}

\begin{enumerate}[\hspace{0.5cm}1.]
\itemsep0em
\item initial precision heuristic ($p$-adic, real, complex)
\item complex case
\item update non-Archimedean ellipsoid and sieve
\item update Archimedean ellipsoid and sieve
\item heuristic for choosing vectors $\mathbf{l}$ in reduction
\item refined reduction process?
\item Samir has updated the PIRL; should update corresponding writeup
\item probably don't need to use Ficnke-Pohst on translated lattices
\end{enumerate}

%---------------------------------------------------------------------------------------------%

\section{Code}
\label{sec:code}

\begin{enumerate}[\hspace{0.5cm}1.]
\item back up data onto dropbox (fix error on github repo)
\item Thue equations - regenerate Thue equations as in GenerateSUnitEquations Alpha.m
\item Thue equations from NoSUnitEqNeeded.csv
\item Python code to rerun missing TM equations arising from Magma inernal errors
\item Samir has updated the PIRL; should update corresponding code
\item reducible forms
\item change bound $\Omega$ to be $[K:\mathbb{Q}]\Omega$
\item ensure ad-bc in matR is not 0
\end{enumerate}

%---------------------------------------------------------------------------------------------%

\section{Paper}
\label{sec:paper}

\begin{enumerate}[\hspace{0.5cm}1.]
\item probably don't need \autoref{subsec:FinckePohstRemarks}
\item chapter/section/subsection labels
\end{enumerate}

%---------------------------------------------------------------------------------------------%
%---------------------------------------------------------------------------------------------%

\chapter{Preliminaries}
\label{cha:preliminaries}

In this chapter, we give some of the primary algorithms needed to solve an arbitrary Thue-Mahler equation. The methods presented here follow somewhat \cite{Ham} and \cite{TW3}, with new results and modifications from \cite{GhKaMaSi}.

%---------------------------------------------------------------------------------------------%

\section{$p$-adic valuations}
\label{sec:pAdicValuations}

In this section we give a concise exposition of $p$-adic valuations. As references for this material we give \cite{BS} (especially Theorem 3 in Chapter 4, Section 2), \cite{Ca} (especially Lemma 2.1 in Chapter 9), \cite{Has2} (especially Chapter 18), \cite{Ko} (especially Chapter 3, Section 2), and \cite{Nark} (especially Theorem 6.1).

We denote the algebraic closure of $\mathbb{Q}_p$ by $\overline{\mathbb{Q}}_p$. The completion of $\overline{\mathbb{Q}}_p$ with respect to the absolute value of $\overline{\mathbb{Q}}_p$ is denoted by $\mathbb{C}_p$.

Let $K$ be an arbitrary number field. A homomorphism $v: K^* \to \mathbb{R}_{\geq 0}$ of the multiplicative group of $K$ into the group of positive real numbers is called a \textit{valuation} if it satisfies the condition
\[v(x+y) \leq v(x) + v(y).\]
This definition may be extended to all of $K$ by setting $v(0) = 0$. If
\[v(x+y) \leq \max(v(x),v(y))\]
holds for all $x,y \in K$, then $v$ is called a \textit{non-Archimedean valuation}. All remaining valuations on $K$ are called \textit{Archimedean}.

Every valuation $v$ induces on $K$ the structure of a metric topological space which may or may not be complete. We say that two valuations are \textit{equivalent} if they define the same topology and we call an equivalence class of absolute values a \textit{place} of $K$. It is an elementary result of topology that every metric space may be embedded in a complete metric space, and this can be done in an essentially unique way. For the field $K$, the resulting complete metric space may be given a field structure. Equivalently, there exists a field $L$ with a valuation $w$ such that $L$ is complete in the topology induced by $w$. The field $K$ is contained in $L$ and the valuations $v$ and $w$ coincide in $K$. Moreover, the completion $L$ of $K$ is unique up to topological isomorphism.

For any non-zero prime ideal $\mathfrak{p}$ of $\mathcal{O}_K$, let $\ord_{\mathfrak{p}}(\mathfrak{a})$ denote the exact power to which $\mathfrak{p}$ divides the ideal $\mathfrak{a}$. For fractional ideals $\mathfrak{a}$ this number may be negative. For $\alpha \in K$, we write $\ord_{\mathfrak{p}}(\alpha)$ for $\ord_{\mathfrak{p}}\left((\alpha)\mathcal{O}_K\right)$. Every prime ideal defines a discrete non-Archimedean valuation on $K$ via
\[v(x):= \left(\frac{1}{N_{K/\mathbb{Q}}(\mathfrak{p})}\right)^{\ord_{\mathfrak{p}}(x)}.\]
Furthermore, every embedding of $K$ into the complex field defines an Archimedean valuation. Conversely, every discrete valuation on $K$ arises in this way by a prime ideal of $\mathcal{O}_K$, while every Archimedean valuation of $K$ is equivalent to $|\sigma(x)|$, where $\sigma$ is an embedding of $K$ into $\mathbb{C}$. Valuations defined by different prime ideals are non-equivalent, and two valuations defined by different embeddings of $K$ into $\mathbb{C}$ are equivalent if and only if those embeddings are complex conjugated. The topology induced in $K$ by a prime ideal $\mathfrak{p}$ of $\mathcal{O}_K$ is called the \textit{$\mathfrak{p}$-adic topology}. The completion of $K$ under this valuation is denoted by $K_{\mathfrak{p}}$ or $K_v$ and called the \textit{$\mathfrak{p}$-adic field}. Let $V$ be the set of all valuations of an algebraic number field $K$. Then for every non-zero element $\alpha \in K$ we have
\[\prod_{v \in V} v(\alpha) = 1.\]

In the ring of integers of $\mathbb{Q}$, the prime ideals are generated by the rational primes $p$, and the resulting topology in the field $\mathbb{Q}$ is called the \textit{$p$-adic topology}. The completion of $\mathbb{Q}$ under this valuation is denoted by $\mathbb{Q}_p$. If $v(x)$ is a non-trivial valuation of $\mathbb{Q}$, then either $v(x)$ is equivalent to the ordinary absolute value $|x|$, or it is equivalent to one of the $p$-adic valuations induced by rational primes. Analogous to $\ord_{\mathfrak{p}}$, for any prime $p$ we define the $p$-adic order of $x \in \mathbb{Q}$ as the largest exponent of $p$ dividing $x$. Then, the $p$-adic valuation $v$ is defined as
\[v(x) = p^{-\ord_p(x)}.\]
If $K_{\mathfrak{p}}$ is a $\mathfrak{p}$-adic field, it is necessarily a finite extension of a certain $\mathbb{Q}_p$.

Consider now $K/\mathbb{Q}$ where $n = [K:\mathbb{Q}]$ and let $g(t)$ denote the minimal polynomial of $K$ over $\mathbb{Q}$. Suppose $p$ is a rational prime and let $g(t) = g_1(t) \cdots g_m(t)$ be the decomposition of $g(t)$ into irreducible polynomials $g_i(t) \in \mathbb{Q}_p[t]$ of degree $n_i = \deg g_i(t)$. The prime ideals in $K$ dividing $p$ are in one-to-one correspondence with $g_1(t), \dots, g_m(t)$. More precisely, we have in $K$ the following decomposition of $(p)\mathcal{O}_K$
\[(p)\mathcal{O}_K = \mathfrak{p}_1^{e(\mathfrak{p}_1|p)} \cdots \mathfrak{p}_m^{e(\mathfrak{p}_m|p)},\]
with $\mathfrak{p}_1, \dots, \mathfrak{p}_m$ distinct prime ideals and ramification indices $e(\mathfrak{p}_1 | p), \dots, e(\mathfrak{p}_m | p) \in \mathbb{N}$. For $i = 1, \dots, m$ the inertial degree of $\mathfrak{p}_i$ is denoted by $f(\mathfrak{p}_i|p)$. Then $n_i = e(\mathfrak{p}_i | p)f(\mathfrak{p}_i | p)$ and $K_{\mathfrak{p}_i} \simeq \mathbb{Q}_p(\theta_i)$, where $g(\theta_i) = 0$.

By $\overline{\mathbb{Q}_p}$ we denote the algebraic closure of $\mathbb{Q}_p$. There are $n$ embeddings of $K$ into $\overline{\mathbb{Q}_p}$, and each one fixes $\mathbb{Q}$ and maps $\theta$ to a root of $g$ in $\overline{\mathbb{Q}_p}$. Let $\theta_i^{(1)}, \dots, \theta_i^{(n_i)}$ denote the roots of $g_i(t)$ in $\overline{\mathbb{Q}_p}$. For $i = 1, \dots, m$ and $j = 1, \dots, n_i$, let $\sigma_{ij}$ be the embedding of $K$ into $\mathbb{Q}_p(\theta_i^{(j)})$ defined by $\theta \mapsto \theta_i^{(j)}$. The $m$ classes of conjugate embeddings are $\{\sigma_{i1}, \dots, \sigma_{in_i}\}$ for $i = 1, \dots, m$. Note that $\sigma_{ij}$ coincides with the embedding $K \hookrightarrow K_{\mathfrak{p}_i} \simeq \mathbb{Q}_p(\theta_i) \simeq \mathbb{Q}_p(\theta_i^{(j)})$.

For any finite extension $L$ of $\mathbb{Q}_p$, the $p$-adic valuation $v$ of $\mathbb{Q}_p$ extends uniquely to $L$ as
\[v(x) = |N_{L/\mathbb{Q}_p}(x)|^{1/[L:\mathbb{Q}_p]}.\]
Here, we define the $p$-adic order of $x \in L$ by
\[\ord_p(x) = \frac{1}{[L:\mathbb{Q}_p]}\ord_p(N_{L/\mathbb{Q}_p}(x)).\]
This definition is independent of the field $L$ containing $x$. So, since each element of $\overline{\mathbb{Q}_p}$ is by definition contained in some finite extension of $\mathbb{Q}_p$, this definition can be used to define the $p$-adic valuation $v$ of any $x \in \overline{\mathbb{Q}_p}$. Every finite extension of $\mathbb{Q}_p$ is complete with respect to $v$, but $\overline{\mathbb{Q}_p}$ is not. The completion of $\overline{\mathbb{Q}_p}$ with respect to $v$ is denoted by $\mathbb{C}_p$.

The $m$ extensions of the $p$-adic valuation on $\mathbb{Q}$ to $K$ are just multiples of the $\mathfrak{p}_i$-adic valuation on $K$:
\[\ord_p(x) = \frac{1}{e_i}\ord_{\mathfrak{p}_i}(x) \quad \text{ for } i = 1, \dots, m.\]
We also view these extensions as arising from various embeddings of $K$ into $\overline{\mathbb{Q}_p}$. Indeed, the extension to $\mathbb{Q}_p(\theta_i^{(j)})$ of the $p$-adic valuation on $\mathbb{Q}_p$ induces a $p$-adic valuation on $K$ via the embedding $\sigma_{ij}$ as
\[v(x) = |N_{K_{\mathfrak{p}_i}/\mathbb{Q}_p}(\sigma_{ij}(x))|^{1/n_i}.\]
Here, as before, $n_i = \deg g_i(t) = [K_{\mathfrak{p}_i} : \mathbb{Q}_p]$. Furthermore,
\[\ord_p(x) = \ord_p(\sigma_{ij}(x)),\]
and we have
\[\ord_p(\sigma_{ij}(x)) =  \frac{1}{e_i}\ord_{\mathfrak{p}_i}(x) \quad \text{ for } i = 1, \dots, m,\ j = 1, \dots, n_i.\]

Of course, in the special case $x \in \mathbb{Q}_p$, we can write
\[x = \sum_{i=k}^{\infty} u_ip^i\]
where $k = \ord_p(x)$ and the $p$-adic digits $u_i$ are in $\{0, \dots, p-1\}$ with $u_k \neq 0$. If $\ord_p(x) \geq 0$ then $x$ is called a $p$-adic \textit{integer}. The set of $p$-adic integers is denoted $\mathbb{Z}_p$. A $p$-adic \textit{unit} is an $x \in \mathbb{Q}_p$ with $\ord_p(x) = 0$. For any $p$-adic integer $\alpha$ and $\mu \in \mathbb{N}_0$ there exists a unique rational integer $x^{(\mu)} = \sum_{i=0}^{\mu-1}u_ip^i$ such that
\[\ord_p(x-x^{(\mu)}) \geq \mu, \quad \text{ and } \quad 0 \leq x^{(\mu)} \leq p^{\mu} - 1.\]
For $\ord_p(x) \geq k$ we also write $x \equiv 0 \mod{p^k}$.

%---------------------------------------------------------------------------------------------%
%---------------------------------------------------------------------------------------------%

\section{$p$-adic logarithms}
\label{sec:pAdicLogarithms}

We have seen how to extend $p$-adic valuations to algebraic extensions of $\mathbb{Q}$. For any $z \in \mathbb{C}_p$ with $\ord_p(z-1) > 0$, we can also define the $p$-adic logarithm of $z$ by
\[\log_p(z) = -\sum_{i=1}^{\infty} \frac{(1-z)^i}{i}.\]
By the $n^{\text{th}}$ term test, this series converges precisely in the region where ${\ord_p(z-1) > 0}$. Three important properties of the $p$-adic logarithm are
\begin{enumerate}
\item $\log_p(xy) = \log_p(x) + \log_p(y)$ whenever $\ord_p(x-1) > 0$ and $\ord_p(y-1) > 0$.
\item $\log_p(z^k) = k \log(p)$ whenever $\ord_p(z-1) > 0$ and $k \in \mathbb{Z}$.
\item $\ord_p(\log_p(z)) = \ord_p(z-1)$ whenever $\ord_p(z-1) > 1/(p-1)$.
\end{enumerate}
Proofs of the first and last property can be found in \cite{Has2} (pp. 264-265). The second property follows from the first.

We will use the following lemma to extend the definition of the $p$-adic logarithm to all $p$-adic units in $\overline{\mathbb{Q}_p}$.
\begin{lemma} \label{lem: pAdicLogarithms}
Let $z$ be a $p$-adic unit belonging to a finite extensions $L$ of $\mathbb{Q}_p$. Let $e$ and $f$ be the ramification index and inertial degree of $L$.
\begin{enumerate}[(a)]
\item There is a positive integer $r$ such that $\ord_p(z^r-1) >0$.
\item If $r$ is the smallest positive integer having $\ord_p(z^r-1) >0$, then $r$ divides $p^f-1$, and an integer $q$ satisfies $\ord_p(z^q-1) >0$ if and only if it is a multiple of $r$.
\item If $r$ is a nonzero integer with $\ord_p(z^r-1) >0$, and if $k$ is an integer with $p^k(p-1) > e$, then
\[\ord_p(z^{rp^k}-1) >\frac{1}{p-1}.\]
\end{enumerate}
\end{lemma}

For $z$ a $p$-adic unit in $\overline{\mathbb{Q}_p}$ we define
\[\log_p{z} = \frac{1}{q}\log_p{z^q},\]
where $q$ is an arbitrary non-zero integer such that $\ord_p(z^q-1) >0$. To see that this definition is independent of $q$, let $r$ be the smallest positive integer with $\ord_p(z^r-1) >0$, note that $q/r$ is an integer, and use the second property of $p$-adic logarithms above to write
\[\frac{1}{q}\log_p{z^q} = \frac{1}{r(q/r)}\log_p{z^{r(q/r)}} = \frac{1}{r}\log_p{z^r}.\]
Choosing $q$ such that $\ord_p(z^q-1) > 1/(p-1)$ helps to speed up and control the convergence of the series defining $\log_p$ (cf. \cite{Sm} (pp. 28-30) and \cite{Coh2} (pp. 263-265)).

It is straightforward to see that Properties 1 and 2 above extend to the case where $x,y,z$ are $p$-adic units. Combining this with Property 3, we obtain
\begin{lemma}\label{lem:pAdicLogarithms2}
Let $z_1, \dots, z_m \in \overline{\mathbb{Q}_p}$ be $p$-adic units and let $b_1, \dots, b_m \in \mathbb{Z}$. If
\[\ord_p(z_1^{b_1}\cdots z_m^{b_m} - 1) > \frac{1}{p-1}\]
then
\[\ord_p(b_1\log_p{z_1} + \cdots + b_m \log_p{z_m}) = \ord_p(z_1^{b_1}\cdots z_m^{b_m} - 1).\]
\end{lemma}

%---------------------------------------------------------------------------------------------%

\section{The Weil height}
\label{sec:WeilHeight}

Let $K$ be a number field and at each place $v$ of $K$, let $K_v$ denote the completion of $K$ at $v$. Then
\[\sum_{v|p} [K_v:\mathbb{Q}_v] = [K:\mathbb{Q}]\]
for all places $p$ of $\mathbb{Q}$. We will use two absolute values $| \cdot |_v$ and $\| \cdot \|_v$ on $K$ which we now define. If $v|\infty$, then $\| \cdot \|_v$ restricted to $\mathbb{Q}$ is the usual Archimedean absolute value; if $v|p$ for a rational prime $p$, then $\| \cdot \|_v$ restricted to $\mathbb{Q}$ is the usual $p$-adic valuation. We then set
\[ | \cdot |_v = \| \cdot \|_v^{[K_v:\mathbb{Q}_v]/[K:\mathbb{Q}]}.\]
Let $x \in K$ and let $\log^+(\cdot)$ denote the real-valued function $\max\{\log(\cdot),0\}$ on $\mathbb{R}_{\geq 0}$. We define the \textit{logarithmic Weil height} $h(x)$ by
\[h(x) = \frac{1}{[K:\mathbb{Q}]}\sum_v \log^+|x|_v,\]
where the sum is take over all places $v$ of $K$. If $x$ is an algebraic unit, then $|x|_v = 1$ for all non-Archimedean places $v$, and therefore $h(x)$ can be taken over the Archimedean places only.
In particular, if $x \in \mathbb{Q}$, then with $x = p/q$ for $p,q \in \mathbb{Z}$ with $\gcd(p,q) = 1$, we have $h(x) = \log\max\{|p|,|q|\}$, and if $x \in \mathbb{Z}$ then $h(x) = \log|x|$.

%reference: BoGu

%---------------------------------------------------------------------------------------------%

\section{Elliptic curves}
\label{sec:EllipticCurves}

Let $K$ be a field of characteristic $\text{char}(K) \neq 2,3$. An \textit{elliptic curve} $E$ over $K$ is a nonsingular curve of the form
\begin{equation} \label{eq:EllipticCurve}
E: y^2 + a_1xy + a_3y = x^3 + a_2x^2 + a_4x + a_6
\end{equation}
with $a_i \in K$ having a specified base point, $\mathcal{O}\in E$. An equation of the form (\ref{eq:EllipticCurve}) is called a \textit{Weierstrass equation}. This equation is unique up to a coordinate transformation of the form
\[x = u^2x' + r, \quad\quad y = u^3y' + su^2x' + t, \]
with $r,s,t,u \in K, u\neq 0$.
Applying several linear changes of variables and writing
\[b_2 = a_1^2 + 4a_2, \quad b_4 = a_1a_3 + 2a_4, \quad b_6 = a_3^2 + 4a_6,\]
\[b_8 = a_1^2a_6 + 4a_2a_6 - a_1a_3a_4 + a_2a_3^2 - a_4^2,\]
\[ c_4 = b_2^2 - 24b_4, \quad \text{ and } \quad c_6 = -b_2^3 + 36b_2b_4 + 9b_2b_4b_6,\]
$E$ can be written as
\[E: y^2 = x^3 - 27c_4x - 54c_6.\]
Associated to this curve are the quantities
\[\Delta = -b_2^2b_8 - 8b_4^3 - 27b_6^2 + 9b_2b_4b_6 \quad \text{ and } \quad j = c_4^3/\Delta,\]
where $\Delta$ is called the \textit{discriminant} of the Weierstrass equation and the quantity $j$ is called the \textit{j-invariant} of the elliptic curve. The condition of being nonsingular is equivalent to $\Delta$ being non-zero. Two elliptic curves are isomorphic over $\bar{K}$, the algebraic closure of $K$, if and only if they both have the same $j$-invariant.

When $K = \mathbb{Q}$, the Weierstrass model (\ref{eq:EllipticCurve}) can be chosen so that $\Delta$ has minimal $p$-adic order for each rational prime $p$ and $a_i \in \mathbb{Z}$. Suppose (\ref{eq:EllipticCurve}) is such a global minimal model for an elliptic curve $E$ over $\mathbb{Q}$. Reducing the coefficients modulo a rational prime $p$ yields a (possibly singular) curve over $\mathbb{F}_p$
\begin{equation}
\tilde{E}: y^2 + \tilde{a_1}xy + \tilde{a_3}y = x^3 + \tilde{a_2}x^2 + \tilde{a_4}x + \tilde{a_6},
\end{equation}
where $\tilde{a_i} \in \mathbb{F}_p$. This ``reduced" curve $\tilde{E}/\mathbb{F}_p$ is called the \textit{reduction of $E$ modulo} $p$. It is nonsingular provided that $\Delta \not \equiv 0 \mod{p}$, in which case it is an elliptic curve defined over $\mathbb{F}_p$. The curve $E$ is said to have \textit{good reduction} modulo $p$ if $\tilde{E}/\mathbb{F}_p$ is nonsingular, otherwise, we say $E$ has \textit{bad reduction} modulo $p$.

The reduction type of $E$ at a rational prime $p$ is measured by the \textit{conductor},
\[N = \prod_{p}p^{f_p}\]
where the product runs over all primes $p$ and $f_p = 0$ for all but finitely many primes. In particular, $f_p \neq 0$ if $p$ does not divide $\Delta$. Equivalently, $E$ has bad reduction at $p$ if and only if $p \mid N$. Suppose $E$ has bad reduction at $p$ so that $f_p \neq 0$. The reduction type of $E$ at $p$ is said to be \textit{multiplicative} ($E$ has a node over $\mathbb{F}_p$) or \textit{additive} ($E$ has a cusp over $\mathbb{R}_p$) depending on whether $f_p = 1$ or $f_p \geq 2$, respectively. The $f_p$, hence the conductor, are invariant under isogeny.

%---------------------------------------------------------------------------------------------%

\section{Cubic forms}
\label{sec:CubicForms}

Let $a,b,c$ and $d$ be integers and consider the binary cubic form
\[F(x,y) = ax^3 + bx^2y + cxy^2 + dy^3.\]
Two such forms $F_1$ and $F_2$ are called \textit{equivalent} if they are equivalent under the $GL_{2}(\mathbb{Z})$-action. That is, if there exist integers $a_1, a_2, a_3$, and $a_4$ such that
\[F_1(a_1x + a_2y, a_3x + a_4y) = F_2(x,y)\]
for all $x,y$, where $a_1a_4 - a_2a_3 = \pm 1$. In this case, we write $F_1 \sim F_2$. The \textit{discriminant} $D_F$ of such a form is given by
\[D_F = -27a^2d^2 + b^2c^2 + 18abcd - 4ac^3 - 4b^3d = a^4 \prod_{i < j} (\alpha_i - \alpha_j)^2,\]
where $\alpha_1, \alpha_2$ and $\alpha_3$ are the roots of the polynomial $F(x,1)$. We observe that if $F_1 \sim F_2$, then $D_{F_1} = D_{F_2}$.

Associated to $F$ is the Hessian $H_F(x,y)$, given by
\begin{align*}
H_F(x,y) & = -\frac{1}{4}\left( \frac{\partial^2F}{\partial x^2} \frac{\partial^2F}{\partial y^2} - \left(\frac{\partial^2F}{\partial x \partial y}\right)^2\right)\\
& = (b^2 - 3ac)x^2 + (bc - 9ad)xy + (c^2 - 3bd)y^2,
\end{align*}
and the Jacobian determinant of $F$ and $H_F$, a cubic form $G_F(x,y)$ defined by
\begin{align*}
G_F(x,y) &= \frac{\partial F}{\partial x} \frac{\partial H_F}{\partial y} - \frac{\partial F}{\partial y} \frac{\partial H_F}{\partial x} \\
& =  (-27a^2d + 9abc -2b^3)x^3 + (-3b^2c - 27abd + 18ac^2)x^2y +  \\
& \quad \quad + (3bc^2 - 18b^2d + 27acd)xy^2 + (-9bcd + 2c^3 + 27ad^2)y^3.
\end{align*}

%---------------------------------------------------------------------------------------------%

\section{Lattices}
\label{sec:Lattices}

An $n$-dimensional lattice is a discrete subgroup of $\mathbb{R}^n$ of the form
\[\Gamma = \left\{ \sum_{i=1}^n x_i \mathbf{b}_i \ : \ x_i \in \mathbb{Z} \right\},\]
where $\mathbf{b}_1, \dots, \mathbf{b_n}$ are vectors forming a basis for $\mathbb{R}^n$. We say that the vectors $\mathbf{b}_1, \dots, \mathbf{b_n}$ form a \textit{basis} for $\Gamma$, or that they generate $\Gamma$. Let $B$ denote the matrix whose columns are the vectors $\mathbf{b}_1, \dots, \mathbf{b_n}$. Any lattice element $\mathbf{v}$ may be expressed as $\mathbf{v} = B\mathbf{x}$ for some $\mathbf{x} \in \mathbb{Z}^n$. We call $\mathbf{v}$ the \textit{embedded vector} and $\mathbf{x}$ the \textit{coordinate vector}.

A \textit{bilinear form} on a lattice $\Gamma$ is a function $\Phi: \Gamma \times \Gamma \to \mathbb{Z}$ satisfying
\begin{enumerate}
\item $\Phi(\mathbf{u}, \mathbf{v}+\mathbf{w}) = \Phi(\mathbf{u},\mathbf{v}) + \Phi(\mathbf{u},\mathbf{w})$
\item $\Phi(\mathbf{u}+\mathbf{v}, \mathbf{w}) = \Phi(\mathbf{u},\mathbf{w}) + \Phi(\mathbf{v},\mathbf{w})$
\item $\Phi(a\mathbf{u}, \mathbf{w}) = a\Phi(\mathbf{u},\mathbf{w})$
\item $\Phi(\mathbf{u}, a\mathbf{w}) = a\Phi(\mathbf{u},\mathbf{w})$
\end{enumerate}
for all $\mathbf{u}, \mathbf{v}$, and $\mathbf{w}$ in $\Gamma$ and any $a \in \mathbb{Z}$.

Given a basis, we can define a specific bilinear form on our lattice $\Gamma$ as part of its structure. This form describes a kind of distance between elements $\mathbf{u}$ and $\mathbf{v}$ and we say the lattice is \textit{defined} by $\Phi$. Associated to this bilinear form is a quadratic form $Q: \Gamma \to \mathbb{Z}$ defined by $Q(\mathbf{v}) = \Phi(\mathbf{v}, \mathbf{v})$. A lattice is called \textit{positive definite} if its quadratic form is positive definite.

The bilinear forms (and their associated quadratic forms) that we will be using come from the usual inner product on vectors in $\mathbb{R}^n$. This is simply the dot product $\Phi(\mathbf{u},\mathbf{v}) = \mathbf{u} \cdot \mathbf{v}$ for embedded vectors, $\mathbf{u},\mathbf{v}$. For the coordinate vectors $\mathbf{x},\mathbf{y}$ associated to these vectors, this translates to multiplication with the basis matrix. Precisely, if $\mathbf{u} = B\mathbf{x}$ and $\mathbf{v} = B\mathbf{y}$, we have $\Phi(\mathbf{u},\mathbf{v}) = \mathbf{x}^TB^TB\mathbf{y}$.

If $\mathbf{v} = B\mathbf{x}$, the \textit{norm} of the vector $\mathbf{v} \in \Gamma$ is defined to be the inner product $\Phi(\mathbf{v},\mathbf{v})$. In terms of the corresponding coordinate vector $\mathbf{x}$, this is
\[\mathbf{v}^T\mathbf{v} = \mathbf{x}^TB^TB\mathbf{x}.\]
Equivalently, we write $\mathbf{x}^TA\mathbf{x}$ where $A = B^TB$ is the Gram matrix of $\Gamma$ with basis $B$ and bilinear form $\Phi$. The entries of the matrix $A$ are $a_{ij} = \Phi(\mathbf{b}_i,\mathbf{b}_j)$.

Two basis matrices $B_1$ and $B_2$ define the same lattice $\Gamma$ if and only if there is a unimodular matrix $U$ such that $B_1U = B_2$. The bilinear form on $\Gamma$ can be written with respect to either embedded or coordinate vectors. Using another basis to express the lattice elements is possible, and sometimes preferable. However, the Gram matrix is specific to the bilinear form on the lattice and should not change when operating on embedded vectors. If it is operating on coordinate vectors, the change of basis must be accounted for.

%---------------------------------------------------------------------------------------------%

\section{Continued fractions}
\label{sec:continued-fractions}

In this section, we give a brief introduction to continued fractions. The background developed here will be important to us later when we will need to generate rational lattices. In particular, we will have to generate rational approximations to $\log(p)$ for various primes $p$, and the theory discussed here will enable us to generate such an approximation with relatively high precision. \edit{This is all taken from http://pi.math.cornell.edu/~gautam/ContinuedFractions.pdf (basics); the more advanced concepts are from https://www.math.ru.nl/~bosma/Students/CF.pdf and I can probably edit this section to sound nicer and/or remove anything extra.}

\begin{definition}
  A \textit{simple continued fraction} is an expression of the form
  \[a_0 + \cfrac{1}{a_1 + \cfrac{1}{a_2 + \cfrac{1}{a_3 + \dots}}}\]
  where $a_i$ are non-negative integers, for $i > 0$, and $a_0 \in \mathbb{Z}$.
\end{definition}
For ease of notation, we let
\[ [a_0,a_1,a_2,a_3,\dots] \]
denote the continued fraction above.
\begin{definition}
  For $0 \leq m \leq n$, we call $[a_0, \dots, a_m]$ the \textit{$m^{\text{th}}$ convergent} to $[a_0,\dots, a_n]$.
\end{definition}

Of course, every rational number has a simple continued fraction expansion which is finite, and every finite simple continued fraction expansion is a rational number. Moreover, if a rational number $x$ is representable by a simple continued fraction with an odd (respectively, even) number of convergents, it is also representable by one with an even (respectively, odd) number. In fact, there are exactly two ways to represent a rational number as a finite simple continued fraction: if $a_n\geq2$,
\[ [a_0,a_1,\dots,a_n] = [a_0,a_1,\dots,a_n - 1,1]. \]
If $a_n = 1$,
\[ [a_0,a_1,\dots,a_{n-1},1] = [a_0,a_1,\dots,a_{n-1} + 1,1].\]

If $p_n$ and $q_n$ are defined by
\[p_0 = a_0, \quad p_1 = a_1a_0 + 1, \quad p_n = a_np_{n-1} + p_{n-2} \quad \text{ for } n\geq 2\]
\[q_0 = 1, \quad q_1 = a_1, \quad q_n = a_nq_{n-1} + q_{n-2} \quad \text{ for } n\geq 2,\]
then
\[ [a_0,\dots,a_n] = \frac{p_n}{q_n}.\]
It follows that the $n^{\text{th}}$ convergent is
\[\frac{p_n}{q_n} = \frac{a_np_{n-1} + p_{n-2}}{a_nq_{n-1} + q_{n-2}}.\]

To compute the continued fraction expansion of a number $x$, rational or not, one uses the following algorithm, based on the Euclidean algorithm:
Let $x \in \mathbb{R}$ and set $x_0 = x$.
\begin{enumerate}[1.]
\item Set $a_m$ to be the integral part of $x_m$.
\item Set $\psi_m:= x_m - a_m$.
\item If $\psi_m \neq 0$, set $\frac{q}{\psi_m}$ as $x_{m+1}$ and return to step 1 to compute $a_{m+1}$.
\item If $\psi = 0$, terminate this algorithm.
\end{enumerate}
Using this algorithm, we may see rounding errors in computing $\frac{1}{\psi_m}$. Once these intermediate fractions become close to $0$, we stop the calculations to obtain a good approximation of $x$.

Let $x$ be given by $[a_0, \dots, a_n]$ and let $x_m$ denote the $m^{\text{th}}$ convergent $p_m/q_m$. The following theorems hold.

\begin{theorem}
  The even convergents $x_{2m}$ increase strictly with $m$, while the odd convergents $x_{2m+1}$ decrease strictly.
\end{theorem}
We thus have
\[x_0 < x_2 < x_4 < x_6< \dots \quad \text{ and } \quad x_1 > x_3 > x_5 > x_7 > \dots.\]
\begin{theorem}
  Every odd convergent is greater than any even convergent.
\end{theorem}
\begin{theorem}
  The value of the continued fraction is greater than and of its even convergents and less than any of its odd convergents (except where it is equal to the last convergent).
\end{theorem}

Consider now the best approximation to a given number with small denominators.
\begin{definition}
  The rational number $p/q$ is the \textit{best approximation} to a real number $x$ if $|p/q - x| \leq |P/Q - x|$, where $P/Q$ is any other rational number such that $Q \leq q$.
\end{definition}
\begin{theorem}
  The convergents to a simple continued fraction are in their lowest terms.
\end{theorem}
\begin{theorem}
  The denominators of the convergents satisfy the following inequalities
  \[q_n \geq n, \text{ with strict inequality when } n > 3.\]
\end{theorem}
\begin{theorem}
  \label{th:convergentbound}
  For any number $x$ with convergents $\frac{p_m}{q_m}$,
  \[\frac{1}{2q_mq_{m+1}} < \frac{1}{q_m(q_m + q_{m+1})} < \left|x - \frac{p_m}{q_m}\right| < \frac{1}{q_mq_{m+1}} < \frac{1}{q_m^2}\]
  for $m \geq 1$.
\end{theorem}
\begin{theorem}
  $\frac{p_m}{q_m}$ is the best approximation to $x$ with denominator $\leq q_m$.
\end{theorem}

All convergents to $x$ are best approximations to $x$, but these are not all the best approximations! Consider the following example:
\begin{example}
  \[x = 0.18421052631 = \frac{7}{38} = [0,5,2,3], \quad \text{ with convergents } \frac{0}{1}, \frac{1}{5}, \frac{2}{11}, \frac{7}{38}.\]
  If we look at all fractions with denominators $\leq 28$, then $\frac{5}{27}$ is the best approximation to $x$, with an error of $0.00097465886$, but it is not one of the convergents. Indeed,
  \[\frac{5}{27} = 0.18518518518 = [0,5,2,2].\]
\end{example}

This leads us to the following two questions:
\begin{enumerate}
\item What are all the best approximations?
\item How are they related to the convergents?
\end{enumerate}

\begin{definition}
  A \textit{semi-convergent} or \textit{secondary convergent} to $x$ is a number of the form
  \[\frac{p_k +r p_{k+1}}{q_k + rq_{k+1}},\]
  where $\frac{p_k}{q_k}$ and $\frac{p_{k+1}}{q_{k+1}}$ are two consecutive convergents to $x = [a_0,a_1,a_2,\dots]$ and $r$ is an integer such that $0 \leq r \leq a_k$.
\end{definition}
Note in particular that the convergents to $x$ are also semi-convergents.
\begin{theorem}
  If $x$ is any real number and $a/b$ is a not a semi-convergent to $x$, then $a/b$ is not the best approximation to $x$ with denominator $\leq b$.
\end{theorem}
The previous theorem tells us that the only candidates for the best approximations are the semi-convergents. In fact, there is a precise statement which says which semi-convergents are the best approximations which we will not state here \edit{but we actually should include this becasue it's important}. Roughtly speaking, about half the semi-convergents between $p_k/q_k$ and $p_{k+2}/q_{k+2}$ which are closest to $p_{k+2}/q_{k+2}$ are the best approximations to $x$.

In our example above, $5/27$ is a semi-convergent to $7/38$ but not a convergent. All the best approximations to $7/38 = [0,5,2,3]$ are $[0],[0,3],[0,4],[0,5],[0,5,2],[0,5,2,2],[0,5,2,3]$, where the convergents are $[0],[0,5],[0,5,2],[0,5,2,3]$.

When considering best approximations, we consider the distance between the fraction $p/q$ and $x$ as a measure of how well it approximates $x$. However, if the denominator increases, we should expect better approximations to have smaller distance from $x$. To take this into account, one could consider instead the distance $|qx - p|$.
\begin{definition}
  A fraction $p/q$ is a \textit{best approximation of the second kind} to a real number $x$ if for every fraction $a/b$ with $b \leq q$, we have $|qx-p| < |bx - a|$.
\end{definition}
\begin{theorem}
  The convergents to a real number $x$ are precisely all the best approximations of the second kind to $x$.
\end{theorem}

Consider now the coordinate plane where all points with integer coordinates are marked (ie. a lattice on the plane). Fix some $\alpha$ and draw the line $y = \alpha x$. If $\alpha$ is rational, then it would intersect the lattice in inifintely many points. If $\alpha$ is irrational, then it will not intersect the lattice at any point other than the origin.
\begin{theorem}
  The closest points in the lattice to the line $y = \alpha x$ are in one-to-one correspondence with the convergents to the continued fraction of $\alpha$. Let these points be labelled as $A_m = (q_m,p_m)$. The point is above the line if $m$ is odd and below otherwise.
\end{theorem}

Given just the points on the lattice closest to the line, it is also possible to recover the continued fraction.
\begin{theorem}
  Let $[a_0,\dots,a_n]$ be the continued fraction for $\alpha$ and let $A_m$ be the marked points in the lattice as before. Then $a_m$ is the integral distance between $A_m$ and $A_{m+2}$.
\end{theorem}
Here the integral distance between two points refers to the number of points on the line segment joining two points minus $1$. These two theorems give us a geometric way of going back and forth between continued fractions and approximations.

One of the main interests of continued fractions is in its application to the representation of irrationals. Suppose $a_0,a_1,a_2,\dots$ is a sequence of positive integers such that
\[x_n = [a_0,a_1,\dots,a_n]\]
is a simple continued fraction of a rational number $x_n$ for every $n$. If these $x_n \to x$ when $n \to \infty$, then we say that $[a_0,a_1,\dots]$ is $x$ and we write
\[x = [a_0,a_1,\dots].\]
\begin{theorem}
  If $a_0,a_1,a_2,\dots$ is a sequence of positive integers, then $x = [a_0,a_1,\dots] \to x$ as $n \to \infty$.
\end{theorem}
In particular, this means that we can always talk about $[a_0,a_1,a_2,\dots]$ as it is a well-defined real number.
\begin{theorem}
  An infinite simple continued fraction is less than any of its odd convergents and greater than any of its even convergents.
\end{theorem}
\begin{theorem}
  Every irrational number can be expressed in just one way as an infinite simple continued fraction.
\end{theorem}

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %

\subsection{General continued fractions}
\label{sec:gener-cont-fract}

\begin{definition}
  The \textit{general continued fraction} is a simple continued fraction in which the numerators and denominators can assume arbitrary complex values. A generalized continued fraction is an expression of the form
  \[x = a_0 + \cfrac{b_1}{a_1 + \cfrac{b_2}{a_2 + \cfrac{b_3}{a_3 + \dots}}}.\]
\end{definition}
Working with general continued fractions instead of simple continued fractions does not provide any new information, but in some cases, makes it easier to explicitly compute the former rather than the latter.

If $\{c_1,c_2,c_3,\dots\}$ is any infinite sequence of non-zero complex numbers, the following equivalence holds
\[ a_0 + \cfrac{b_1}{a_1 + \cfrac{b_2}{a_2 + \cfrac{b_3}{a_3 + \cfrac{b_4}{a_4 + \dots}}}}
  = a_0 + \cfrac{c_1b_1}{c_1a_1 + \cfrac{c_1c_2b_2}{c_2a_2 + \cfrac{c_2c_3b_3}{c_3a_3 + \cfrac{c_3c_4b_4}{c_4a_4 + \dots}}}}.\]
That is, the successive convergents of the continued fraction on the left are exactly the same as the convergents of the fraction on the right. The equivalence transformation is perfectly general, however, if none of the $b_i$ are zero, one can choose the sequence $\{c_i\}$ so as to obtain a simple continued fraction
\[ a_0 + \cfrac{b_1}{a_1 + \cfrac{b_2}{a_2 + \cfrac{b_3}{a_3 + \cfrac{b_4}{a_4 + \dots}}}}
  = a_0 + \cfrac{1}{c_1a_1 + \cfrac{1}{c_2a_2 + \cfrac{1}{c_3a_3 + \cfrac{1}{c_4a_4 + \dots}}}}\]
via
\[c_1 = \frac{1}{b_1}, \quad c_{n+1} = \frac{1}{b_{n+1}c_n}.\]

For our purposes, we will need the continued fration expansion of $\log(p)$. Indeed, for
\begin{align*}
  \log\left(\frac{1+z}{1-z}\right)
  & = 2\sum_{n=0}^{\infty}\frac{z^{2n+1}}{2n+1} \\
  & = \cfrac{2z}{1-\cfrac{z^2}{3 - \cfrac{4z^2}{5-\cfrac{9z^2}{7-\cfrac{16z^2}{9 - \cfrac{25z^2}{11 - \cfrac{36z^2}{13 - \dots}}}}}}}
\end{align*}
for all $z \in \mathbb{C}/((-\infty,-1] \cup [1,\infty))$. Writing $z = \frac{p-1}{p+1}<1$, we obtain
\begin{align*}
  \log(p) & = \log\left(\frac{1+z}{1-z}\right)\\
          & = \cfrac{2z}{1-\cfrac{z^2}{3 - \cfrac{4z^2}{5-\cfrac{9z^2}{7-\cfrac{16z^2}{9 - \cfrac{25z^2}{11 - \cfrac{36z^2}{13 - \dots}}}}}}}
\end{align*}

\edit{The above does not work in Magma. Using this approach does not give us fast enough convergence, and in fact, the bound in Theorem \ref{th:convergentbound} does not even hold! It's far better to compute the convergents as}
\begin{lstlisting}
Convergents(ContinuedFraction(RealField(prec)!Log(RealField(prec)!p)));
\end{lstlisting}
\edit{This generates a $2 \times 2$ matrix with integer coefficients
  \[  \begin{bmatrix}
      p_n & p_{n-1} \\
      q_n & q_{n-1}
    \end{bmatrix}.
  \]
  The quotients $p_{n-1}/q_{n-1}$ and $p_n/q_n$ form the last two convergents for $\log(p)$ as provided by}
\begin{lstlisting}
ContinuedFraction(RealField(prec)!Log(RealField(prec)!p));
\end{lstlisting}
\edit{Meanwhile, the above function takes $\log(p)$ as input, with given precision, and returns a sequence of integers that form the partial quotient for the (regular/simple) continued fraction expansion for $\log(p)$. The length of the sequence is determined in such a way that the last significant partial quotient is obtained (determined by the precision with which $\log(p)$ is known). Note finally that if $n$ is even, the resulting continued fraction $p_n/q_n$ will have
\[\frac{p_n}{q_n} < \log(p).\]
Taking $n$ odd will yield the desired result, $\log(p) < \frac{p_n}{q_n}$, however}.

%---------------------------------------------------------------------------------------------%
%---------------------------------------------------------------------------------------------%

\chapter{Algorithms for Thue-Mahler Equations}
\label{ch:AlgorithmsForTM}

In this chapter, we give some of the primary algorithms needed to solve an arbitrary Thue-Mahler equation. The methods presented here follow somewhat \cite{Ham} and \cite{TW3}, with new results and modifications from \cite{GhKaMaSi}.

%---------------------------------------------------------------------------------------------%

\section{First steps}
\label{sec:FirstSteps}

Fix a nonzero integer $c$ and let $S=\{p_1,\dotsc,p_v\}$ be a set of rational primes. Let
\[F(X,Y) = c_0 X^n + c_1 X^{n-1}Y + \cdots + c_{n-1}XY^{n-1} + c_nY^n\]
be an irreducible binary form over $\mathbb{Z}$ of degree $n \geq 3$. We want to solve the Thue--Mahler equation
\begin{equation} \label{eq:ThueMahler}
F(X,Y) = c p_1^{Z_1}\cdots p_v^{Z_v}
\end{equation}
for unknowns $X,Y, Z_1, \dots, Z_v$ with $\gcd(X,Y) = 1$ and $Z_i \geq 0$ for $i = 1,\dots, v$. To do so, we first reduce \eqref{eq:ThueMahler} to the special case where $c_0 = 1$ and $\gcd(c,p_i) = 1$ for $i = 1, \dots, v$, loosely following \cite{Ham}.

As $F$ is irreducible by assumption, at least one of the coefficients $c_0$ and $c_n$ is nonzero. Hence, we may transform the given Thue--Mahler equation to one with $c_0 \neq 0$ by interchanging $X$ and $Y$ and by renaming the coefficients $c_i$ appropriately. In particular, solving \eqref{eq:ThueMahler} is equivalent to solving
\[ c_0' \overline{X}^n + c_1' \overline{X}^{n-1}\overline{Y} + \cdots + c_{n-1}'\overline{X}\overline{Y}^{n-1} + c_n'\overline{Y}^n = c p_1^{Z_1}\cdots p_v^{Z_v},\]
where $c_i' = c_{n-1}$ for $i = 0, \dots, n$, $\overline{X} = Y$, and $\overline{Y} = X$.

Let $\mathcal{D}$ be the set of all positive integers $m$ dividing $c_0$ such that ${\ord_p(m)\leq \ord_p(c)}$ for each rational prime $p\notin S$. Equivalently, $\mathcal{D}$ is precisely the set of all possible integers $d$ such that $d = \gcd(c_0,Y)$. To see this, let $q_1, \dots, q_{w}$ denote the distinct prime divisors of $a$ not contained in $S$. Then
\[c = \prod_{i=1}^w q_i^{b_i}\cdot \prod_{i=1}^v p_i^{\ord_{p_i}(c)}\]
for some integers $b_i >0$. If $(X,Y,Z_1, \dots, Z_v)$ is a solution of the Thue-Mahler equation in question, it follows that
\[F(X,Y) = cp_1^{Z_1}\dots p_v^{Z_v} =  \prod_{i=1}^w q_i^{b_i}\cdot \prod_{i=1}^v p_i^{\ord_{p_i}(c) + Z_i}.\]
Suppose $\gcd(c_0,Y) = d$. Since $d$ divides $F(X,Y)$, it necessarily divides
\[{\prod_{i=1}^w q_i^{b_i}\cdot \prod_{i=1}^v p_i^{\ord_{p_i}(c) + Z_i}}.\]
In particular,
\[d = \prod_{i=1}^w q_i^{s_i}\cdot \prod_{i=1}^v p_i^{t_i}\]
for some non-negative integers $s_1, \dots, s_w, t_1, \dots, t_v$ such that
\[s_i \leq \min\{\ord_{q_i}(c), \ord_{q_i}(c_0)\} \quad \text{ and } \quad
	t_i \leq \min\{\ord_{p_i}(c) + Z_i, \ord_{p_i}(c_0)\}.\]
From here, it is easy to see that ${\ord_p(d)\leq \ord_p(c)}$ for each rational prime $p\notin S$ so that $d \in \mathcal{D}$.

Conversely, suppose $d \in \mathcal{D}$ so that $\ord_{p}(d) \leq \ord_{p}(c)$ for all $p \notin S$. That is, the right-hand side of
\[\ord_{p}(d) \leq \ord_{p}(c) =
\ord_p\left(\prod_{i=1}^w q_i^{b_i}\cdot \prod_{i=1}^v p_i^{\ord_{p_i}(c)}\right)\]
is non-trivial only at the primes $\{q_1, \dots, q_w\}$. In particular,
\[d = \prod_{i=1}^w q_i^{s_i}\cdot \prod_{i=1}^v p_i^{t_i}\]
for non-negative integers $s_1, \dots, s_w, t_1, \dots, t_v$ such that
\[s_i \leq \min\{\ord_{q_i}(c), \ord_{q_i}(c_0)\} \quad \text{ and } \quad
	t_i \leq \ord_{p_i}(c_0).\]
It follows that $d = \gcd(c_0,Y)$ for some solution $(X,Y,Z_1, \dots, Z_v)$ of equation~\eqref{eq:ThueMahler}.

For any $d\in \mathcal{D}$, we define the rational numbers
\[u_d = c_0^{n-1}/d^n \quad \textnormal{and}\quad c_d = \sgn(u_dc)\prod_{p\notin S} p^{\ord_p(u_dc)}.\]
On using that $d\in \mathcal{D}$, we see that the rational number $c_d$ is in fact an integer coprime to $S$.

Suppose $(X,Y,Z_1, \dots, Z_v)$ is a solution of \eqref{eq:ThueMahler} with ${\gcd(X,Y) = 1}$ and $d = \gcd(c_0,Y)$. Define the homogeneous polynomial $f(x,y) \in \mathbb{Z}[x,y]$ of degree $n$ by
\[f(x,y) = x^n + C_1 x^{n-1}y + \dots + C_{n-1}xy^{n-1} + C_ny^n,\]
where
\[x=\tfrac{c_0X}{d},\quad y=\tfrac{Y}{d} \quad \text{ and } \quad C_i = c_ic_0^{i-1} \quad \text{ for } i = 1, \dots, n.\]
Since $\gcd(X,Y) = 1$, the numbers $x$ and $y$ are also coprime integers by definition of $d$. We observe that
\[f(x,y) = u_dF(X,Y) = u_dc \prod_{i = 1}^v p_i^{Z_i} = c_d\prod_{p \in S}p^{Z_i + \ord_p(u_dc)}.\]
Setting $z_i = Z_i + \ord_p(u_dc)$ for all $i \in \{1, \dots, v\}$, we obtain
\begin{equation} \label{eq:ThueMahler2}
f(x,y) = x^n + C_1 x^{n-1}y + \dots + C_{n-1}xy^{n-1} + C_ny^n = c_d p_1^{z_1}\cdots p_v^{z_v},
\end{equation}
where $\gcd(x,y) = 1$ and $\gcd(c_d,p_i) = 1$ for all $i = 1, \dots, v$.

Since there are only finitely many choices for $d = \gcd(c_0, Y)$, there are only finitely many choices for $\{c_d,u_d,d\}$. Then, solving \eqref{eq:ThueMahler} is equivalent to solving the finitely many Thue-Mahler equations \eqref{eq:ThueMahler2} for each choice of $\{c_d,u_d,d\}$.  For each such choice, the solution $\{x,y,z_1, \dots, z_v\}$ is related to $\{X,Y, Z_1, \dots, Z_v\}$ via
\[X = \frac{dx}{c_0},\quad Y=dy \quad \text{ and } \quad Z_i = z_i - \ord_p(u_dc).\]

Lastly, we observe that the polynomial $f(x,y)$ of \eqref{eq:ThueMahler2} remains the same for any choice of $\{c_d,u_d,d\}$. Thus, to solve the family of equations \eqref{eq:ThueMahler2}, we need only to enumerate over every possible $c_d$. Now, if $\mathcal{C}$ denotes the set of all $\{c_d,u_d,d\}$ and $d_1, d_2 \in \mathcal{D}$, we may have $\{c_{d_1},u_{d_1}, d_1\}, \{c_{d_2},u_{d_2}, d_2\} \in \mathcal{C}$ where $c_{d_1} = c_{d_2}$. That is, $d_1, d_2$ may yield the same value of $c_d$, reiterating that we need only solve \eqref{eq:ThueMahler2} for each distinct $c_d$.

%---------------------------------------------------------------------------------------------%

\section{The relevant algebraic number field}
\label{sec:RelevantAlgNumField}

For the remainder of this chapter, we consider the Thue-Mahler equation
\begin{equation} \label{eq:ThueMahler3}
f(x,y) = x^n + C_1 x^{n-1}y + \dots + C_{n-1}xy^{n-1} + C_ny^n = c p_1^{z_1} \cdots p_v^{z_v}
\end{equation}
where $\gcd(x,y) = 1$ and $\gcd(c,p_i) = 1$ for $i = 1, \dots, p_v$.

Following \cite{TW3}, put
\[g(t) = f(t,1) = t^n + C_1 t^{n-1} + \dots + C_{n-1}t + C_n\]
and note that $g(t)$ is irreducible in $\mathbb{Z}[t]$. Let $K = \mathbb{Q}(\theta)$ with $g(\theta) = 0$. Now \eqref{eq:ThueMahler3} is equivalent to the norm equation
\begin{equation} \label{eq:normTM}
N_{K/\mathbb{Q}}(x-y\theta) = cp_1^{z_1}\dots p_v^{z_v}.
\end{equation}

Let $p_i$ be any rational prime and let
\[(p_i)\mathcal{O}_K = \prod_{j = 1}^{m_i} \mathfrak{p}_{ij}^{e(\mathfrak{p}_{ij}|p_i)}\]
be the factorization of $p_i$ into prime ideals in the ring of integers $\mathcal{O}_K$ of $K$. Let $f(\mathfrak{p}_{ij}|p_i)$ be the inertial degree of $\mathfrak{p}_{ij}$ over $p_i$. Since $N(\mathfrak{p}_{ij}) = p_i^{f_{ij}}$, \eqref{eq:normTM} leads to finitely many ideal equations of the form
\begin{equation} \label{eq:idealTM}
(x-y\theta)\mathcal{O}_K = \mathfrak{a} \prod_{j = 1}^{m_1} \mathfrak{p}_{1j}^{z_{1j}} \cdots \prod_{j = 1}^{m_v} \mathfrak{p}_{vj}^{z_{vj}}
\end{equation}
where $\mathfrak{a}$ is an ideal of norm $|c|$ and the $z_{ij}$ are unknown integers related to $z_i$ by
\[\sum_{j = 1}^{m_i} f(\mathfrak{p}_{ij}|p_i)z_{ij} = z_i\]
for $i \in \{1, \dots, v\}$.

Our first task is to cut down the number of variables appearing in \eqref{eq:idealTM}. We will do this by showing that only a few prime ideals can divide $(x-y\theta)\mathcal{O}_K$ to a large power.

%---------------------------------------------------------------------------------------------%

\section{The prime ideal removing lemma}
\label{sec:PIRL}

In this section, we establish some key results that will allow us to cut down the number of prime ideals that can appear to a large power in the factorization of $(x-y\theta)\mathcal{O}_K$. It is of particular importance to note that we do not appeal to the Prime Ideal Removing Lemma of Tzanakis and de Weger (\cite{TW3}) here and instead apply the following results of \cite{GhKaMaSi}.

Let $p \in \{p_1, \dots, p_v\}$. We will produce the following two finite lists $L_p$ and $M_p$. The list $L_p$ will
consist of certain ideals $\mathfrak{b}$ of $\mathcal{O}_K$ supported at the prime ideals above $p$. The list $M_p$ will consist of certain pairs $(\mathfrak{b},\mathfrak{p})$ where $\mathfrak{b}$ is supported at the prime ideals above $p$ and $\mathfrak{p}$ is a prime ideal lying over $p$ satisfying $e(\mathfrak{p}|p)=f(\mathfrak{p}|p)=1$. These lists will satisfy the following property: if $(x,y,z_1,\dots,z_v)$ is a solution to the Thue-Mahler equation \eqref{eq:ThueMahler3} then
\begin{enumerate}[(i)]
\item either there is some $\mathfrak{b} \in L_p$
such that
\begin{equation} \label{eq:Lp}
\mathfrak{b} \mid (x-y\theta )\mathcal{O}_K, \qquad \text{$(x-y\theta)\mathcal{O}_K/\mathfrak{b}$ is coprime to $(p)\mathcal{O}_K$};
\end{equation}
\item or there is a pair $(\mathfrak{b},\mathfrak{p}) \in M_p$ and a non-negative integer $v_p$ such that
\begin{equation} \label{eq:Mp}
(\mathfrak{b} \mathfrak{p}^{v_p}) \mid (x-y\theta)\mathcal{O}_K, \qquad \text{$(x-y\theta)\mathcal{O}_K/(\mathfrak{b} \mathfrak{p}^{v_p})$ is coprime to $(p)\mathcal{O}_K$}.
\end{equation}
\end{enumerate}

To generate the lists $M_p$, $L_p$ we consider two affine patches, $p \nmid y$ and $p \mid y$. We begin with the following lemmata.

\begin{lemma} \label{lem:AffinePatch1}
Let $(x,y,z_1, \dots, z_v)$ be a solution of \eqref{eq:ThueMahler3} with $p \nmid y$, let $t$ be a positive integer, and suppose $x/y \equiv u \pmod{p^t}$, where ${u \in \{0,1,2,\dotsc,p^{t}-1\}}$. If $\mathfrak{q}$ is a prime ideal of $\mathcal{O}_K$ lying over $p$, then
\[\ord_{\mathfrak{q}}(x-y\theta)\ge \min\{\ord_{\mathfrak{q}}(u-\theta), t \cdot e(\mathfrak{q}|p)\}.\]
Moreover, if $\ord_{\mathfrak{q}}(u-\theta) < t \cdot e(\mathfrak{q}|p)$, then
\[\ord_\mathfrak{q}(x-y\theta) = \ord_{\mathfrak{q}}(u-\theta).\]
\end{lemma}

\begin{lemma} \label{lem:AffinePatch2}
Let $(x,y,z_1, \dots, z_v)$ be a solution of \eqref{eq:ThueMahler3} with $p \mid y$ (and thus $p \nmid x$), let $t$ be a positive integer, and suppose $y/x \equiv u \pmod{p^t}$, where $u \in \{0,1,2,\dotsc,p^{t}-1\}$. If $\mathfrak{q}$ is a prime ideal of $\mathcal{O}_K$ lying over $p$, then
\[\ord_{\mathfrak{q}}(x-y\theta)\ge \min\{\ord_{\mathfrak{q}}(1-\theta u), t \cdot e(\mathfrak{q}|p)\}.\]
Moreover, if $\ord_{\mathfrak{q}}(1-\theta u) < t \cdot e(\mathfrak{q}|p)$, then
\[\ord_\mathfrak{q}(x-y\theta) = \ord_{\mathfrak{q}}(1 - \theta u).\]
\end{lemma}

\begin{proof}[Proof of Lemmas~\ref{lem:AffinePatch1} and \ref{lem:AffinePatch2}]
Suppose $p \nmid y$. Thus $\ord_{\mathfrak{q}}(y) = 0$ and hence
\[\ord_{\mathfrak{q}}(x-y\theta) = \ord_{\mathfrak{q}}(x/y - \theta).\]
Since $x/y-\theta = u - \theta + x/y - u,$ we have
\[\begin{array}{ll}
\ord_\mathfrak{q}(x/y-\theta)	& = \ord_{\mathfrak{q}}(u - \theta + x/y - u) \\
						& \geq \min\{\ord_{\mathfrak{q}}(u - \theta), \ord_{\mathfrak{q}}(x/y - u)\}.
\end{array}\]
By assumption,
\[\ord_{\mathfrak{q}}(x/y-u) \geq \ord_{\mathfrak{q}}(p^t) = t \cdot e(\mathfrak{q}|p),\]
 %Thus $\ord_\fq(x-\theta)=\ord_\fq(u-\theta)$,
completing the proof of Lemma~\ref{lem:AffinePatch1}. The proof of Lemma~\ref{lem:AffinePatch2} is similar.
\end{proof}

The following algorithm computes the lists $L_p$ and $M_p$ that come from the first patch $p \nmid y$. We denote these respectively by $\mathcal{L}_p$ and $\mathcal{M}_p$.

\begin{algorithm} \label{alg:AffinePatch1}
To compute
$\mathcal{L}_p$ and $\mathcal{M}_p$:

\begin{enumerate}[Step (1)]
\item Let
\[\mathcal{L}_p \leftarrow \emptyset, \qquad \mathcal{M}_p \leftarrow \emptyset,\]
\[ t \leftarrow 1, \quad \mathcal{U} \leftarrow \{w : w \in \{0,1,\dots,p-1\} \}.\]
\item Let
\[\mathcal{U}^\prime \leftarrow \emptyset.\]
Loop through the elements $u \in \mathcal{U}$. Let
\[\mathcal{P}_u= \{\mathfrak{q} \text{ lying above } p \ : \ \ord_{\mathfrak{q}}(u-\theta) \geq t \cdot e(\mathfrak{q}|p)\}\]
and
\[ \mathfrak{b}_u 	= \prod_{\mathfrak{q} \mid p} \mathfrak{q}^{\min\{\ord_\mathfrak{q}(u-\theta), t \cdot e(\mathfrak{q}|p)\}}
				= (u-\theta) \mathcal{O}_K+p^t \mathcal{O}_K.\]
\begin{enumerate}[(i)]
\item If $\mathcal{P}_u = \emptyset$ then
\[\mathcal{L}_p \leftarrow \mathcal{L}_p \cup \{\mathfrak{b}_u\}.\]
\item Else if $\mathcal{P}_u = \{\mathfrak{p}\}$ with $e(\mathfrak{p}|p)=f(\mathfrak{p}|p)=1$ and there is at least one $\mathbb{Z}_p$-root $\alpha$ of $g(t)$ satisfying $\alpha \equiv u \pmod{p^t}$, then
\[\mathcal{M}_p \leftarrow \mathcal{M}_p \cup \{ (\mathfrak{b}_u,\mathfrak{p})\}.\]
\item Else
\[\mathcal{U}^\prime \leftarrow \mathcal{U} \cup \{ u+p^{t}w : w \in \{0,\dots,p-1\} \}.\]
\end{enumerate}

\item If $\mathcal{U}^\prime \ne \emptyset$ then let
\[t \leftarrow t+1, \qquad \mathcal{U} \leftarrow \mathcal{U}^{\prime},\]
and return to Step (2). Else output $\mathcal{L}_p$, $\mathcal{M}_p$.
\end{enumerate}
\end{algorithm}

\begin{lemma}
Algorithm~\ref{alg:AffinePatch1} terminates.
\end{lemma}

\begin{proof}
Suppose otherwise. Write $t_0=1$ and $t_i=t_0+i$ for $i=1,2,3,\dots$. Then there is an infinite sequence of congruence classes $u_i \mod{p^{t_i}}$ such that ${u_{i+1} \equiv u_i \mod{p^{t_i}}}$, and such that the $u_i$ fail the hypotheses of both (i) and (ii). This means that $\mathcal{P}_{u_i}$ is non-empty for every $i \in \mathbb{N}_{>0}$. By the pigeon-hole principle, some prime ideal $\mathfrak{p}$ of $\mathcal{O}_K$ appears in infinitely many of the $\mathcal{P}_{u_i}$. Thus ${\ord_{\mathfrak{p}}(u_i-\theta) \ge t_i\cdot e(\mathfrak{p}|p)}$ infinitely often. However, the sequence $\{u_i\}_{i=1}^{\infty}$ converges to some $\alpha \in \mathbb{Z}_p$ so that $\alpha=\theta$ in $K_\mathfrak{p}$. This forces $e(\mathfrak{p}|p)=f(\mathfrak{p}|p)=1$ and $\alpha$ to be a $\mathbb{Z}_p$-root of $g(t)$. In this case, $\mathfrak{p}$ corresponds to the factor $(t-\alpha)$ in the $p$-adic factorisation of $g(t)$. There can be at most one such $\mathfrak{p}$, forcing $\mathcal{P}_{u_i}=\{\mathfrak{p}\}$ for all $i$. In particular, the hypothesis of (ii) are satisfied and we reach a contradiction.
\end{proof}

\begin{lemma}\label{lem:AffinePatch1Check}
Let $p \in \{p_1, \dots, p_v\}$ and let $\mathcal{L}_p$, $\mathcal{M}_p$ be as given by Algorithm~\ref{alg:AffinePatch1}. Let $(x,y,z_1,\dots, z_v)$ be a solution to \eqref{eq:ThueMahler3}. Then
\begin{itemize}
\item either there is some $\mathfrak{b} \in \mathcal{L}_p$ such that \eqref{eq:Lp} is satisfied;
\item or there is some $(\mathfrak{b},\mathfrak{p}) \in \mathcal{M}_p$ with $e(\mathfrak{p}|p)=f(\mathfrak{p}|p)=1$ and integer $v_p \geq 0$ such that \eqref{eq:Mp} is satisfied.
\end{itemize}
\end{lemma}

\begin{proof}
Let
\[t_0 = 1 \quad \text{ and } \quad \mathcal{U}_0=\{w \; :\;  w \in \{0,1,\dots,p-1\}\}\]
be the initial values for $t$ and $\mathcal{U}$ in the algorithm. Then $x/y \equiv u_0 \pmod{p^{t_0}}$ for some $u_0 \in \mathcal{U}_0$. Write $\mathcal{U}_i$ for the value of $\mathcal{U}$ after $i$ iterations of the algorithm  and let $t_i=t_0+i$. As the algorithm terminates, $\mathcal{U}_i = \emptyset$ for some sufficiently large $i$. Hence there is some $i$ such that $x/y \equiv u_i \mod{p^{t_i}}$ where $u_i \in \mathcal{U}_i$, but there is no element in $\mathcal{U}_{i+1}$ congruent to $x/y$ modulo $p^{t_{i+1}}$. In other words, $u_i$ must satisfy the hypotheses of either step (i) or (ii) of algorithm~\ref{alg:AffinePatch1}. Write $u=u_i$ and $t=t_i$ for $x/y \equiv u \mod{p^t}$ and consider the ideal $\mathfrak{b}_u$ generated in this step. By Lemma~\ref{lem:AffinePatch1}, $\mathfrak{b}_u$ divides $(x-y\theta) \mathcal{O}_K$. Furthermore, by definition of $\mathcal{P}_u$, if $\mathfrak{q}$ is a prime ideal of $\mathcal{O}_K$ not contained in $\mathcal{P}_u$, then $(x-y\theta)\mathcal{O}_K/\mathfrak{b}_u$ is not divisible by $\mathfrak{q}$.

Suppose first that the hypothesis of (i) is satisfied: $\mathcal{P}_u = \emptyset$. The algorithm adds $\mathfrak{b}_u$ to the set $\mathcal{L}_p$, with the above remarks ensuring that \eqref{eq:Lp} is satisfied.

Suppose next that the hypothesis of (ii) is satisfied: $\mathcal{P}_u=\{\mathfrak{p}\}$ where ${e(\mathfrak{p}|p)=f(\mathfrak{p}|p)=1}$ and there is a unique $\mathbb{Z}_p$ root $\alpha$ of $g(t)$ such that $\alpha \equiv u \mod{p^t}$. The algorithm adds $(\mathfrak{b}_u,\mathfrak{p})$ to the set $\mathcal{M}_p$. By the above, $(x-y\theta)\mathcal{O}_K/\mathfrak{b}_u$ is an integral ideal, not divisible by any prime ideal $\mathfrak{q} \neq \mathfrak{p}$ lying over $p$. Thus there is some positive integer $v_p \geq 0$ such that \eqref{eq:Mp} is satisfied, concluding the proof.
\end{proof}

Having computed the lists arising from the affine patch $p \nmid y$, we initialize $L_p$ and $M_p$ as $\mathcal{L}_p$ and $\mathcal{M}_p$, respectively, and append to these lists the elements from the second patch, $p \mid y$, using the following algorithm.

\begin{algorithm}\label{alg:AffinePatch2}
To compute $L_p$ and $M_p$.

\begin{enumerate}[Step (1)]
\item Let
\[ L_p \leftarrow \mathcal{L}_p, \qquad M_p \leftarrow \mathcal{M}_p,\]
where $\mathcal{L}_p$, $\mathcal{M}_p$ are computed by Algorithm~\ref{alg:AffinePatch1}.
\item Let
\[ t \leftarrow 2, \qquad \mathcal{U} \leftarrow \{pw \; : \; w \in \{0,1,\dots,p-1\} \}.\]
\item Let
\[ \mathcal{U}^{\prime} \leftarrow \emptyset.\]
Loop through the elements $u \in \mathcal{U}$. Let
\[\mathcal{P}_u=\{\mathfrak{q} \text{ lying above } p \ : \ \ord_{\mathfrak{q}}(1-u\theta ) \ge t \cdot e(\mathfrak{q}|p)\},\]
and
\[ \mathfrak{b}_u=\prod_{\mathfrak{q} \mid p} \mathfrak{q}^{\min\{\ord_{\mathfrak{q}}(1-u\theta ), t \cdot e(\mathfrak{q}|p)\}} =(1-u\theta) \mathcal{O}_K+p^t \mathcal{O}_K.\]

\begin{enumerate}[(i)]
\item If $\mathcal{P}_u=\emptyset$
%$\ord_p(\Norm(u-\theta)) \ge (n-1) c_0$
then
\[L_p \leftarrow L_p \cup \{\mathfrak{b}_u\}.\]
%\item[(ii)] Else if $\cP_u=\{\fp\}$ with
%$e(\fp/p)=f(\fp/p)=1$,
%and
%$\ord_p(\Norm(u-\theta)) \ge (n-1) c_0$,
%and there is at least on $\Z_p$-root $\alpha$ of
%$f$ satisfying $\alpha \equiv u \pmod{p^t}$,
%then
%\[
%\cM_p \leftarrow \cM_p \cup \{ (\fb_u,\fp)\}.
%\]
\item Else
\[\mathcal{U}^\prime \leftarrow \mathcal{U}^\prime \cup \{ u+p^{t}w : w \in \{0,\dotsc,p-1\} \}.\]
\end{enumerate}

\item If $\mathcal{U}^\prime \ne \emptyset$ then let
\[t \leftarrow t+1, \qquad \mathcal{U} \leftarrow \mathcal{U}^\prime,\]
and return to Step (3). Else output $L_p$, $M_p$.
\end{enumerate}
%\noindent \textbf{Output:} $\cL_p$, $\cM_p$.
\end{algorithm}

\begin{lemma}
Algorithm~\ref{alg:AffinePatch2} terminates.
\end{lemma}

\begin{proof}
Suppose that the algorithm does not terminate. Let $t_0=2$ and $t_i=t_0+i$ for $i \in \mathbb{N}$. Then there is an infinite sequence of congruence classes $\{u_i\}_{i = 0}^{\infty}$ and corresponding sets $\{\mathcal{P}_{u_i}\}_{i=0}^{\infty}$ such that $u_{i+1} \equiv u_i \mod{t_i}$ and $\mathcal{P}_{u_i} \ne \emptyset$ for all $i$. Moreover, $p \mid u_0$. Let $\alpha$ be the limit of $\{u_i\}_{i=0}^{\infty}$ in $\mathbb{Z}_p$. By the pigeon-hole principle, there is some ideal $\mathfrak{q}$ in $\mathcal{O}_K$ above $p$ which appears in infinitely many sets $\mathcal{P}_{u_i}$. It follows that $\ord_{\mathfrak{q}}(1 -u_i \theta) \ge t_i \cdot e(\mathfrak{q}|p)$ and thus $1-\alpha \theta=0$ in $K_{\mathfrak{q}}$. But as $p \mid u_0$, we have $\ord_p(\alpha) \ge 1$, and so $\ord_{\mathfrak{q}}(\theta)<0$. This contradicts the fact that $\theta$ is an algebraic integer. Therefore the algorithm must terminate.
\end{proof}

\begin{lemma}\label{lem:AffinePatch2Check}
Let $p \in \{p_1, \dots, p_v\}$ and let $L_p$, $M_p$ be as given by Algorithm~\ref{alg:AffinePatch2}. Let $(x,y,z_1,\dots, z_v)$ be a solution to \eqref{eq:ThueMahler3}. Then
\begin{itemize}
\item either there is some $\mathfrak{b} \in L_p$ such that \eqref{eq:Lp} is satisfied;
\item or there is some $(\mathfrak{b},\mathfrak{p}) \in M_p$ with $e(\mathfrak{p}|p)=f(\mathfrak{p}|p)=1$ and integer $v_p \geq 0$ such that \eqref{eq:Mp} is satisfied.
\end{itemize}
\end{lemma}

\begin{proof}
Let $(x,y,z_1,\dots, z_v)$ be a solution to \eqref{eq:ThueMahler3}. In view of Lemma~\ref{lem:AffinePatch1Check} we may suppose $p \mid y$. Then $\ord_{\mathfrak{q}}(x) = 0$ and $\ord_{\mathfrak{q}}(x-y\theta)=\ord_{\mathfrak{q}}(1 - (y/x) \theta)$ for any prime ideal $\mathfrak{q}$ lying over $p$. The remainder of the proof is analogous to the proof of Lemma~\ref{lem:AffinePatch1Check}.
\end{proof}

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %

\subsection{Computational remarks and refinements}
\label{subsec:PIRLRemarks}

In implementing Algorithms~\ref{alg:AffinePatch1} and \ref{alg:AffinePatch2}, we reduce the number of prime ideals appearing to a large power in the factorization of $(x-y\theta)\mathcal{O}_K$. The Prime Ideal Removing Lemma, as originally stated in Tzanakis - de Weger outlines a similar process by comparing the valuations of $(x-y\theta)\mathcal{O}_K$ at two prime ideals $\mathfrak{p}_1$ and $\mathfrak{p}_2$ above $p$. Of course if $\mathfrak{p}_1 \mid (x-y\theta)\mathcal{O}_K$, we restrict the possible values for $x$ and $y$ modulo $p$. However any choice of $x$ and $y$ modulo $p$ affects the valuations of $(x-y\theta)\mathcal{O}_K$ at all prime ideals above $p$. In the present refinement outlined by Lemma~\ref{lem:AffinePatch1} and Lemma~\ref{lem:AffinePatch2}, we instead study the valuations of $(x-y\theta)\mathcal{O}_K$ at all prime ideals above $p$ simultaneously. This presents us with considerably less ideal equations of the form \eqref{eq:idealTM} to resolve.

Moreover, this variant of the Prime Ideal Removing Lemma permits the following additional refinements:
\begin{itemize}
\item Let $\mathfrak{b} \in L_p$. If there exists a pair $(\mathfrak{b}^\prime,\mathfrak{p}) \in M_p$ with $\mathfrak{b}^\prime \mid \mathfrak{b}$ and $\mathfrak{b}/\mathfrak{b}^\prime=\mathfrak{p}^w$
for some $w \ge 0$, then we may delete $\mathfrak{b}$ from $L_p$. In doing so, the conclusion to Lemma~\ref{lem:AffinePatch2Check} continues to hold.
\item Suppose $(\mathfrak{b},\mathfrak{p})$, $(\mathfrak{b}^\prime,\mathfrak{p}) \in M_p$ with $\mathfrak{b}^{\prime} \mid \mathfrak{b}$, and $\mathfrak{b}/\mathfrak{b}^{\prime}=\mathfrak{p}^w$ for some ${w \geq 0}$. Then, we may delete $(\mathfrak{b},\mathfrak{p})$ from $M_p$ without affecting the conclusion to Lemma~\ref{lem:AffinePatch2Check}.
\end{itemize}

%---------------------------------------------------------------------------------------------%

\section{Factorization of the Thue-Mahler equation}
\label{sec:FactorizationTM}

After applying Algorithm~\ref{alg:AffinePatch1} and Algorithm~\ref{alg:AffinePatch2}, we are reduced to solving finitely many ideal equations of the form
\begin{equation}\label{eq:TMfactored}
(x-y\theta)\mathcal{O}_K=\mathfrak{a} \mathfrak{p}_1^{u_1}\cdots \mathfrak{p}_{\nu}^{u_{\nu}}
\end{equation}
in integer variables $x,y,u_1, \dots, u_{\nu}$ with $u_i \geq 0$ for $i = 1, \dots, \nu$, where ${0 \leq \nu \leq v}$. Here
\begin{itemize}
\item for $i \in \{1, \dots, \nu\}$, $\mathfrak{p}_i$ is a prime ideal of $\mathcal{O}_K$ arising from Algorithm~\ref{alg:AffinePatch1} and Algorithm~\ref{alg:AffinePatch2} applied to $p \in \{p_1, \dots, p_v\}$, such that $(\mathfrak{b}, \mathfrak{p}_i) \in M_p$ for some ideal $\mathfrak{b}$;
\item for $i \in \{\nu+1, \dots, v\}$, the corresponding rational prime $p_i \in S$ yields $M_{p_i} = \emptyset$, in which case we set $u_i = 0$;
\item $\mathfrak{a}$ is an ideal of $\mathcal{O}_K$ of norm $|c|\cdot p_1^{t_1} \cdots p_v^{t_v}$ such that
$u_i + t_i =  z_i$.
\end{itemize}

For each choice of $\mathfrak{a}$ and prime ideals $\mathfrak{p}_1, \dots, \mathfrak{p}_{\nu}$, we reduce equation~\eqref{eq:TMfactored} to a number of so-called ``$S$-unit equations''. We present two different algorithms for doing so and outline the advantages and disadvantages of each. In practicality, we do not know a priori which of these two options is more efficient. Instead, we implement and use both algorithms simultaneously and selecting the most computationally efficient option as it appear.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %

\subsection{Avoiding the class group $\text{Cl}(K)$}
\label{subsec:FactorizationTMwithoutOK}

For $i = 1, \dots, {\nu}$ let $h_i$ be the smallest positive integer for which $\mathfrak{p}_i^{h_i}$ is principal and let
$r_i$ be a positive integer satisfying $0 \leq r_i < h_i$. Let
\[\mathbf{a}_i = (a_{1i}, \dots, a_{{\nu}i}).\]
where $a_{ii} = h_i$ and $a_{ji} = 0$ for $j \neq i$. We let $A$ be the matrix with columns $\mathbf{a}_1, \dots, \mathbf{a}_{\nu}$. Hence $A$ is a $\nu \times \nu$ diagonal matrix over $\mathbb{Z}$ with diagonal entries $h_i$. Now, if \eqref{eq:TMfactored} has a solution $\mathbf{u} = (u_1, \dots, u_{\nu})$, it necessarily must be of the form $\mathbf{u} = A\mathbf{n} + \mathbf{r}$, where $\mathbf{n} = (n_1, \dots, n_{\nu})$ and $\mathbf{r} = (r_1, \dots, r_{\nu})$. The vector $\mathbf{n}$ is comprised of integers $n_i$ which we solve for. The vector $\mathbf{r}$ is comprised of the values $r_i$ satisfying $0 \leq r_i < h_i$ for $i = 1, \dots, \nu$.

Using the above notation, we let
\[\mathfrak{c}_i = \tilde{\mathfrak{p}}^{\mathbf{a}_i}=\mathfrak{p}_1^{a_{1i}}\cdot \mathfrak{p}_2^{a_{2i}} \cdots \mathfrak{p}_{\nu}^{a_{{\nu}i}} = \mathfrak{p}_i^{h_i} \]
for all $i \in \{1, \dots, {\nu}\}$.

Thus, we can write \eqref{eq:TMfactored} as
\[ (x-y\theta) \mathcal{O}_K = \mathfrak{a} \tilde{\mathfrak{p}}^{\mathbf{u}}  = (\mathfrak{a} \cdot \tilde{\mathfrak{p}}^\mathbf{r}) \cdot \mathfrak{c}_1^{n_1}\cdots \mathfrak{c}_{\nu}^{n_{\nu}}.\]

By definition of $h_i$, each $i \in \{1, \dots, {\nu}\}$ yields an element $\gamma_i \in K^*$ such that
\[\mathfrak{c}_i = (\gamma_i) \mathcal{O}_K.\]
Furthermore, if $\mathbf{u}$ is a solution of \eqref{eq:TMfactored} with corresponding vectors $\mathbf{n}, \mathbf{r}$, there exists some $\alpha \in K^*$ such that
\[\mathfrak{a} \cdot \tilde{\mathfrak{p}}^\mathbf{r}= (\alpha)\mathcal{O}_K.\]

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %

\subsection{Using the class group $\text{Cl}(K)$}
\label{subsec:FactorizationTMwithOK}

Let $\mathbf{u}=(u_1,\dots, u_{\nu})$ be a solution of \eqref{eq:TMfactored} and consider the map
\[\phi : \mathbb{Z}^{\nu} \rightarrow \text{Cl}(K), \qquad (x_1,\dots ,x_{\nu}) \mapsto [\mathfrak{p}_1]^{x_1}\cdots [\mathfrak{p}_{\nu}]^{x_{\nu}},\]
where $[ \mathfrak{q} ]$ denotes the equivalence class of the fractional ideal $\mathfrak{q}$.
Since the product of $\mathfrak{a}$ and $\mathfrak{p}_1^{u_1}\cdots \mathfrak{p}_{\nu}^{u_{\nu}}$ defines a principal ideal, the map $\phi$ implies
\[\phi(\mathbf{u})=[\mathfrak{a}]^{-1}.\]
In particular, if $[\mathfrak{a}]^{-1}$ does not belong to the image of $\phi$ then \eqref{eq:TMfactored} has no solutions. We therefore suppose that $[\mathfrak{a}]^{-1}$ belongs to the image. Let $\mathbf{r}=(r_1,\dotsc,r_{\nu})$ denote a preimage of $[\mathfrak{a}]^{-1}$ and observe that $\mathbf{u} - \mathbf{r}$ belongs to the kernel of $\phi$. The kernel is a subgroup of $\mathbb{Z}^v$ of rank $\nu$. Let $\mathbf{a}_1,\dots,\mathbf{a}_{\nu}$ be a basis for the kernel, where
\[\mathbf{a}_i = (a_{1i}, \dots, a_{\nu i}) \quad \text{ for } i = 1, \dots, \nu.\]
Let
\[\mathbf{u}-\mathbf{r}=n_1 \mathbf{a}_1+\cdots + n_{\nu} \mathbf{a}_{\nu}\]
for some integers $n_i \in \mathbb{Z}$ and let $A$ denote the $\nu \times \nu$ matrix over $\mathbb{Z}$ with columns $\mathbf{a}_1,\dots,\mathbf{a}_{\nu}$. It follows that $\mathbf{u}= A\mathbf{n}+\mathbf{r}$ where $\mathbf{n} = (n_1,\dots,n_{\nu})$.

For $\mathbf{a}_i=(a_{1i},\dotsc,a_{\nu i}) \in \mathbb{Z}^{\nu}$, we adopt the notation
\[\tilde{\mathfrak{p}}^\mathbf{a} :=\mathfrak{p}_1^{a_{1i}}\cdot \mathfrak{p}_2^{a_{2i}} \cdots \mathfrak{p}_{\nu}^{a_{\nu i}}.\]
Let
\[\mathfrak{c}_1= \tilde{\mathfrak{p}}^{\mathbf{a}_1},\dotsc,\mathfrak{c}_{\nu}= \tilde{\mathfrak{p}}^{\mathbf{a}_{\nu}}.\]
Thus, we can rewrite \eqref{eq:TMfactored} as
\[(x-y\theta) \mathcal{O}_K = \mathfrak{a} \tilde{\mathfrak{p}}^{\mathbf{u}} = (\mathfrak{a} \cdot \tilde{\mathfrak{p}}^\mathbf{r}) \cdot \mathfrak{c}_1^{n_1}\cdots \mathfrak{c}_{\nu}^{n_{\nu}}.\]

Consider the ideal equivalence class of $(\mathfrak{a} \cdot \tilde{\mathfrak{p}}^\mathbf{r})$ in $\Cl(K)$ and note that
\[[\mathfrak{a} \cdot \tilde{\mathfrak{p}}^\mathbf{r}]
	= [\mathfrak{a}] \cdot [\mathfrak{p}_1]^{r_1}\cdots [\mathfrak{p}_{\nu}]^{r_{\nu}}
	= [\mathfrak{a}]\cdot \phi(r_1,\dotsc,r_{\nu})=[1]\]
as $\phi(r_1,\dotsc,r_{\nu})=[\mathfrak{a}]^{-1}$ by construction. This means
\[\mathfrak{a} \cdot \tilde{\mathfrak{p}}^\mathbf{r}= (\alpha) \mathcal{O}_K\]
for some $\alpha \in K^*$. Furthermore,
\[[\mathfrak{c}_i] = [\tilde{\mathfrak{p}}^{\mathbf{a}_i}] = \phi(\mathbf{a}_i) = [1] \quad \text{ for } i = 1, \dots, \nu,\]
as the $\mathbf{a}_i$ are a basis for the kernel of $\phi$. For all $i \in \{1, \dots, {\nu}\}$, we therefore have
\[\mathfrak{c}_i= (\gamma_i) \mathcal{O}_K\]
for some $\gamma_i \in K^*$.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %

\subsection{The $S$-unit equation}
\label{subsec:SUnitEquation}

\autoref{subsec:FactorizationTMwithoutOK} and  \autoref{subsec:FactorizationTMwithOK} outline two different algorithms to reduce the ideal equation~\eqref{eq:TMfactored} to a number of certain ``$S$-unit equations'', which we define shortly. Regardless of which method we use, under both algorithms outlined above, equation~\eqref{eq:TMfactored} becomes
\begin{equation} \label{eq:TMprincipal}
(x-y\theta) \mathcal{O}_K= (\alpha \cdot \gamma_1^{n_1} \cdots \gamma_{\nu}^{n_{\nu}}) \mathcal{O}_K
\end{equation}
for some vector $\mathbf{n} = (n_1, \dots, n_{\nu}) \in \mathbb{Z}^{\nu}$. The ideal generated by $\alpha$ in $K$ has norm
\[|c|\cdot p_1^{t_1 + r_1} \cdots p_{\nu}^{t_{\nu} + r_{\nu}}p_{\nu +1}^{t_{\nu +1}} \cdots p_v^{t_v}\]
and the $n_i$ are related to the $z_i$ via
\[z_i = u_i + t_i = \sum_{j = 1}^{\nu}n_ja_{ij} + r_i + t_i \quad \text{ for } i =1, \dots, v.\]
where $u_i = r_i = 0$ for all $i \in \{\nu + 1, \dots, v\}$.

Fix a complete set of fundamental units $\{\eps_1, \dots, \eps_r\}$ of $\mathcal{O}_K$. Here $r = s + t -1$, where $s$ denotes the number of real embeddings of $K$ into $\mathbb{C}$ and $t$ denotes the number of complex conjugate pairs of non-real embeddings of $K$ into $\mathbb{C}$. Then, under either method, equation~\eqref{eq:TMfactored} reduces to a finite number of equations in $K$ of the form
\begin{equation} \label{eq:TMinK}
x-y\theta = \alpha \zeta \varepsilon_1^{a_1} \cdots \varepsilon_r^{a_r}\gamma_1^{n_1}\cdots \gamma_{\nu}^{n_{\nu}}
\end{equation}
with unknowns $a_i \in \mathbb{Z}$, $n_i \in \mathbb{Z}$, and $\zeta$ in the set $T$ of roots of unity in $\mathcal{O}_K$. Since $T$ is finite, we treat $\zeta$ as another parameter.

Let $p \in \{p_1, \dots, p_v, \infty\}$. Recall that $g(t)$ is an irreducible polynomial in $\mathbb{Z}[t]$ arising from \eqref{eq:ThueMahler3} such that
\[g(t) = f(t,1) = t^n + C_1 t^{n-1} + \dots + C_{n-1}t + C_n.\]
Denote the roots of $g(t)$ in $\overline{\mathbb{Q}_p}$ (where $\overline{\mathbb{Q}_{\infty}} = \overline{\mathbb{R}} = \mathbb{C}$) by $\theta^{(1)}, \dots, \theta^{(n)}$. Let $i_0, j, k \in \{1,\dots, n\}$ be distinct indices and consider the three embeddings of $K$ into $\overline{\mathbb{Q}_p}$ defined by $\theta \mapsto \theta^{(i_0)}, \theta^{(j)}, \theta^{(k)}$. We use $z^{(i)}$ to denote the image of $z$ under the embedding $\theta \mapsto \theta^{(i)}$. From the Siegel identity
\[(\theta^{(i_0)} - \theta^{(j)})(x-y\theta^{(k)}) + (\theta^{(j)} - \theta^{(k)})(x-y\theta^{(i_0)}) + (\theta^{(k)} - \theta^{(i_0)})(x-y\theta^{(j)}) = 0,\]
applying the embeddings to $\beta = x-y\theta$ yields the so-called ``$S$-unit equation''
\begin{equation} \label{eq:Sunit}
\delta_1 \prod_{i = 1}^r\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right)^{a_i}\prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)^{n_i} - 1 = \delta_2 \prod_{i = 1}^{r}\left( \frac{\varepsilon_i^{(i_0)}}{\varepsilon_i^{(j)}}\right)^{a_i} \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(i_0)}}{\gamma_i^{(j)}}\right)^{n_i},
\end{equation}
where
\[\delta_1 = \frac{\theta^{(i_0)} - \theta^{(j)}}{\theta^{(i_0)} - \theta^{(k)}}\cdot\frac{\alpha^{(k)}\zeta^{(k)}}{\alpha^{(j)}\zeta^{(j)}}, \quad \delta_2 = \frac{\theta^{(j)} - \theta^{(k)}}{\theta^{(k)} - \theta^{(i_0)}}\cdot \frac{\alpha^{(i_0)}\zeta^{(i_0)}}{\alpha^{(j)}\zeta^{(j)}}\]
are constants.

To summarize, our original problem of solving \eqref{eq:ThueMahler3} for $(x,y,z_1,\dots, z_v)$ has been reduced to solving finitely many equations of the form \eqref{eq:Sunit} for the variables $( n_1, \dots, n_{\nu},a_1,\dots,a_r)$.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %

\subsection{Computational remarks and comparisons}
\label{subsec:FactorizationRemarks}

In \autoref{subsec:FactorizationTMwithoutOK}, we follow closely the method of \cite{TW3} to reduce the ideal equation~\eqref{eq:TMfactored} to the $S$-unit equation~\eqref{eq:Sunit}. To implement this reduction, we begin by computing all $h_i$ for which $\mathfrak{p}_i^{h_i}$ is principal for $i = 1, \dots, \nu$. In doing so, we generate all possible values for $r_i$, the non-negative integer satisfying $0 \leq r_i < h_i$. We then generate every possible vector $\mathbf{r} = (r_1, \dots, r_{\nu})$ and test the corresponding ideal product $\mathfrak{a} \cdot \tilde{\mathfrak{p}}^{\mathbf{r}}$ for principality. Those vectors which pass this test yield an $S$-unit equation~\eqref{eq:Sunit}. In the worst case scenario, this method reduces to $h_K^{\nu}$ such equations, where $h_K$ is the class number of $K$. Moreover, this process needs to be applied to every ideal equation~\eqref{eq:TMfactored}, yielding what may be a very large number of principalization tests and subsequent large number of $S$-unit equations to solve.

In contrast, the method in \autoref{subsec:FactorizationTMwithOK} reduces \eqref{eq:TMfactored} to only $\#T/2$ $S$-unit equations to solve, where $T$ is the set of roots of unity in $K$. In particular, the sum total of $S$-unit equations does not drastically increase. If $[\mathbf{a}]^{-1}$ is not in the image of $\phi$, we reach a contradiction. If $[\mathbf{a}]^{-1}$ is in the image of $\phi$ then we obtain only $\#T/2$ corresponding equations \eqref{eq:Sunit}. In particular, the number of principalization tests in this method is limited by the number of ideal equations~\eqref{eq:TMfactored}, where each such equation yields only $(1+\nu)$ tests.

However, when generating the vectors $\mathbf{r} = (r_1, \dots, r_{\nu})$ using the class group, we observe that some of the integers $r_i$ may be negative, so we do not expect $\alpha$ to be an algebraic integer in general. This can be problematic later in the algorithm when we compute the embedding of $K$ into our $p$-adic fields. In those instances, the precision on our $p$-adic fields may not be high enough, and as a result, some non-zero elements of $K$ may be erroneously mapped to $0$. To avoid this, we force the $r_i$ to be positive by adding sufficiently many multiples of the class number.

In most cases, the method described in \autoref{subsec:FactorizationTMwithOK} is far more efficient than that of \autoref{subsec:FactorizationTMwithoutOK}. However, computing the class group may be a very costly computation. Indeed, for some Thue-Mahler equations, this may be the bottle-neck of the algorithm. In this case, it may happen that computing the class group will take longer than directly checking each potential $S$-unit equation arising from the alternative method. Unfortunately, we cannot know a priori how long computing $\Cl(K)$ will take in so much that we cannot know a priori how long solving all $S$-unit equations from the other algorithm will take. In practicality, generating the class group in Magma is a process which cannot be terminated without exiting the program. For this reason, we cannot simply apply a timeout in Magma if computing $\Cl(K)$ is exceeding what we deem a reasonable amount of time. Adding to this, Magma does not support parallelization, so we cannot implement both algorithms simultaneously. Our compromise to solve a single Thue-Mahler equation is to run two separate instances of Magma in parallel, each generating the $S$-unit equations using the two aforementioned algorithms. When one of these instances finishes, the other is forced to terminate. In this way, though far from ideal, we are able to select the most computationally efficient option.

%---------------------------------------------------------------------------------------------%

\section{A small upper bound for $u_l$ in a special case}
\label{sec:SmallBoundForSpecialCase}

We now restrict our attention to those $p \in \{p_1, \dots, p_{\nu}\}$ and study the $p$-adic valuations of the numbers appearing in \eqref{eq:Sunit}. In particular, for $l \in \{1, \dots, \nu\}$, we identify conditions in which $\sum_{j = 1}^{\nu} n_ja_{lj}$ can be bounded by a small explicit constant, where $a_{lj}$ is the $(l,j)^{\text{th}}$ entry of the matrix $A$ derived in either \autoref{subsec:FactorizationTMwithoutOK} or \autoref{subsec:FactorizationTMwithOK}. Recall that $u_l + r_l = \sum_{j = 1}^{\nu} n_ja_{lj}$, where $r_l$ is known, so that a bound on $\sum_{j = 1}^{\nu} n_ja_{lj}$ yields a bound on the exponent $u_l$ in \eqref{eq:TMfactored}.

Fix a rational prime $p_l \in \{p_1, \dots, p_{\nu}\}$ and recall that $z \in \mathbb{C}_{p_l}$ having $\ord_{p_l}(z) = 0$ is called a $p_l$-adic unit. Part (i) of the Corollary of Lemma 7.2 of \cite{TW3} tells us that $\frac{\eps_1^{(i_0)}}{\varepsilon_1^{(j)}}, \dots, \frac{\eps_r^{(i_0)}}{\varepsilon_r^{(j)}}$ and $\frac{\varepsilon_1^{(k)}}{\varepsilon_1^{(j)}}, \dots, \frac{\varepsilon_r^{(k)}}{\varepsilon_r^{(j)}}$ are $p_l$-adic units.

Let $g_l(t)$ be the irreducible factor of $g(t)$ in $\mathbb{Q}_{p_l}[t]$ corresponding to the prime ideal $\mathfrak{p}_l$. Since $\mathfrak{p}_l$ has ramification index and residue degree equal to $1$, $\deg(g_l(t)) = 1$. We now choose $i_0 \in \{1, \dots, 4\}$ so that $\theta^{(i_0)}$ is the root of $g_l(t)$. We fix this choice of index $i_0$ for the remainder of this chapter. The indices of $j,k$ are fixed, but arbitrary.

\begin{lemma} \label{lem:SunitUnits} \
\begin{enumerate}
\item[(i)] Let $i \in \{1, \dots, \nu\}$. Then $\frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}$ are $p_l$-adic units.
\item[(ii)] Let $i \in \{1, \dots, \nu\}$. Then $\ord_{p_l}\left(\frac{\gamma_i^{(i_0)}}{\gamma_i^{(j)}}\right) = a_{li}$, where $\mathbf{a_i} = (a_{1i}, \dots, a_{vi})$ is the $i^{\text{th}}$ column of the matrix $A$ of either \autoref{subsec:FactorizationTMwithoutOK} or \autoref{subsec:FactorizationTMwithOK}.
\end{enumerate}
\end{lemma}

\begin{proof}
Consider the factorization $g(t) = g_1(t) \cdots g_m(t)$ of $g(t)$ in $\mathbb{Q}_{p_l}[t]$. Note that $\theta^{(j)}$ is a root of some $g_h(t) \neq g_l(t)$. Let $\mathfrak{p}_h$ be the corresponding prime ideal above $p_l$ and $e(\mathfrak{p}_h|p_l)$ be its ramification index. Then $\mathfrak{p} \neq \mathfrak{p}_l$ and since
\[(\gamma_i)\mathcal{O}_K = \mathfrak{p}_1^{a_{1i}} \cdots \mathfrak{p}_v^{a_{vi}},\]
we have
\[\ord_{p_l}(\gamma_i^{(j)}) = \frac{1}{e(\mathfrak{p}_h|p_l)}\ord_{\mathfrak{p}_h}(\gamma_i) = 0.\]
An analogous argument gives $\ord_{p_l}(\gamma_i^{(k)}) = 0$. On the other hand,
\[\ord_{p_l}(\gamma_i^{(i_0)}) = \frac{1}{e(\mathfrak{p}_l|p_l)}\ord_{\mathfrak{p}_l}(\gamma_i) = \ord_{\mathfrak{p}_l}(\mathfrak{p}_1^{a_{1i}} \cdots \mathfrak{p}_v^{a_{vi}}) = a_{li}.\]
\end{proof}

The next lemma deals with a special case in which the sum $\sum_{j = 1}^{\nu} n_ja_{lj}$ can be computed directly. This lemma is analogous to Lemma 7.3 of \cite{TW3}.

Recall the constants
\[\delta_1 = \frac{\theta^{(i_0)} - \theta^{(j)}}{\theta^{(i_0)} - \theta^{(k)}}\cdot\frac{\alpha^{(k)}\zeta^{(k)}}{\alpha^{(j)}\zeta^{(j)}}, \quad \delta_2 = \frac{\theta^{(j)} - \theta^{(k)}}{\theta^{(k)} - \theta^{(i_0)}}\cdot \frac{\alpha^{(i_0)}\zeta^{(i_0)}}{\alpha^{(j)}\zeta^{(j)}}\]
of \eqref{eq:Sunit}.
\begin{lemma}\label{lem:Delta1}
Let $l \in \{1, \dots, v\}$. If $\ord_{p_l}(\delta_1) \neq 0$, then
\[ \sum_{i = 1}^{\nu} n_ia_{li} = \min\{\ord_{p_l}(\delta_1), 0\} - \ord_{p_l}(\delta_2).\]
\end{lemma}

\begin{proof}
Apply the Corollary of Lemma $7.2$ of \cite{TW3} and Lemma~\ref{lem:SunitUnits} to both expressions of $\lambda$ in \eqref{eq:Sunit}. On the one hand, we obtain that
\[\ord_{p_l}(\lambda) = \min\{\ord_{p_l}(\delta_1), 0\},\]
and on the other hand,
\begin{align*}
\ord_{p_l}(\lambda)
& = \ord_{p_l}(\delta_2) + \sum_{i = 1}^{\nu} \ord_{p_l}\left( \frac{\gamma_i^{(i_0)}}{\gamma_i^{(j)}}\right)^{n_i}\\
& = \ord_{p_l}(\delta_2) + \sum_{i = 1}^{\nu} n_ia_{li}.
\end{align*}
\end{proof}

For the remainder of this section, we assume $\ord_{p_l}(\delta_1) = 0$. Here, it is convenient to use the notation
\[b_1 = 1, \quad b_{1+i} = n_i \ \text{ for } i \in \{1, \dots, \nu\},\]
and
\[ b_{1+{\nu}+i} = a_i \ \text{ for } i  \in \{1, \dots, r\}.\]
Put
\[\alpha_1 = \log_{p_l} \delta_1, \quad \alpha_{1+i} = \log_{p_l}\left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)  \ \text{ for } i \in \{1, \dots, \nu\},\]
and
\[\alpha_{1+\nu+i} = \log_{p_l}\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right) \ \text{ for } i  \in \{1, \dots, r\}.\]
Define
\[\Lambda_l = \sum_{i = 1}^{1+\nu+r} b_i\alpha_i.\]

Let $L$ be a finite extension of $\mathbb{Q}_{p_l}$ containing $\delta_1$, $\frac{\gamma_1^{(k)}}{\gamma_1^{(j)}}, \dots, \frac{\gamma_{\nu}^{(k)}}{\gamma_{\nu}^{(j)}}$, and $\frac{\varepsilon_1^{(k)}}{\varepsilon_1^{(j)}}, \dots, \frac{\varepsilon_r^{(k)}}{\varepsilon_r^{(j)}}$. Since finite $p_l$-adic fields are complete, $\alpha_i \in L$ for $i = 1, \dots, 1+\nu+r$ as well. Choose $\phi \in \overline{\mathbb{Q}_{p_l}}$ such that $L = \mathbb{Q}_{p_l}(\phi)$ and $\ord_{p_l}(\phi) > 0 $. Let $G(t)$ be the minimal polynomial of $\phi$ over $\mathbb{Q}_{p_l}$ and let $s$ be its degree. For $i = 1, \dots, 1+\nu+r$ write
\[\alpha_i = \sum_{h = 1}^s \alpha_{ih}\phi^{h - 1}, \quad \alpha_{ih} \in \mathbb{Q}_{p_l}.\]
Then
\begin{equation} \label{eq:LambdaL}
\Lambda_l = \sum_{h = 1}^s \Lambda_{lh}\phi^{h-1},
\end{equation}
with
\[\Lambda_{lh} = \sum_{i = 1}^{1+\nu+r} b_i \alpha_{ih}\]
for $h = 1, \dots, s$.

\begin{lemma}\label{lem:DiscG}
For every $h \in \{1, \dots, s\}$, we have
\[\ord_{p_l}(\Lambda_{lh}) > \ord_{p_l}(\Lambda_l) - \frac{1}{2}\ord_{p_l}(\text{Disc}(G(t))).\]
\end{lemma}

\begin{proof}
For $h = 1, \dots, s$, taking the images of \eqref{eq:LambdaL} under conjugation $\phi \mapsto \phi^{(h)}$ yields
\[\begin{bmatrix}
\Lambda_l^{(1)} \\
\vdots \\
\Lambda_l^{(s)}	\\
\end{bmatrix}
=
\begin{bmatrix}
1 		& \phi^{(1)} 	& \cdots 	& \phi^{(1)s-1}\\
\vdots 	& \vdots 		& 		& \vdots \\
1 		& \phi^{(s)} 	& \cdots  	& \phi^{(s)s-1}\\
\end{bmatrix}
\begin{bmatrix}
\Lambda_{l1}\\
\vdots \\
\Lambda_{ls}\\
\end{bmatrix}.\]
The $s \times s$ matrix $(\phi^{(h)i-1})$ above is invertible, with inverse
\[\frac{1}{\displaystyle \prod_{1\leq j<k\leq s} (\phi^{(k)} - \phi^{(j)})}
\begin{bmatrix}
\gamma_{11} 	& \cdots 	& \gamma_{1s}\\
\vdots 		& 		& \vdots\\
\gamma_{s1} 	& \cdots 	& \gamma_{ss}\\
\end{bmatrix},\]
where $\gamma_{jk}$ is an integral polynomial in the entries of $(\phi^{(h)i-1})$. As $\ord_{p_l}(\phi) > 0$ and $\ord_{p_l}(\phi^{(h)}) = \ord_{p_l}(\phi)$ for all $h = 1, \dots, s$, it follows that $\ord_{p_l}(\gamma_{jk}) > 0 $ for every $\gamma_{jk}$. Therefore, as
\[\Lambda_{lh} = \frac{1}{\displaystyle \prod_{1\leq j<k\leq s}(\phi^{(k)} - \phi^{(j)})}\sum_{i = 1}^s \gamma_{hi}\Lambda_l^{(i)},\]
we have
\begin{align*}
\ord_{p_l}(\Lambda_{lh})
	& = \min_{1 \leq i \leq s} \left\{\ord_{p_l}(\gamma_{hi}) + \ord_{p_l}(\Lambda_l^{(i)})\right\} -\frac{1}{2}\ord_{p_l}(\text{Disc}(G(t)))\\
	& \geq \min_{1 \leq i \leq s} \ord_{p_l}(\Lambda_l^{(i)}) +  \min_{1 \leq i \leq s} \ord_{p_l}(\gamma_{hi}) - \frac{1}{2}\ord_{p_l}(\text{Disc}(G(t)))\\
	& = \ord_{p_l}\Lambda_l + \min_{1 \leq i \leq s} \ord_{p_l}(\gamma_{hi}) - \frac{1}{2}\ord_{p_l}(\text{Disc}(G(t)))
\end{align*}
for every $h \in \{1, \dots, s\}$.
%\min_{1 \leq i \leq s} \left\{\ord_{p_l}(\gamma_{hi}) + \ord_{p_l}(\Lambda_l^{(i)}) -\frac{1}{2}\ord_{p_l}(\text{Disc}(G(t)))\right\}\]
\end{proof}

\begin{lemma} \label{lem:Lambda}
If
\[\sum_{i = 1}^{\nu} n_{i}a_{li} > \frac{1}{p_l-1} - \ord_{p_l}(\delta_2),\]
then
\[\ord_{p_l}(\Lambda_l) = \sum_{i = 1}^{\nu} n_{i}a_{li} + \ord_{p_l}(\delta_2).\]
\end{lemma}

\begin{proof}
Immediate from Lemma~\ref{lem:pAdicLogarithms2}.
\end{proof}

\begin{lemma} \label{lem:specialcase} \
Let
\[w_l = \bigg\lfloor{\frac{1}{p_l-1} - \ord_{p_l}(\delta_2)}\bigg\rfloor.\]
\begin{enumerate}[(i)]
\item If $\ord_{p_l}(\alpha_1) < \displaystyle \min_{2 \leq i \leq 1+\nu+r} \ord_{p_l}(\alpha_i)$, then
\begin{align*}
\sum_{i = 1}^{\nu} n_i a_{li} \leq \max \left\{ w_l,  \bigg \lceil\displaystyle \min_{2 \leq i \leq 1+\nu+r} \ord_{p_l}(\alpha_{i}) - \ord_{p_l}(\delta_2) \bigg \rceil - 1 \right\}
\end{align*}

\item For all $h \in \{1, \dots, s\}$, if $\ord_{p_l}(\alpha_{1h}) < \displaystyle \min_{2 \leq i \leq 1+\nu+r} \ord_{p_l}(\alpha_{ih})$, then
\[\sum_{i = 1}^{\nu} n_i a_{li} \leq \max \left\{w_l, \bigg \lceil \displaystyle \min_{2 \leq i \leq 1+\nu+r} \ord_{p_l}(\alpha_{ih})- \ord_{p_l}(\delta_2) + d_l \bigg \rceil - 1\right\},\]
where
\[d_l = \frac{1}{2}\ord_{p_l}(\text{Disc}(G(t))).\]
\end{enumerate}
\end{lemma}

\begin{proof} \
\begin{enumerate}[(i)]
\item We prove the contrapositive. Suppose
\[\sum_{i = 1}^{\nu} n_i a_{li} > \frac{1}{p_l-1} - \ord_{p_l}(\delta_2), \]
and
\[\sum_{i = 1}^{\nu} n_i a_{li}  \geq \displaystyle \min_{2 \leq i \leq 1+\nu+r} \ord_{p_l}(\alpha_{i}) - \ord_{p_l}(\delta_2).\]
Observe that
\begin{align*}
\ord_{p_l}(\alpha_{1})
	& = \ord_{p_l}\left( \Lambda_{l} - \sum_{i = 2}^{1+\nu+r}b_i\alpha_{i}\right) \\
	& \geq \min\left\{ \ord_{p_l}(\Lambda_{l}), \min_{2 \leq i \leq 1+\nu+r} \ord_{p_l}(b_i\alpha_{i})\right\}.
\end{align*}
Therefore, it suffices to show that
\[\ord_{p_l}(\Lambda_{l}) \geq \min_{2 \leq i \leq 1+\nu+r} \ord_{p_l}(b_i\alpha_{i}).\]
By Lemma~\ref{lem:pAdicLogarithms2}, the first inequality implies
\[{\ord_{p_l}(\Lambda_{l}) = \displaystyle \sum_{i = 1}^{\nu} n_ia_{li} + \ord_{p_l}(\delta_2)},\]
from which the result follows.

\item Similar to the proof of (i).
%\item[(ii)] We prove the contrapositive. Let $h \in \{1, \dots, s\}$ and suppose
%\[\sum_{i = 1}^v n_i a_{li} > \frac{1}{p-1} - \ord_{p_l}(\delta_2), \]
%and
%\[\sum_{i = 1}^v n_i a_{li}  \geq \nu_l + \displaystyle \min_{2 \leq i \leq v+2} \ord_{p_l}(\alpha_{ih}) - \ord_{p_l}(\delta_2).\]
%Observe that
%\[\begin{split}
%\ord_{p_l}(\alpha_{1h})
%	& = \ord_{p_l}\left( \Lambda_{lh} - \sum_{i = 2}^{v+2}b_i\alpha_{ih}\right) \\
%	& \geq \min\left\{ \ord_{p_l}(\Lambda_{lh}), \min_{2 \leq i \leq v+2} \ord_{p_l}(b_i\alpha_{ih})\right\}
%\end{split}\]
%Therefore, it suffices to show that
%\[\ord_{p_l}(\Lambda_{lh}) \geq \min_{2 \leq i \leq v+2} \ord_{p_l}(b_i\alpha_{ih}).\]
%By Lemma~\ref{Lem:padic}, the first inequality implies $\ord_{p_l}(\Lambda_{l}) = \displaystyle \sum_{i = 1}^v n_ia_{li} + \ord_{p_l}(\delta_2)$. Combining this with Lemma~\ref{Lem:discG} yields
%\[\ord_{p_l}(\Lambda_{lh}) \geq \displaystyle \sum_{i = 1}^v n_ia_{li} + \ord_{p_l}(\delta_2) - \nu_l.\]
%The results now follow from our second assumption.
\end{enumerate}
\end{proof}

%---------------------------------------------------------------------------------------------%

\section{Lattice-Based Reduction}
\label{sec:LatticeReduction}

At this point in solving the Thue-Mahler equation, we proceed to solve each $S$-unit equation~\eqref{eq:Sunit} for the exponents $(n_1, \dots, n_{\nu}, a_1, \dots, a_r)$. To do so, we generate a very large upper bound on the exponents and reduce this bound via Diophantine approximation computations. The specific details of this process are described in \autoref{ch:EfficientTMSolver} and \autoref{ch:Goormaghtigh}. In general, from each $S$-unit equation, we generate several linear forms in logarithms to which we associate an integral lattice $\Gamma$. It will be important in this reduction process to enumerate all short vectors in these lattices. In this section, we describe two algorithms used in the short vector enumeration process.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %

\subsection{The $L^3$-lattice basis reduction algorithm}
\label{subsec:LLL}

Let $\Gamma$ be an $n$-dimensional lattice with basis vectors $\mathbf{b}_1, \dots, \mathbf{b}_n$ equipped with a bilinear form $\Phi: \Gamma \times \Gamma \to \mathbb{Z}$. Recall that $\Phi$ defines a norm on $\Gamma$ via the usual inner product on $\mathbb{R}^n$. For $i = 1, \dots, n$, define the vectors $\mathbf{b}_i^*$ inductively by
\[\mathbf{b}_i^* = \mathbf{b}_i - \sum_{j=1}^{i-1}\mu_{ij}\mathbf{b}_j^*, \quad \mu_{ij} = \frac{\Phi(\mathbf{b}_i,\mathbf{b}_j^*)}{\Phi(\mathbf{b}_j^*,\mathbf{b}_j)},\]
where $\mu_{ij} \in \mathbb{R}$ for $1\leq j < i \leq n$. This is the usual Gram-Schmidt process. The basis $\mathbf{b}_1,\dots, \mathbf{b}_n$ is called \textit{LLL-reduced} if
\[|\mu_{ij}| \leq \frac{1}{2} \quad \text{ for } 1\leq j < i \leq n, \]
\[\frac{3}{4}|\mathbf{b}_{i-1}^*|^2 \leq |\mathbf{b}_i^* + \mu_{ii-1}\mathbf{b}_{i-1}^*|^2 \quad \text{ for } 1 <i \leq n,\]
where $| \cdot |$ is the usual Euclidean norm in $\mathbb{R}^n$,
\[|\mathbf{v}| = \Phi(\mathbf{v},\mathbf{v}) = \mathbf{v}^{T}\mathbf{v}.\]

These properties imply that an LLL-reduced basis is approximately orthogonal, and that, generically, its constituent vectors are roughly of the same length. Every $n$-dimensional lattice has an LLL-reduced basis and such a basis can be computed very quickly using the so-called LLL algorithm (\cite{LLL}). This algorithm takes as input an arbitrary basis for a lattice and outputs an LLL-reduced basis. The algorithm is typically modified to additionally output a unimodular matrix $U$ such that $A = BU$, where $B$ is the matrix whose column-vectors are the input basis and $A$ is the matrix whose column-vectors are the LLL-reduced output basis. Several versions of this algorithm are implemented in Magma, including de Weger's exact integer version. (\cite{Weg0}).

We remark that a lattice may have more than one reduced basis, and that the ordering of the basis vectors is not arbitrary. The properties of reduced bases that are of most interest to us are the following. Let $\mathbf{v}$ a vector in $\mathbb{R}^n$ and denote by $l(\Gamma,\mathbf{v})$ the distance from $\mathbf{v}$ to the nearest point in the lattice $\Gamma$, viz.
\[l(\Gamma,\mathbf{v}) = \min_{\mathbf{u} \in \Gamma \backslash\{\mathbf{v}\}} |\mathbf{u} - \mathbf{v}|.\]
From an LLL-reduced basis for $\Gamma$, we can compute lower bounds for $l(\Gamma,\mathbf{v})$, according to the following results.

\begin{lemma} \label{lem:LLL}
Let $\Gamma$ be a lattice with LLL-reduced basis $\mathbf{c}_1, \dots, \mathbf{c}_n$ and let $\mathbf{v}$ be a vector in $\mathbb{R}^n$.
\begin{enumerate}[(a)]
\item If $\mathbf{v} = \mathbf{0}$, then $l(\Gamma,\mathbf{v}) \geq 2^{-(n-1)/2}|\mathbf{c}_1|$.
\item Assume $\mathbf{v} = s_1\mathbf{c}_1 + \cdots + s_n \mathbf{c}_n$, where $s_1, \dots, s_n \in \mathbb{R}$ with not all $s_i \in \mathbb{Z}$. Put
\[J = \{j \in \{1, \dots, n\} \ : \ s_j \notin \mathbb{Z} \}.\]
For $j \in J$, set
\[\delta(j) =
\begin{cases}
\max_{i > j} \|s_i \| |\mathbf{c}_i| 	& \text{ if } j < n\\
0 							& \text{ if } j = n,
\end{cases}\]
where $\| \cdot \|$ denotes the distance to the nearest integer. We have
\[l(\Gamma,\mathbf{v}) \geq \max_{j \in J}\left(2^{-(n-1)/2}\| s_j\| |\mathbf{c}_1| - (n-j)\delta(j)\right).\]
\end{enumerate}
\end{lemma}
Lemma~\ref{lem:LLL} (a) is Proposition 1.11 in \cite{LLL}; proofs can be found in \cite{LLL}, \cite{Weg0} (Section 3.4), or \cite{Sm} (Section V.3). Lemma~\ref{lem:LLL} (b) is a combination of Lemmas 3.5 and 3.6 in \cite{Weg0}. Note that the assumption in Lemma~\ref{lem:LLL} (b) is equivalent to ${\mathbf{v} \notin \Gamma}$.

We see that the vector $\mathbf{c}_1$ in a reduced basis is, in a very precise sense, not too far from being the shortest non-zero vector of $\Gamma$. As has already been mentioned, what makes this result so valuable is that there is a very simple and efficient algorithm to find a reduced basis in a lattice, namely the LLL algorithm.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %

\subsection{The Fincke-Pohst algorithm}
\label{subsec:FinckePohst}

Sometimes it is not sufficient to have a lower bound for $l(\Gamma,\mathbf{v})$ only. It may be useful to know exactly all vectors $\mathbf{u} \in \Gamma$ such that $|\mathbf{u}|  = \Phi(\mathbf{u}, \mathbf{u}) \leq C$ for a given constant $C$. This can be done efficiently using an algorithm of Fincke-Pohst (cf. \cite{FP}, \cite{Coh1}). A version of this algorithm with some improvements due to Stehl\'e is implemented in Magma. As input this algorithm takes a matrix $B$, whose columns span the lattice $\Gamma$, and a constant $C > 0$. The output is a list of all lattice points $\mathbf{u} \in \Gamma$ with $|\mathbf{u}| \leq C$, apart from $\mathbf{u} = \mathbf{0}$. In this section, we outline the main steps in this algorithm.

We begin by letting $B$ denote the basis matrix associated to the lattice $\Gamma$, with corresponding bilinear form $\Phi$. We call a vector $\mathbf{u} \in \Gamma$ \textit{small} if its norm $\Phi(\mathbf{u}, \mathbf{u})$ is less than a constant $C$. As an element of the lattice, $\mathbf{u} = B\mathbf{x}$ for some coordinate vector $\mathbf{x} \in \mathbb{Z}^n$. Let $Q$ be the quadratic form associated to $\Phi$ and let $A=B^TB$. Now finding the short vectors $\mathbf{u} \in \Gamma$ is equivalent to solving
\begin{equation} \label{eq:ShortVector}
Q(\mathbf{x}) = \mathbf{x}^TA\mathbf{x} \leq C.
\end{equation}

Let $\mathbf{x} = (x_1, \dots, x_n)$. To solve this inequality, we first rearrange the terms of the quadratic form via quadratic completion. Here we assume that $\Gamma$ is positive definite so that every nonzero element of the lattice has a positive norm. With this, we find the Cholesky decomposition $A = R^TR$, where $R$ is an upper triangular matrix, and express $Q$ as
\[ Q(\mathbf{x}) = \sum_{i=1}^n q_{ii}\left( x_i + \sum_{j=i+1}^n q_{ij}x_j\right)^2.\]
The coefficients $q_{ij}$ are defined from $R$ and stored in a matrix $\tilde{Q}$ for convenience. In particular,
\begin{equation} \label{eq:CholeskyCoeffs}
q_{ij} =
\begin{cases}
\frac{r_{ij}}{r_{ii}} & \text{ if } i < j\\
r_{ii}^2 & \text{ if } i = j.
\end{cases}
\end{equation}
Since $R$ is upper triangular, the matrix $\tilde{Q}$ is as well. This yields the following reformulation of \eqref{eq:ShortVector}
\[ \sum_{i=1}^n q_{ii}\left( x_i + \sum_{j=i+1}^n q_{ij}x_j\right)^2 \leq C.\]
From here we observe that the individual term $q_{nn}x_n^2$ must also be less than $C$. Specifically,
\[x_n^2 \leq \frac{C}{q_{nn}}\]
so that $x_n$ is bounded above by $\sqrt{C/q_{nn}}$ and below by $-\sqrt{C/q_{nn}}$. This illustrates the first step in establishing bounds on a specific entry $x_i$. Adding more terms from the outer sum to this sequence, a pattern emerges. Let
\[U_k = \sum_{j = k+1}^n q_{kj}x_j,\]
where $U_n = 0$, and rewrite $Q(\mathbf{x})$ as
\[Q(\mathbf{x}) = \sum_{i=1}^n q_{ii}\left( x_i + \sum_{j=i+1}^n q_{ij}x_j\right)^2 = \sum_{i=1}^n q_{ii}\left( x_i + U_i\right)^2.\]
In general,
\[q_{kk}(x_k + U_k)^2 \leq C - \sum_{i = k+1}^n q_{ii}(x_i + U_i)^2.\]
Let $T_k$ denote the bound on the right-hand side,
\[T_k = C - \sum_{i = k+1}^n q_{ii}(x_i + U_i)^2.\]
We set $T_n = C$ and find each subsequent $T_k$ by subtracting the next term from the outer summand,
\[T_k = T_{k+1} - q_{k+1,k+1}(x_{k+1} + U_{k+1})^2.\]
This yields the upper bound
\[q_{kk}(x_k + U_k)^2 \leq T_k\]
so that $x_k$ is bounded above by $\sqrt{T_k/q_{kk}} - U_k$ and below by ${-\sqrt{T_k/q_{kk}} - U_k}$. In this way, we iteratively enumerate all vectors $\mathbf{x}$ satisfying $Q(\mathbf{x}) \leq C$, beginning with the entry $x_n$ of $\mathbf{x}$ and working down towards $x_1$.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %

\subsection{Computational remarks and translated lattices}
\label{subsec:FinckePohstRemarks}

Recall that the Cholesky decomposition of $A = B^TB$ yields the upper triangular matrix $R$ where $A = R^TR$. It is noted in the \cite{FP} that if we label the columns of $R$ by $\mathbf{r}_i$ and the rows of $R^{-1}$ by $\mathbf{r}'_i$, then
\[x_k^2 = \left( \mathbf{r}'^{\ T}_k \cdot \sum_{i=1}^n x_i \mathbf{r}_i \right)^2 \leq \mathbf{r}'^{\ T}_k \mathbf{r}_k (\mathbf{x}^TR^TR\mathbf{x}) \leq | \mathbf{r}'_k |^2C.\]
To reduce the search space, it is thus beneficial to reduce the rows of $R^{-1}$. Furthermore, rearranging the columns of $R$ so that the shortest column vector is first helps reduce the total running time of the Fincke-Pohst algorithm. In particular, doing so leads to progressively smaller intervals in which $x_k$ may exist.

We express this reduction with a unimodular matrix $V^{-1}$ so that $R_1^{-1} = V^{-1}R^{-1}$. Applying an appropriate permutation matrix $P$, we then reorder the columns of $R_1$. Since $R_1 = RV$, this yields $R_2 = (RV)P$. Finally, we compute the solutions $\mathbf{y}$ to $\mathbf{y}^TR_2^TR_2\mathbf{y}\leq C$ and recover the short vectors $\mathbf{x}$ satisfying the original inequality \eqref{eq:ShortVector} via $\mathbf{x} = VP\mathbf{y}$.

As before, let $\Gamma$ be an $n$-dimensional lattice with basis matrix $B$, quadratic form $\Phi$, and associated bilinear form $Q$. In \autoref{subsec:FinckePohst}, it is noted that an implementation of the Fincke-Pohst algorithm is available in Magma. Unfortunately, this implementation does not support \textit{translated} lattices, a variant of the Fincke-Pohst algorithm which we will need in \autoref{ch:EfficientTMSolver}. By a translated lattice, we mean the discrete subgroup of $\mathbb{R}^n$ of the form
\[\Gamma + \mathbf{w} = \left\{ \sum_{i=1}^n x_i \mathbf{b}_i + \mathbf{w}\ : \ x_i \in \mathbb{Z} \right\},\]
where $\mathbf{b}_1, \dots, \mathbf{b}_n$ form the columns of $B$ and $\mathbf{w} \in \mathbb{R}^n$. In the remainder of this section, we describe how to modify the Fincke-Pohst algorithm and its refinements to support translated lattices.

Analogous to the non-translated case, any embedded vector $\mathbf{u}$ of $\Gamma + \mathbf{w}$ may be expressed as $\mathbf{u} = B\mathbf{x} + \mathbf{w}$ for a corresponding coordinate vector $\mathbf{x}$. In this case, we call the vector $\mathbf{u} \in \Gamma + \mathbf{w}$ \textit{small} if
\begin{equation} \label{eq:TransShortVector}
(\mathbf{x}-\mathbf{c})^TB^TB(\mathbf{x}-\mathbf{c}) \leq C
\end{equation}
for some $C \geq 0$, where $\mathbf{c} = -\mathbf{w}$.

As in the usual short vectors process, we begin by applying Cholesky decomposition to the positive definite matrix $A=B^TB$ to obtain an upper triangular matrix $R$ satisfying $A = R^TR$. We then generate the matrices $R_1, R_2, V,$ and $P$ described earlier in this section. This allows us to write $A = U^TGU$ for a unimodular matrix $U$ and Gram matrix $G$ given by
\[U = P^{-1}V^{-1} \quad \text{ and } \quad G = R_2^TR_2.\]
Thus the inequality~\eqref{eq:TransShortVector} becomes
\begin{equation} \label{eq:TransShortVector2}
(\mathbf{y}-\mathbf{d})^TG(\mathbf{y}-\mathbf{d}) \leq C
\end{equation}
where
\[\mathbf{y} = U\mathbf{x} \quad \text{ and } \quad \mathbf{d} = U\mathbf{c}.\]
To enumerate the vectors $\mathbf{y}$ which satisfy this inequality, we consider the bilinear form $Q$ associated to the lattice $\Gamma$. We express this form as
\[ Q(\mathbf{y}-\mathbf{d}) = \sum_{i=1}^n q_{ii}\left( y_i - d_i + \sum_{j=i+1}^n q_{ij}(y_j - d_j)\right)^2.\]
As in the usual Fincke-Pohst algorithm, the coefficients $q_{ij}$ are defined from the matrix $R$ via equation~\eqref{eq:CholeskyCoeffs}. Let
\[U_k = -d_k + \sum_{j = k+1}^n q_{kj}(y_j - d_j),\]
where $U_n = -d_n$, and rewrite $Q(\mathbf{y}-\mathbf{d})$ as
\[ Q(\mathbf{y}-\mathbf{d}) = \sum_{i=1}^n q_{ii}\left( y_i - d_i + \sum_{j=i+1}^n q_{ij}(y_j - d_j)\right)^2 = \sum_{i=1}^n q_{ii}\left( y_i + U_i\right)^2.\]
From here, we proceed as in the usual Fincke-Pohst algorithm described in \autoref{subsec:FinckePohst}. Once we compute all vectors $\mathbf{y}$ which satisfy \eqref{eq:TransShortVector2}, we recover $\mathbf{x}$ using $\mathbf{x} = U^{-1}\mathbf{y}$.

As a final remark about Fincke-Pohst for translated lattices, it is worth noting that one could use the variant implemented in Magma simply by increasing the dimension of the lattice $\Gamma$ and appropriately redefining the basis vectors $\mathbf{b}_i$. This is highly ill-advised as it increases the search space and subsequent running time of the algorithm.

Generally speaking, the use of Fincke-Pohst in our applications poses one of the main bottlenecks in solving Thue-Mahler and Thue-Mahler-like equations. Specifically, this algorithm often yields upwards of hundreds of millions of short vectors, each one needing to be stored and, in our case, appropriately manipulated. This creates both timing and memory problems, often leading to gigabytes of data usage. Deleting these vectors does not release the memory and, as with the class group function, Magma's built-in Fincke-Pohst process cannot be terminated without exiting the program. The primary advantage of implementing and using our own version of Fincke-Pohst, as described in this section, is therefore the ability to add a fail-stop should the number of vectors found become too large.

%---------------------------------------------------------------------------------------------%
%---------------------------------------------------------------------------------------------%

\chapter{Computing Elliptic Curves over $\mathbb{Q}$}
\label{cha:comp-ellipt-curv}

In the chapter at hand, we outline an algorithm to compute elliptic curves over $\mathbb{Q}$, based upon techniques of solving Thue-Mahler equations. Our aim is to give a straightforward demonstration of the link
between the conductors of the elliptic curves in question and the corresponding equations, and to make the Diophantine approximation problem
that follows as easy to tackle as possible. It is worth noting here that these connections are quite straightforward for primes $p > 3$, but require
careful analysis at the primes $2$ and $3$.
%We will demonstrate our approach for a number of specific conductors and sets $S$, and then focus our main computational efforts on curves with bad reduction at a single prime (i.e. curves of conductor $p$ or $p^2$ for $p$ prime).  In these cases, the computations simplify significantly and we are able to find all curves of prime conductor up to $2 \times 10^9$ ($10^{10}$ in the case of curves of positive discriminant) and conductor $p^2$ for $p \leq 5\times 10^5$. We then extend these computations in the case of conductor $p$,  for prime $p \leq 2 \times 10^{13}$, and conductor $p^2$ for prime $p \leq 10^{10}$. We are not, however, able to guarantee completeness for these extended computations (we will discuss this further in what follows).

%We are in the process of making our data more easily available through the LMFDB\footnote{The $L$-function and modular
%form database, currently accessible at \url{http://www.lmfdb.org/}}. Until this is completed, we invite
%the interested reader to contact the authors.

%---------------------------------------------------------------------------------------------%

\section{Elliptic curves}
\label{sec:elliptic-curves}


Our basic problem is to find a model for each isomorphism class of elliptic curves over $\mathbb{Q}$ with a given
conductor. Let $S=\{ p_1, p_2, \ldots, p_k \}$ where the $p_i$ are distinct primes, and fix a conductor $N= p_1^{\eta_1} \cdots p_k^{\eta_k}$ for
$\eta_i \in \mathbb{N}$.  Any curve of conductor $N$ has a minimal
model
\begin{align*}
E:&\phantom{=} y^2 + a_1 xy + a_3 y = x^3 + a_2 x^2 + a_4 x + a_6
\end{align*}
with the $a_i$ integral and discriminant
\begin{align*}
\Delta_E &= (-1)^\delta p_1^{\gamma_1} \cdots p_k^{\gamma_k},
\end{align*}
where the $\gamma_i$ are positive integers satisfying $\gamma_i \geq \eta_i$, for each $i = 1, 2, \ldots, k$, and $\delta \in \{ 0, 1 \}$.

Writing
$$
b_2 = a_1^2+4a_2, \; \; b_4 = a_1 a_3 + 2 a_4, \; \;
b_6 = a_3^2+4a_6, \; \;
c_4 = b_2^2-24 b_4
$$
and
$$
c_6 = -b_2^3+ 36 b_2 b_4 -216 b_6,
$$
we have
$1728 \Delta_E = c_4^3-c_6^2$ and
$j_E = c_4^3/\Delta_E$.
It follows that
\begin{align} \label{first}
c_6^2 &= c_4^3 + (-1)^{\delta +1} 2^6 \cdot 3^3 \cdot p_1^{\gamma_1} \cdots p_k^{\gamma_k}.
\end{align}
In fact, it is equation~\eqref{first} that lies at the heart of our method (see also Cremona and
Lingham \cite{CrLi} for an approach to the problem that takes as its starting point equation~\eqref{first}, but
subsequently heads in a rather different direction).

Let $\nu_p(x)$ be the largest power of a prime $p$ dividing a nonzero integer $x$. Since our model is minimal, we
may suppose  (via Tate's algorithm; see, for example, Papadopoulos \cite{Pap}) that
$$
\min \{ 3 \nu_p (c_4), 2 \nu_p (c_6) \} < 12 + 12 \nu_p(2) + 6 \nu_p(3),
$$
for each prime $p$, while
$$
\nu_p (N_E) \leq 2 + \nu_p (1728).
$$
For future use, it will be helpful to have a somewhat more precise determination of the possible
values of $\nu_p(c_4)$ and $\nu_p(c_6)$ we encounter. We compile this data from Papadopoulos~\cite{Pap} and
summarize it in Tables~\ref{tab nu2},~\ref{tab nu3} and~\ref{tab nup}.

\begin{table}[h]
$$
\begin{array}{|r|r|r|r|}
\hline
\nu_2 (c_4) & \nu_2 (c_6) & \nu_2 (\Delta_E) & \nu_2 (N)  \\ \hline
0 & 0 & \geq 0  & \min \{ 1, \nu_2 (\Delta_E)  \}  \\
\geq 4 &  3 & 0 & 0  \\
\geq 4 & 5 & 4 & 2, 3 \mbox{ or } 4  \\
\geq 4 & \geq 6 & 6 & 5 \mbox{ or } 6  \\
4 & 6 & 7 & 7  \\
4 & 6 & 8 & 2, 3 \mbox{ or } 4  \\
4 & 6 & 9 &  5   \\
4 & 6 & 10 \mbox{ or } 11 & 3 \mbox{ or } 4   \\
4 & 6 & \geq 12 &  4  \\
5 & 7 & 8 & 7  \\
\geq 6 & 7 & 8 & 2, 3 \mbox{ or } 4  \\
\hline
\end{array}
\quad
\begin{array}{|r|r|r|r|}
\hline
\nu_2 (c_4) & \nu_2 (c_6) & \nu_2 (\Delta_E) & \nu_2 (N)  \\ \hline
 5 & \geq 8 & 9 & 8 \\
  \geq 6 & 8 & 10 & 6 \\
 6 & \geq 9 & 12 & 5 \mbox{ or } 6 \\
 6 & 9 & \geq 14 &  6 \\
 7 & 9 & 12 & 5 \\
  \geq 8 & 9 & 12 & 4 \\
 6 & 9 & 13 & 7 \\
 7 & 10 & 14 & 7 \\
 7 & \geq 11 & 15 & 8 \\
  \geq 8 &  10 & 14 & 6 \\
  & & & \\
\hline
\end{array}
$$


\caption{The possible values of $\nu_2(c_4), \nu_2(c_6), \nu_2(\Delta_E)$ and $\nu_2(N)$.}
\label{tab nu2}
\end{table}

\begin{table}[h]
$$
\begin{array}{|r|r|r|r|}
\hline
\nu_3 (c_4) & \nu_3 (c_6) & \nu_3 (\Delta_E) & \nu_3 (N)  \\ \hline
0 & 0 & \geq 0  & \min \{ 1, \nu_3 (\Delta_E)  \}  \\
1 & \geq 3 & 0 & 0  \\
\geq 2 & 3 & 3 & 2 \mbox{ or } 3  \\
2 & 4 & 3 & 3  \\
2 & \geq 5 & 3 & 2  \\
2 & 3 & 4 & 4  \\
2 & 3 & 5 & 3  \\
2 & 3 & \geq 6 & 2  \\
\geq 3 & 4 & 5 & 5  \\
3 & 5 & 6 & 4  \\
\hline
\end{array}
\quad
\begin{array}{|r|r|r|r|}
\hline
\nu_3 (c_4) & \nu_3 (c_6) & \nu_3 (\Delta_E) & \nu_3 (N)  \\ \hline
 3 & \geq 6 & 6 & 2 \\
 \geq 4 & 5 & 7 & 5 \\
 \geq 4 & 6 & 9 & 2 \mbox{ or } 3 \\
 4 & 7 & 9 & 3 \\
 4 & \geq 8 & 9 & 2 \\
 4 & 6 & 10 & 4 \\
 4 & 6 & 11 & 3 \\
 \geq 5 & 7 & 11 & 5 \\
 5 & 8 & 12 & 4 \\
 \geq 6 & 8 & 13 & 5 \\
\hline
\end{array}
$$

\caption{The possible values of $\nu_3(c_4), \nu_3(c_6), \nu_3(\Delta_E)$ and $\nu_3(N)$.}
\label{tab nu3}
\end{table}

\begin{table}[h]
$$
\begin{array}{|r|r|r|r|}
\hline
\nu_p (c_4) & \nu_p (c_6) & \nu_p (\Delta_E) & \nu_p (N)  \\ \hline
0 & 0 & \geq 1  & 1  \\
\geq 1 & 1 & 2 & 2  \\
1 & \geq 2 & 3 & 2  \\
\geq 2 & 2 & 4 & 2  \\
\geq 2 & \geq 3 & 6 & 2 \\
\hline
\end{array}
\quad
\begin{array}{|r|r|r|r|}
\hline
\nu_p (c_4) & \nu_p (c_6) & \nu_p (\Delta_E) & \nu_p (N)  \\ \hline
 2 & 3 & \geq 7 & 2 \\
 \geq 3 & 4 & 8 & 2 \\
 3 & \geq 5 & 9 & 2 \\
 \geq 4 & 5 & 10 & 2 \\
  &  &  &  \\
\hline
\end{array}
$$

\caption{The possible values of $\nu_p(c_4), \nu_p(c_6), \nu_p(\Delta_E)$ and $\nu_p(N)$ when $p > 3$ is prime and
$p\mid \Delta_E$.}
\label{tab nup}
\end{table}

%---------------------------------------------------------------------------------------------%

\section{Cubic forms: the main theorem and algorithm}
\label{sec:cubic-forms:-main-1}

Having introduced the notation we require for elliptic curves, we now turn our attention to cubic forms and our main result. Fix integers $a, b,
c$ and $d$, and consider the binary cubic form
\begin{align} \label{form0}
F(x,y)&=ax^3+bx^2y+cxy^2+dy^3,
\end{align}
with discriminant
\begin{equation} \label{claire-bear}
D_F = -27 a^2 d^2 + b^2 c^2 + 18 abcd -4 ac^3 -4 b^3 d.
\end{equation}
To any such form, we can associate a pair of covariants, the Hessian  $H=H_F$:
\begin{align*}
H=  H_F (x,y)=  - \frac{1}{4} \left(\frac{\partial^2 F}{\partial x^2} \frac{\partial^2 F}{\partial y^2} -
\left(\frac{\partial^2 F}{\partial x \partial y}\right)^2 \right)
\end{align*}
and the Jacobian determinant of $F$ and $H$,  a cubic form $G=G_F$ defined by
\begin{align*}
G&=G_F (x,y)=\frac{\partial F}{\partial x}\frac{\partial H}{\partial y}-  \frac{\partial F}{\partial y} \frac{\partial
H}{\partial x}.
\end{align*}
A quick computation reveals that, explicitly,
$$
H= (b^2-3ac) x^2 + (bc-9ad) xy + (c^2-3bd) y^2
$$
and
$$
\arraycolsep=1.4pt\def\arraystretch{1.4}
\begin{array}{ll}
G = & (-27 a^2d+9abc-2b^3)  x^3 + (-3b^2c-27 abd+18ac^2) x^2 y \\
   & + (3bc^2-18b^2d+27acd)  x y^2 + (-9bcd+2c^3+27ad^2) y^3.\\
\end{array}
$$
These satisfy the syzygy
\begin{align} \label{syz}
4H(x,y)^3 &= G(x,y)^2+27D_F F(x,y)^2
\end{align}
as well as the resultant identities:
\begin{equation} \label{resultant}
\mbox{Res} (F,G) = -8 D_F^3 \; \; \mbox{ and } \; \;
 \mbox{Res} (F,H) = D_F^2.
\end{equation}
Note here that we could just as readily work with $-G$ instead of $G$ here (corresponding to taking the Jacobian determinant of $H$ and $F$, rather than of $F$ and $H$). Indeed, as we shall observe in Section \ref{sec:mboxgl_2m-vs-mboxsl}, for our applications we will, in some sense, need to consider both possibilities.

Notice that if we set $(x,y)=(1,0)$ and multiply through by $\mathcal{D}^6/4$ (for any rational $\mathcal{D}$), then
this syzygy can be rewritten as
\begin{align*}
  ( \mathcal{D}^2 H(1,0))^3 - \left( \frac{\mathcal{D}^3}{2} G(1,0) \right)^2
  &=  1728 \cdot \frac{\mathcal{D}^6 D_F}{256} F(1,0)^2.
\end{align*}
Given an elliptic curve with corresponding invariants $c_4, c_6$ and $\Delta_E$, we will show that it is always possible to construct a binary
cubic form $F$, with corresponding  $\mathcal{D}$ for which
$$
\mathcal{D}^2 H(1,0) = c_4, \; \; -\frac{1}{2} \mathcal{D}^3 G(1,0) = c_6 \; \mbox{ and } \; \Delta_E =  \frac{\mathcal{D}^6  D_F F(1,0)^2}{256}
$$
(and hence equation (\ref{first}) is satisfied). This is the basis of the proof of our main result, which provides an algorithm for computing all isomorphism classes of elliptic curves $E/\mathbb{Q}$ with conductor a fixed positive integer $N$. Though we state our result for curves with $j_E \neq 0$, the case $j_E=0$ is easy to treat separately (see Section \ref{Mordell}).

\begin{theorem} \label{fisk}
Let $E/\mathbb{Q}$ be an elliptic curve of conductor $N=2^\alpha 3^\beta N_0$, where $N_0$ is coprime to $6$ and $0 \leq \alpha \leq 8$, $0 \leq \beta \leq 5$. Suppose further that $j_E \neq 0$.
Then there exists an integral binary cubic form $F$ of discriminant
\begin{align*}
D_F &= \text{sign}(\Delta_E) 2^{\alpha_0} 3^{\beta_0} N_1,
\end{align*}
and relatively prime integers $u$ and $v$ with
\begin{equation} \label{TM-eq}
F(u,v) =  \omega_0 u^3 + \omega_1 u^2v + \omega_2 uv^2 + \omega_3 v^3 = 2^{\alpha_1} \cdot 3^{\beta_1} \cdot \prod_{p \mid N_0} p^{\kappa_p},
\end{equation}
such that $E$ is isomorphic over $\mathbb{Q}$ to $E_{\mathcal{D} }$, where
\begin{equation} \label{curvey}
E_{\mathcal{D}} \; \; : \; \;  3^{[\beta_0/3]} y^2 = x^3 -27 \mathcal{D}^2 H_F(u,v) x +27 \mathcal{D}^3 G_F(u,v)
\end{equation}
and, for $[r]$ the greatest integer not exceeding a real number $r$,
\begin{align} \label{Dee}
\mathcal{D} &= \prod_{p \mid \gcd (c_4(E), c_6(E))} p^{\min \{ [\nu_p (c_4(E))/2], [\nu_p (c_6(E))/3] \}}.
\end{align}
The $\alpha_0$, $\alpha_1$, $\beta_0$, $\beta_1$ and $N_1$ are nonnegative integers satisfying  $N_1 \mid N_0$,
\begin{align*}
(\alpha_0, \alpha_1) &=
\begin{cases}
(2, 0)  \mbox{ or } (2,3)
    & \mbox{ if }  \alpha =0, \\
(3,\geq 3) \mbox{ or } (2,\geq 4)
    & \mbox{ if }  \alpha =1, \\
(2,1), (4,0) \mbox{ or }  (4,1)
    & \mbox{ if }  \alpha =2, \\
(2,1), (2,2), (3,2), (4,0)  \mbox{ or }  (4,1)
    & \mbox{ if }  \alpha =3, \\
(2, \geq 0), (3, \geq 2), (4,0)  \mbox{ or }  (4, 1)
    & \mbox{ if }  \alpha =4,  \\
(2, 0) \mbox{ or } (3,1)
    & \mbox{ if }  \alpha =5, \\
(2, \geq 0), (3, \geq 1), (4,0) \mbox{ or }  (4, 1)
    & \mbox{ if }  \alpha =6, \\
(3,0) \mbox{ or } (4,0)
    & \mbox{ if }  \alpha =7,  \\
(3, 1)
    & \mbox{ if }  \alpha =8
\end{cases}
\intertext{and}
(\beta_0, \beta_1) &=
\begin{cases}
(0, 0)
    & \mbox{ if } \beta =0, \\
(0, \geq 1) \mbox{ or } (1, \geq 0)
    & \mbox{ if } \beta =1, \\
(3,0), (0, \geq 0) \mbox{ or } (1, \geq 0)
    & \mbox{ if } \beta =2, \\
(\beta, 0) \mbox{ or } (\beta,1)
    & \mbox{ if } \beta \geq 3.
\end{cases}
\end{align*}
% $$
% \; \; \; \; \; \; \; \; \; \; \;
% (\alpha_0, \alpha_1)  = \left\{
% \begin{array}{l}
% (2, 0)  \mbox{ or } (2,3)  \; \mbox{ if } \; \alpha =0, \\
% (3,\geq 3) \mbox{ or } (2,\geq 4)  \; \mbox{ if } \; \alpha =1, \\
% (2,1), (4,0) \mbox{ or }  (4,1)  \; \mbox{ if } \; \alpha =2, \\
% (2,1), (2,2), (3,2), (4,0)  \mbox{ or }  (4,1)  \; \mbox{ if } \; \alpha =3, \\
% (2, \geq 0), (3, \geq 2), (4,0)  \mbox{ or }  (4, 1) \; \mbox{ if } \; \alpha =4,  \\
% (2, 0) \mbox{ or } (3,1)  \; \mbox{ if } \; \alpha =5, \\
% (2, \geq 0), (3, \geq 1), (4,0) \mbox{ or }  (4, 1) \; \mbox{ if } \; \alpha =6, \\
% (3,0) \mbox{ or } (4,0)  \; \mbox{ if } \; \alpha =7, \\
% (3, 1)  \; \mbox{ if } \; \alpha =8, \\
% \end{array}
% \right.
% $$
% $$
% (\beta_0, \beta_1)  = \left\{
% \begin{array}{l}
% (0, 0) \; \mbox{ if } \; \beta =0, \\
% (0, \geq 1) \mbox{ or } (1, \geq 0) \; \mbox{ if } \; \beta =1, \\
% (3,0), (0, \geq 0) \mbox{ or } (1, \geq 0) \; \mbox{ if } \; \beta =2, \\
% (\beta, 0) \mbox{ or } (\beta,1) \; \mbox{ if } \; \beta \geq 3, \\
% \end{array}
% \right.
% $$
The  $\kappa_p$ are nonnegative integers with
\begin{equation} \label{term0}
\nu_p (\Delta_E)  =
\left\{
\begin{array}{lc}
 \nu_p (D_F) + 2 \kappa_p & \mbox{ if }  p \nmid \mathcal{D}, \\
\nu_p (D_F) + 2 \kappa_p + 6 & \mbox{ if }  p \mid \mathcal{D} \\
\end{array}
\right.
\end{equation}
and
\begin{equation} \label{term1}
\kappa_p \in \{ 0, 1 \} \; \; \mbox{ whenever } \; \; p^2 \mid N_1.
\end{equation}
Further, we have
\begin{equation} \label{term2}
 \mbox{ if } \; \; \beta_0 \geq 3, \; \mbox{ then } \; 3 \mid \omega_1 \mbox{ and } 3 \mid \omega_2,
\end{equation}
and
\begin{equation} \label{term3}
 \mbox{ if } \nu_p(N)=1, \mbox{ for } p \geq 3, \mbox{ then } p \mid D_F F(u,v).
\end{equation}
\end{theorem}

Here, as we shall make explicit in the next subsection, the form $F$ corresponding to the curve $E$
in Theorem \ref{fisk} determines the $2$-division field of $E$. This connection was noted by Rubin and Silverberg \cite{RuSi} in a somewhat different context -- they proved that if $K$ is a field of characteristic $\neq 2, 3$,  $F(u,v)$ is a binary cubic form defined over $K$,  $E$ is an elliptic curve defined by $y^2=F(x,1)$, and $E_0$ is another elliptic curve over $K$ with the property that
$E[2] \cong E_0[2]$ (as Galois modules), then $E_0$ is isomorphic to the curve
$$
y^2 = x^3 - 3 H_F(u,v) x + G_F(u,v),
$$
for some $u, v \in K$.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %

\subsection{Remarks}
\label{sec:remarks}

Before we proceed, there are a number of observations we should make regarding Theorem \ref{fisk}.

\subsubsection{Historical comments}
Theorem \ref{fisk} is based upon a generalization of classical work of Mordell \cite{Mor1} (see also Theorem 3 of
Chapter 24 of Mordell \cite{Mor}), in which the Diophantine equation
$$
X^2+kY^2 = Z^3
$$
is treated through reduction to binary cubic forms\index{cubic forms} and their covariants, under the assumption that
$X$ and $Z$ are coprime. That this last restriction can, with some care, be eliminated, was noted by Sprindzuk (see
Chapter VI of \cite{Spri}). A similar approach to this problem can be made through the invariant theory of binary quartic forms, where one is led to solve, instead, equations of the shape
$$
X^2 + k Y^3 = Z^3.
$$
We will not carry out the analogous analysis here.

\subsubsection{$2$-division fields and reducible forms}
It might happen that the form $F$ whose existence is guaranteed by Theorem \ref{fisk} is reducible over $\mathbb{Z}[x,y]$. This occurs precisely when the elliptic curve $E$ has a nontrivial rational $2$-torsion point. This follows from the more general fact that the cubic form $F(u,v) =  \omega_0 u^3 + \omega_1 u^2v + \omega_2 uv^2 + \omega_3 v^3$ corresponding to an elliptic curve $E$ has the property that the splitting field of $F(u,1)$ is isomorphic to the $2$-division field of $E$. This is almost immediate from the identity
$$
\arraycolsep=1.4pt\def\arraystretch{1.4}
\begin{array}{ll}
3^3 \, \omega_0^2 \, F \left( \frac{x-\omega_1}{3 \omega_0},1 \right) & = x^3+(9 \omega_0 \omega_2-3 \omega_1^2) x+27 \omega_0^2 \omega_3-9 \omega_0 \omega_1 \omega_2+2 \omega_1^3 \\
 & = x^3 - 3 H_F(1,0) x  + G_F (1,0). \\
\end{array}
$$
Indeed, from (\ref{curvey}), the elliptic curve defined by the equation
$y^2=x^3 - 3 H_F(1,0) x  + G_F (1,0)$
is a quadratic twist of that given by the model $y^2 = x^3 -27 c_4(E) x -54 c_6(E)$, and hence also of $E$ (whereby they have the same $2$-division field).

\subsubsection{Imprimitive forms}
It is also the case that the cubic forms arising need not be primitive (in the sense that $\gcd
(\omega_0,\omega_1,\omega_2,\omega_3)=1$). This situation can occur if each of
the coefficients of $F$ is divisible by some integer $g \in \{ 2, 3, 6 \}$. Since the discriminant is a quartic form in the coefficients of $F$, for this to take place one requires that
$$
D_F \equiv 0 \mod{g^4}.
$$
This is a necessary but not sufficient condition for the form $F$ to be imprimitive. It follows, if we wish to restrict attention to primitive forms in Theorem \ref{fisk}, that the possible values for $\nu_p (D_F)$ that can arise are
\begin{align} \label{lumpy}
& \nu_2 (D_F) \in \{ 0, 2, 3, 4 \}, \; \;  \nu_3 (D_F) \in \{ 0, 1, 3, 4, 5 \} \\
& \mbox{ and } \nu_p (D_F) \in \{ 0, 1, 2 \}, \; \mbox{ for } p > 3.
\end{align}


\subsubsection{Possible twists}
We note that necessarily
\begin{align} \label{froggie}
\mathcal{D} &\mid 2^3 \cdot 3^2 \cdot \prod_{p \mid N_0} p,
\end{align}
so that, given $N$, there is a finite set of $E_{\mathcal{D}}$ to consider (we can restrict our attention to quadratic twists of the curve defined via
$y^2=x^3 - 3 H_F(1,0) x  + G_F (1,0)$,
by squarefree divisors of $6N$). In  case we are dealing with squarefree conductor $N$ (i.e. for semistable curves $E$), then, from Tables \ref{tab nu2}, \ref{tab nu3} and \ref{tab nup}, it follows that $\mathcal{D} \in \{ 1, 2 \}$.


\subsubsection{Necessity, but not sufficiency}
If we search for elliptic curves of conductor $N$, say, there may exist a cubic form $F$ for which the corresponding Thue-Mahler equation \eqref{TM-eq} \index{Thue-Mahler equations} has a
solution, where all of the conditions of Theorem \ref{fisk} are satisfied, but for which the corresponding  $E_{\mathcal{D}}$ has conductor $N_{E_{\mathcal{D}}} \neq N$ for all possible $\mathcal{D}$. This can happen when
certain local conditions at primes dividing $6N$ are not met; these local conditions are, in practice, easy to check and only a minor issue when
performing computations. Indeed, when producing tables of elliptic curves of conductor up to some given bound, we will, in many cases,  apply Theorem \ref{fisk} to find all curves with good reduction outside a fixed set of primes -- in effect, working with
multiple conductors simultaneously. For such a computation, the conductor of every twist $E_{\mathcal{D}}$ we encounter will be of interest to
us.

\subsubsection{Special binary cubic forms} \label{dahlia}
If, for a given binary form $F(x,y)=a x^3 + b x^2 y + c xy^2 + d y^3$, 3 divides both the coefficients $b$ and $c$ (say $b = 3 b_0$ and
$c=3 c_0$), then  $27 \mid D_F$ and, consequently, we can write $D_F=27 \widetilde{D}_F$, where
\begin{align*}
\widetilde{D}_F &= -a^2d^2+6ab_0c_0d+3b_0^2c_0^2-4ac_0^3-4b_0^3d.
\end{align*}
One can show that the set of binary cubic forms with $b \equiv c \equiv 0 \mod{3}$ is closed within the larger set of all binary
cubic forms in $\mathbb{Z}[x,y]$, under the action of either $\mbox{SL}_2 ( \mathbb{Z})$ or $\mbox{GL}_2 ( \mathbb{Z})$.
Also note that for such forms we have
$$
 \widetilde{H}_F(x,y) = \frac{H_F(x,y)}{9}= (b_0^2-ac_0) x^2 + (b_0c_0-ad) xy + (c_0^2-b_0d) y^2
$$
and $\widetilde{G}_F (x,y) =  G_F(x,y)/27$, so that
$$
\arraycolsep=1.4pt\def\arraystretch{1.4}
\begin{array}{cl}
\widetilde{G}_F (x,y) = & (-a^2d+3ab_0c_0-2b_0^3) x^3 + 3 (-b_0^2c_0-ab_0d+2ac_0^2) x^2 y \\
 & + 3 (b_0c_0^2-2b_0^2d+ac_0d) x y^2 + (-3b_0c_0d+2c_0^3+ad^2) y^3. \\
 \end{array}
$$
The syzygy now becomes
\begin{align} \label{syz2}
4\widetilde{H}_F (x,y)^3 &=\widetilde{G}_F(x,y)^2+\widetilde{D}_F F(x,y)^2.
\end{align}
We note, from Theorem \ref{fisk}, that we will be working exclusively with forms of this shape whenever we wish to treat elliptic curves of conductor $N \equiv 0 \mod{3^3}$.

\subsubsection{The case $j_E = 0$} \label{Mordell}
This case is treated over a general number field in Proposition 4.1 of Cremona and Lingham \cite{CrLi}.
The elliptic curves $E/\mathbb{Q}$ with $j_E=0$ and a given conductor $N$ are particularly easy to determine, since a curve with this property is necessarily isomorphic over $\mathbb{Q}$ to a {\it Mordell} curve with a model of the shape $Y^2 = X^3  - 54 c_6$ where $c_6=c_6(E)$. Such a model is minimal except possibly at $2$ and $3$ and has discriminant
$-2^6 \cdot 3^9 \cdot c_6^2$ (whereby any primes $p > 2$ which divide $c_6$  necessarily also divide $N$). Here, without loss of generality, we may suppose that $c_6$ is sixth-power-free.
Further, from Tables \ref{tab nu2}, \ref{tab nu3}, and \ref{tab nup}, we have that $\nu_2(N) \in \{ 0, 2, 3, 4, 6 \}$, that $\nu_3 (N) \in \{ 2, 3, 5 \}$, and that $\nu_p(N)=2$ whenever $p \mid N$ for $p > 3$. Given a positive integer $N$ satisfying these constraints, it is therefore a simple matter to check to see if there are elliptic curves $E/\mathbb{Q}$ with conductor $N$ and $j$-invariant $0$. One needs only to compute the conductors of the curves given by $Y^2 = X^3  - 54 c_6$ for each sixth-power-free integer (positive or negative) $c_6$ dividing $64 N^3$.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %

\subsection{The algorithm}
\label{sec:algorithm}

It is straightforward to convert Theorem~\ref{fisk} into an algorithm for finding all $E/\mathbb{Q}$ of conductor $N$. We can proceed as follows.
\begin{enumerate}
\item Begin by finding all $E/\mathbb{Q}$ of conductor $N$ with $j_E=0$, as outlined in Section \ref{Mordell}.
\item Next, compute $\mbox{GL}_2(\mathbb{Z})$-representatives for every binary form $F$ with discriminant
\begin{align*}
\Delta_F &= \pm 2^{\alpha_0} 3^{\beta_0} N_1
\end{align*}
for each divisor $N_1$ of $N_0$, and each possible pair $(\alpha_0,\beta_0)$ given in the statement of Theorem
\ref{fisk} (see (\ref{lumpy}) for specifics). We describe an algorithm for listing these forms in Section~\ref{sec:find-repr-forms}.
\item Solve the corresponding Thue-Mahler equations\index{Thue-Mahler equations}, finding pairs of integers $(u,v)$ such that
$F(u,v)$ is an $S$-unit, where $S = \{ p \mbox{ prime } : p \mid N \} \cup \{2 \}$ and $F(u,v)$ satisfies the additional conditions given in the statement of Theorem
\ref{fisk}.
\item For each cubic form $F$ and pair of integers $(u,v)$, consider the elliptic curve
$$
E_1 \; \; : \; \; y^2 = x^3 -27 H_F(u,v) x +27 G_F(u,v)
$$
and all its quadratic twists by squarefree divisors of $6N$. Output those curves with conductor $N$ (if any).
\end{enumerate}
The first, second and fourth steps here are straightforward; the first and second can be done efficiently, while the fourth is essentially
trivial. The main bottleneck is step~(3). While there is a deterministic procedure for carrying this out (see Tzanakis and de
Weger \cite{TW2}, \cite{TW3}), it is both involved and, often, computationally taxing.

%---------------------------------------------------------------------------------------------%

\section{Proof of Theorem \autoref{fisk}}
\label{sec:proof-theor-autor}


\begin{proof}
Given an elliptic curve $E/\mathbb{Q}$ of conductor $N=2^\alpha 3^\beta N_0$ and invariants $c_4= c_4(E) \neq 0$ and
$c_6=c_6(E)$, we will construct a corresponding cubic form $F$ explicitly. In fact, our form $F$ will have the property that its leading coefficient will be supported on the primes dividing $6N$, i.e. that
$$
F(1,0) = 2^{\alpha_1} \cdot 3^{\beta_1} \cdot \prod_{p \mid N_0} p^{\kappa_p}.
$$
Define $\mathcal{D}$ as in~\eqref{Dee}, i.e. take
$\mathcal{D}$ to be the largest integer whose square divides $c_4$ and whose cube divides $c_6$. We then set
$$
X = c_4/\mathcal{D}^2 \; \; \mbox{ and } \; \; Y = c_6/\mathcal{D}^3,
$$
whereby, from (\ref{first}),
\begin{align} \label{first2}
Y^2 &= X^3 + (-1)^{\delta +1}  M,
\end{align}
for
\begin{align*}
M &=\mathcal{D}^{-6} \cdot 2^6 \cdot 3^3 \cdot |\Delta_E|.
\end{align*}
Note that the assumption that $c_4(E) \neq 0$ ensures that both the $j$-invariant $j_E \neq 0$ and that $X \neq 0$.

It will prove useful to us later to understand precisely the possible common factors among $X, Y, \mathcal{D}$ and $M$.
For any $p>3$, we have $\nu_p(N) \leq 2$. When
$\nu_p(N)=1$, from Table \ref{tab nup} we find that
\begin{equation} \label{super-1}
( \nu_p (\mathcal{D}), \nu_p (X), \nu_p (Y), \nu_p (M)) = (0,0,0, \geq 1),
\end{equation}
while, if $\nu_p (N)=2$, then either
\begin{equation} \label{super0}
\nu_p (\mathcal{D}) = 1 \mbox{ and }  \min \{ \nu_p (X), \nu_p (Y) \} = 0, \; \nu_p (M)=0 ,
\end{equation}
or
%
\begin{align} \label{super}
\nu_p (\mathcal{D}) \leq 1, \;
&(\nu_p (X), \nu_p (Y), \nu_p (M) ) = (0,0, \geq 1), (\geq 1, 1, 2), (1, \geq 2, 3) \\
&\mbox{ or } (\geq 2, 2, 4).
\end{align}
Things are rather more complicated for the primes $2$ and $3$; we summarize this in Tables~\ref{tab nu2 nxym} and~\ref{tab nu3
nxym} (which are, in turn, compiled from the data in Tables~\ref{tab nu2} and ~\ref{tab nu3}).

\begin{table}[h]
$$
\begin{array}{|c|l|} \hline
\nu_2 (N) & (\nu_2 (X), \nu_2 (Y), \nu_2 (M), \nu_2 (\mathcal{D}) ) \\ \hline
0 &  (\geq 2, 0, 0, 1)  \mbox{ or } (0,0,6, 0)  \\
1 & (0,0,\geq 7, 0)  \\
2 & (\geq 2, 2, 4, 1), (\geq 2, 1, 2, 2) \mbox{ or } (0,0,2, 2) \\
3 & (\geq 2, 2, 4, 1), (\geq 2, 1, 2, 2)  \mbox{ or }  (0,0,t, 2), t= 2, 4 \mbox{ or } 5  \\
4 &  (\geq 2, 2, 4, 1), (\geq 2, 1, 2, 2), (\geq 2, 0, 0, 3)  \mbox{ or }  (0,0,t, 2), t= 2 \mbox{ or } t \geq 4  \\
5 & (\geq 0, \geq 0, 0, 2), (0, \geq 0, 0, 3), (0,0,3, 2) \mbox{ or } (1,0,0, 3)  \\
6 & (\geq 0, \geq 0, 0, 2), (0, \geq 0, 0, 3), (\geq 2, 2, 4, 2), (\geq 2, 1, 2, 3) \mbox{ or }  (0,0,\geq 2, 3) \\
7 & (0,0,1,2), (0,0,1,3), (1,1,2,2) \mbox{ or } (1,1,2,3) \\
8 & (1, \geq 2, 3, 2) \mbox{ or } (1, \geq 2, 3, 3). \\
 \hline
\end{array}
$$
\caption{The possible values of $\nu_2(N), \nu_2 (X), \nu_2 (Y), \nu_2(M)$ and $\nu_2 (D)$}
\label{tab nu2 nxym}
\end{table}

\begin{table}[h]
$$
\begin{array}{|c|l|} \hline
\nu_3 (N) & (\nu_3 (X), \nu_3 (Y), \nu_3 (M), \nu_3 (\mathcal{D}) ) \\ \hline
0 & (1, \geq 3, 3, 0)  \mbox{ or } (0,0,3, 0)  \\
1 & (0,0,\geq 4, 0)  \\
2 & (\geq 0, 0, 0, 1), (0, \geq 2, 0, 1), (0,0, \geq 3, 1), (1, \geq 3, 3, 1), (\geq 0,0,0,2)  \\
 & \mbox{ or } (0,\geq 2, 0, 2) \\
3 & (\geq 0, 0, 0, 1),  (\geq 0, 0, 0, 2), (0,1,0, 1), (0,1,0, 2), (0,0,2,1)\\
 &  \mbox{ or } (0,0,2, 2) \\
4 &  (0,0,1,1), (0,0,1,2), (1,2,3,1) \mbox{ or } (1, 2, 3, 2) \\
5 &   (\geq 1, 1, 2, 1), (\geq 1, 1, 2, 2), (\geq 2, 2, 4, 1) \mbox{ or }  (\geq 2, 2, 4,2). \\
 \hline
\end{array}
$$
\caption{The possible values of $\nu_3(N), \nu_3(X), \nu_3 (Y), \nu_3(M)$ and $\nu_3 (D)$}
\label{tab nu3 nxym}
\end{table}

We will construct a cubic form
$$
 F_1(x,y) = ax^3 + 3b_0 x^2y + 3c_0 xy^2 + dy^3,
$$
one coefficient at a time; our main challenge will be to ensure that the $a, b_0, c_0$ and $d$ we produce are actually integral rather than just rational. The form $F$ whose existence is asserted
in the statement of Theorem \ref{fisk} will turn out to be either $F_1$ or $F_1/3$.

Let us write
\begin{align*}
  M = M_1 \cdot M_2
\end{align*}
where $M_2$ is the largest integer divisor of $M$ that is coprime to $X$, so that
$$
M_1 = \prod_{p \, \mid  \, X} p^{\nu_p (M)} \; \; \mbox{ and } \; \;  M_2 = \prod_{p \, \nmid \, X} p^{\nu_p (M)}.
$$
We define
\begin{equation} \label{a1}
a_1 = \prod_{p \mid M_1} p^{\left[ \frac{\nu_p (M)-1}{2} \right]}
\end{equation}
and set
\begin{equation} \label{a2}
a_2 = \left\{
\begin{array}{cl}
3^{-1} \, \prod_{p \mid M_2} p^{\left[ \frac{\nu_p (M)}{2} \right]} & \mbox{ if }  \nu_3 (X)=0, \, \nu_3(M) =2t, \, t \in \mathbb{Z}, t \geq 2,  \\
\prod_{p \mid M_2} p^{\left[ \frac{\nu_p (M)}{2} \right]} & \mbox{ otherwise. } \\
\end{array}
\right.
\end{equation}
Define $a = a_1 \cdot a_2$.
It follows that $a_1^2 \mid M_1$ and, from (\ref{super-1}), (\ref{super0}), (\ref{super}), and Tables \ref{tab nu2 nxym} and \ref{tab nu3 nxym}, that both
$$
a_1 \mid X \; \; \mbox{ and } \; \;  a_1^2 \mid Y.
$$
We write $X = a_1 \cdot X_1$ and observe that $a_2^2 \mid M_2$. Note that $a_2$ is coprime to $X$ and hence to $a_1$.
Since $a^2 \mid M$, we may thus define a positive integer $K$ via $K = M/a^2$, so that (\ref{first2}) becomes
\begin{align*}
Y^2-X^3 &= (-1)^{\delta+1} Ka^2.
\end{align*}
From the fact that $\gcd (a_2,X)=1$ and $X \neq 0$, we may choose $B$ so that
\begin{align*}
  a_2 B &\equiv -Y/a_1 \mod{X^3},
\end{align*}
whereby
\begin {equation} \label{truth}
a B+Y \equiv 0 \mod{a_1X^3}.
\end{equation}
Note that, since $a_1^2 \mid Y$ and $a_1 \mid X$, it follows that $a_1 \mid B$.
Let us define
\begin{equation} \label{definite}
b_0 = \frac{aB+Y}{X}, \; \;
c_0 = \frac{b_0^2-X}{a} \; \; \mbox{ and } \; \;
d = \frac{b_0c_0 - 2B}{a}.
\end{equation}
We now demonstrate that these are all integers. That $b_0 \in \mathbb{Z}$ is immediate from (\ref{truth}).
Since $b_0 X - Y = aB$, we know that $b_0 X \equiv Y \mod{a}$. Squaring both sides
thus gives
$$
b_0^2 X^2 \equiv Y^2 \equiv X^3 + (-1)^{\delta+1} K a^2  \equiv X^3 \mod{a_1 \cdot a_2},
$$
and, since $\gcd (a_2,X)=1$,
$$
 b_0^2 \equiv X \mod{a_2}.
$$
From (\ref{truth}), we have $b_0 \equiv 0 \mod{a_1 X^2}$, whereby, since $a_1 \mid X$,
$$
b_0^2 \equiv X \equiv 0 \mod{a_1}.
$$
The fact that $\gcd(a_1,a_2)=1$ thus allows us to conclude that $b_0^2 \equiv X \mod{a}$ and hence that $c_0 \in \mathbb{Z}$.

It remains to show that $d$ is an integer.
Let us rewrite $ad$ as
$$
ad = b_0c_0-2B = \left( \frac{aB+Y}{aX} \right) \left( \left( \frac{aB+Y}{X} \right)^2 - X \right) - 2B,
$$
so that
$$
ad =\left( \frac{aB+Y}{aX} \right) \left( \frac{(-1)^{\delta+1} K a^2 + 2 a B Y + a^2 B^2}{X^2} \right) - 2B.
$$
Expanding, we find that
\begin{equation} \label{three}
X^3 d = (-1)^{\delta+1} KY+ 3 Y B^2 + a B^3 + (-1)^{\delta+1} 3 KaB.
\end{equation}
We wish to show that
$$
(-1)^{\delta+1} KY+ 3 Y B^2 + a B^3 + (-1)^{\delta+1} 3 KaB \equiv 0 \mod{X^3}.
$$
From (\ref{truth}), we have that
$$
(-1)^{\delta+1} KY+ 3 Y B^2 + a B^3 + (-1)^{\delta+1} 3 KaB \equiv 2Y \left( B^2 + (-1)^\delta K \right) \mod{a_1 X^3}.
$$
Multiplying congruence (\ref{truth}) by $aB-Y$ (which, from our prior discussion, is divisible by $a_1^2$),
we find that
$$
a^2 B^2 \equiv Y^2 \equiv X^3 + (-1)^{\delta+1} K a^2 \mod{a_1^3 X^3}
$$
and hence, dividing through by $a_1^2$,
$$
a_2^2 B^2 \equiv  a_1 X_1^3 + (-1)^{\delta+1} K a_2^2 \mod{a_1 X^3}.
$$
It follows that
\begin{equation} \label{three-2}
B^2 + (-1)^\delta K \equiv a_2^{-2} a_1 X_1^3  \mod{a_1 X^3},
\end{equation}
and so, since $a_1^2 \mid Y$,
$$
Y \left( B^2 + (-1)^\delta K \right) \equiv 0 \mod{X^3},
$$
whence we conclude that $d$ is an integer, as desired.

With these values of $a, b_0, c_0$ and $d$, we can then confirm (with a quick computation) that the cubic form
\begin{align*}
  F_1(x,y) &= ax^3 + 3b_0 x^2y + 3c_0 xy^2 + dy^3
\end{align*}
has discriminant
\begin{align*}
  D_{F_1} &= \frac{108}{a^2} (X^3-Y^2) = (-1)^\delta \cdot 2^2 \cdot 3^3 \cdot K
\end{align*}
We also note that
$$
F_1(1,0) = a, \; \; \widetilde{H}_{F_1}(1,0) = b_0^2 -a c_0 = X
$$
and
$$
 -\frac{1}{2} \widetilde{G}_{F_1}(1,0) = \frac{1}{2}(a^2d -3ab_0c_0+2b_0^3) = Y,
$$
where $\widetilde{G}_{F}$ and $\widetilde{H}_{F}$ are as in Section \ref{dahlia}.

Summarizing Table \ref{tab nu3 nxym},  we find that we are in one of the following four cases :

\begin{enumerate}
\item[(i)] $\nu_3 (X)=1, \;  \nu_3(Y) =2,  \; \nu_3(M)=3 \; \mbox{ and } \;  \nu_3(N)=4,$
\item[(ii)] $\nu_3(X) \geq 2, \;  \nu_3(Y) =2, \; \nu_3(M) =4, \; \nu_3(N)=5,$
\item[(iii)] $\nu_3(M) \leq 2 $ and $ \nu_3(N) \geq 2$, or
\item[(iv)] $\nu_3 (M)  \geq 3$ and either $\nu_3 (XY)=0 $ or $\nu_3(X)=1, \,  \nu_3(Y) \geq 3$.
\end{enumerate}
In cases (i), (ii), and (iii), we choose $F=F_1$, i.e.
\begin{align*}
(\omega_0,\omega_1,\omega_2,\omega_3) = (a, 3 b_0, 3 c_0, d),
\end{align*}
so that
\[F(1,0)=a, \; \; D_{F} = (-1)^\delta 2^2 \cdot 3^3 \cdot K, \; \;
c_4 = \mathcal{D}^2 \widetilde{H}_{F} (1,0)\]
and
\[c_6 = - \frac{1}{2}  \mathcal{D}^3 \widetilde{G}_{F} (1,0).\]
It follows that $E$ is isomorphic over $\mathbb{Q}$ to the curve
$$
y^2 = x^3 -27 c_4 x -54 c_6 = x^3 - 3 \mathcal{D}^2 H_{F}(1,0) x + \mathcal{D}^3 G_{F}(1,0).
$$

In  case (iv), observe that, from definitions (\ref{a1}) and (\ref{a2}),
\begin{equation} \label{foster}
\nu_3(a) = \left[ \frac{\nu_3(M)-1}{2} \right] \; \; \mbox{ and } \; \;
\nu_3(K) = \nu_3(M) - 2 \nu_3 (a),
\end{equation}
so that $3 \mid a$ and $3 \mid K$. From equation (\ref{three}),  $3 \mid X^3 d$.
If $\nu_3(X)=0$ this implies that $3 \mid d$. On the other hand,
if $\nu_3(X)=1$, then, from (\ref{three-2}), we may conclude that $3 \mid B$. Since each of $a, B$ and $K$ is divisible by $3$, while $\nu_3 (X) =1$ and $\nu_3 (Y) \geq 3$,  equation (\ref{three})
once again implies that $3 \mid d$.
In this case, we can therefore write $a = 3a_0$ and $d=3d_0$, for integers $a_0$ and $d_0$ and
set $F = F_1/3$, i.e. take
\begin{align*}
(\omega_0,\omega_1,\omega_2,\omega_3) = (a_0, b_0, c_0, d_0).
\end{align*}
We have
\[F(1,0) =a/3, \; \;  D_{F}  = (-1)^\delta 2^2  \cdot K/3, \; \;
c_4 = \mathcal{D}^2 H_{F} (1,0)\]
and
\[c_6 = - \frac{1}{2}  \mathcal{D}^3 G_{F} (1,0).\]
The curve $E$ is now isomorphic over $\mathbb{Q}$ to the model
$$
y^2 = x^3 -27 c_4 x -54 c_6 = x^3 - 27 \mathcal{D}^2 H_{F}(1,0) x + 27 \mathcal{D}^3 G_{F}(1,0).
$$

Since $|D_F|/D_F = (-1)^\delta$ and $a^2 K \mid 1728 \Delta_E$, we may write
$$
F(1,0) = 2^{\alpha_1} \cdot 3^{\beta_1} \cdot \prod_{p \mid N_0} p^{\kappa_p}
\; \; \mbox{ and } \; \; D_F = (|\Delta_E|/\Delta_E) 2^{\alpha_0} 3^{\beta_0} N_1,
$$
for nonnegative integers $\alpha_0, \alpha_1, \beta_0, \beta_1, \kappa_p$ and a positive integer $N_1$,  divisible only by primes dividing $N_0$. More explicitly, we have
$$
\alpha_0 = \nu_2 (K) + 2\; \; \mbox{ and } \;  \; \beta_0 =\nu_3 (K) +
\left\{
\begin{array}{rl}
3 & \mbox{ in case (i), (ii) or (iii), or } \\
-1& \mbox{ in case (iv),} \\
\end{array}
\right.
$$
and
$$
\alpha_1 = \nu_2 (a) \; \; \mbox{ and } \;  \; \beta_1 =\nu_3 (a) +
\left\{
\begin{array}{rl}
0 & \mbox{ in case (i), (ii) or (iii), or } \\
-1& \mbox{ in case (iv). } \\
\end{array}
\right.
$$
It remains for us to prove that these integers satisfy the conditions listed in the statement of the theorem. It is straightforward to check this,  considering in turn each possible triple $(X,Y,M)$ from
(\ref{super-1}), (\ref{super0}), (\ref{super}), and Tables~\ref{tab nu2 nxym} and ~\ref{tab nu3 nxym}, and using the fact that $K = M/a^2$.
%, where
%$$
%a = a_3 \mbox{ or } a_3/3, \mbox{ according to (\ref{a2}), } \; \mbox{and } \;
%a_3 = \prod_{p \mid M} p^{\left[ \frac{\nu_p (M)-\delta_p}{2} \right]} \; \mbox{ for } \; \;
%\delta_p =
%\left\{
%\begin{array}{ll}
%1 & \mbox{ if } p \mid X, \\
%0 & \mbox{ if } p \nmid X. \\
%\end{array}
%\right.
%$$

In particular, if $p > 3$, we have $\nu_p(\Delta_E) = 6 \nu_p(\mathcal{D}) + \nu_p (D_F) + 2 \kappa_p$. From Table \ref{tab nup} and (\ref{Dee}), we have $\nu_p(\mathcal{D}) \leq 1$, whereby (\ref{term0}) follows.
Further,
\begin{equation} \label{toothbrush}
\nu_p(a) =
\left\{\begin{array}{ll}
\left[ \frac{\nu_p(M)-1}{2} \right] & \mbox{ if } p \mid X, \\
\left[ \frac{\nu_p(M)}{2} \right] & \mbox{ if } p \nmid X, \\
\end{array}
\right.
\end{equation}
and so, if $p \nmid X$,
$$
\nu_p(M)-2 \nu_p(a) \leq 1.
$$
Since $a^2K=M$, if $p^2 \mid D_F$, then $\nu_p(N)=2$ and it follows that we are in case (\ref{super}), with $p \mid X$. We may thus conclude that $\nu_p (M) \in \{ 2, 3, 4 \}$ and hence, from (\ref{toothbrush}), that $\nu_p(a) \leq 1$. This proves (\ref{term1}).

For (\ref{term2}), note that, in cases (i), (ii) and (iii), we clearly have that  $3 \mid \omega_1$ and $3 \mid \omega_2$.  In case (iv), from (\ref{foster}),
$$
\beta_0 = \nu_3 (D_F) = \nu_3(K) -1 = \nu_3(M) - 2  \left[ \frac{\nu_3(M)-1}{2} \right] - 1 \in \{ 0, 1 \}.
$$
Finally, to see (\ref{term3}), note that if $\nu_p(N)=1$, for  $p > 3$, then we have (\ref{super-1}) and hence
$$
\nu_p(D_F) + 2 \nu_p (F(u,v)) = \nu_p(M) \geq 1,
$$
whereby $p \mid D_F$ or $p \mid F(u,v)$.
We may also readily check that the same conclusion obtains for $p=3$ (since, equivalently, $\beta_0+\beta_1 \geq 1$). This completes the proof of Theorem \ref{fisk}.


\end{proof}

To illustrate this argument, suppose we consider the elliptic curve (denoted 109a1 in Cremona's database) defined via
$$
E \; \; : \; \; y^2 + xy = x^3 - x^2 -8 x -7,
$$
with $\Delta_E=-109$.
We have
$$
c_4(E) = 393 \; \; \mbox{ and } \; \; c_6(E)=7803,
$$
so that $\gcd (c_4(E), c_6(E))=3$. It follows that
$$
\mathcal{D} = 1, \; X=393, \; Y=7803, \; \delta=1, \; M = 2^6 \cdot 3^3 \cdot 109,
$$
and hence we have
$$
M_1 = 3^3, \; M_2=2^6 \cdot 109, \; a_1 = 3, \; a_2 = 2^3, \; a=2^3 \cdot 3 \; \mbox{ and } \; K = 3 \cdot 109.
$$
We solve the congruence $8B \equiv -2601 \mod{393^3}$ to find that we may choose $B=7586982$, so that
$$
b_0 =463347, \; \;
c_0 = 8945435084 \; \; \mbox{ and } \; \;
d =172701687278841.
$$
We are in case (iv) and thus set
$$
F(x,y) = 8 x^3 + 463347 x^2 y + 8945435084 x y^2 + 57567229092947 y^3,
$$
with discriminant $D_F = -4 \cdot 109$,
$$
G_F(1,0) = -15606 = -2 c_6(E) \; \; \mbox{ and } \; \; H_F(1,0)=393 = c_4(E).
$$
The curve $E$ is thus isomorphic to the model
\begin{equation} \label{flag}
E_{\mathcal{D}} \; \; : \; \; y^2 = x^3 - 27 \mathcal{D}^2 H_{F}(1,0) x + 27 \mathcal{D}^3 G_{F}(1,0) = x^3 - 10611x-421362.
\end{equation}

We observe that the form $F$ is $\mbox{GL}_2(\mathbb{Z})$-equivalent to a ``reduced'' form (see Section \ref{sec:find-repr-forms} for details),  given by
$$
\tilde{F} (x,y) = x^3 + 3 x^2y + 4 x y^2 + 6 y^3.
$$
In fact, this is the only form (up to $\mbox{GL}_2(\mathbb{Z})$-equivalence) of discriminant $\pm 4 \cdot 109$. We can check that the solutions to the Thue equation
$\tilde{F}(u,v)=8$ are given by $(u,v)=(2,0)$ and $(u,v)=(-7,3)$.
The minimal quadratic twist of
$$
y^2 = x^3 -27 H_{\tilde{F}}(2,0) x +27 G_{\tilde{F}}(2,0)
$$
has conductor $2^5 \cdot 109$ and hence cannot correspond to $E$. For the solution $(u,v)=(-7,3)$, we find that the curve given by the model
$$
y^2 = x^3 -27 H_{\tilde{F}}(-7,3) x +27 G_{\tilde{F}}(-7,3) =x^3 - 10611x+421362,
$$
is the quadratic twist by $-1$ of the curve (\ref{flag}). This situation arises from the fact that $G_F$ is an $\mbox{SL}_2(\mathbb{Z})$-covariant, but not a $\mbox{GL}_2(\mathbb{Z})$-covariant of $F$ (we will discuss this more in the next section).

%---------------------------------------------------------------------------------------------%

\section{Finding representative forms}
\label{sec:find-repr-forms}

As Theorem \ref{fisk} illustrates, we are able to tabulate elliptic curves over $\mathbb{Q}$ with good reduction outside a given set of primes,
by finding a set of representatives for $\mbox{GL}_2 ( \mathbb{Z})$-equivalence classes of binary cubic forms with
certain discriminants, and then solving a number of Thue-Mahler equations. In this section, we will provide a brief description of techniques to find
distinguished \emph{reduced} representatives for equivalence classes of cubic forms over a given range of
discriminants. For both positive and negative discriminants, the notion of \emph{reduction} arises from associating a
particular definite quadratic form to a given cubic form.
%We do not make these quadratic forms explicit, but rather
%state our definitions of reduction solely in terms of the coefficients of the cubic forms.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %

\subsection{Irreducible Forms}

For forms of positive discriminant, there is a well developed classical theory of reduction dating back to work of
Hermite \cite{Her1}, \cite{Her2} and, later, Davenport (see e.g. \cite{Dav}, \cite{Dav2} and \cite{DaHe}).  We can actually apply
this method to both reducible and irreducible forms. Initially, though, we will assume the forms are irreducible, since we will treat
the elliptic curves corresponding to reducible forms by a somewhat different approach (see Section~\ref{sec:reducible-forms}).
Note that when one speaks of ``irreducible, reduced forms'',
as Davenport observes,
``the terminology is unfortunate, but can hardly be avoided'' (\cite{Dav3}, page 184).

In each of Belabas \cite{Be}, Belabas and Cohen \cite{BeCo} and Cremona
\cite{Cr}, we find very efficient algorithms for computing cubic forms of both positive and negative discriminant, refining classical work of Hermite, Berwick
and Mathews \cite{BeMa}, and Julia \cite{Ju}. These are  readily translated into computer code to loop over valid $(a,b,c,d)$-values (with corresponding forms $ax^3+bx^2y+cxy^2+dy^3$).  The running time in each case is linear in the upper bound $X$.
Realistically, this step (finding representatives for our cubic forms) is highly unlikely to be the bottleneck in our computations.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %

\subsection{Reducible forms}
\label{sec:reducible-forms}

One can make similar definitions of reduction for reducible forms (see \cite{BeGh} for example). However, for our
purposes, it is sufficient to note that a reducible form is equivalent to
$$
F(x,y) = b x^2 y + c x y^2 + d y^3 \; \; \mbox{ with }  \; \; 0 \leq d \leq c,
$$
which has discriminant
\begin{align*}
\Delta_F &= b^2 (c^2 - 4 b d).
\end{align*}

To find all elliptic curves with good reduction outside $S = \{ p_1, p_2, \ldots, p_k \}$, corresponding to
reducible cubics in Theorem~\ref{fisk} (i.e. those $E$ with at least one rational $2$-torsion point), it is enough to find all such triples $(b,c,d)$ for which there exist integers $x$ and $y$ so that both
$$
b^2(c^2-4bd) \; \; \mbox{ and } \; \;  b x^2 y + c x y^2 + d y^3
$$
are $S^*$-units (with $S^* = S \cup \{ 2 \}$). For this to be true, it is necessary that each of the integers
$$
b, \;  \; c^2 - 4 bd,\;  \; y \; \; \mbox{ and } \; \;  \mu = bx^2 + cxy + dy^2
$$
is an $S^*$-unit. Taking the discriminant of $\mu$ as a function of $x$, we thus require that
\begin{align} \label{weger}
(c^2 - 4 bd )  y^2  + 4 b \mu &=Z^2,
\end{align}
for some integer $Z$. This is an equation of the shape
\begin{align} \label{S-square}
 X+Y &=Z^2
\end{align}
in $S^*$-units $X$ and $Y$.

While \emph{a priori} equation~\eqref{S-square} arises as only a necessary condition for the existence
of an elliptic curve of the desired form, given any solution to~\eqref{S-square} in $S^*$-units $X$ and $Y$ and integer $Z$, the curves
$$
E_1(X,Y) \; \; : \; \; y^2 = x^3 + Z x^2 + \frac{X}{4} x
$$
and
$$
E_2(X,Y) \; \; : \; \; y^2 = x^3 + Z x^2 + \frac{Y}{4} x
$$
have nontrivial rational $2$-torsion (i.e. the point corresponding to $(x,y)=(0,0)$) and discriminant $X^2Y$ and $XY^2$, respectively (and hence good reduction at all primes outside $S^*$).

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %

\subsection{Computing forms of fixed discriminant}
\label{sec:comp-forms-fixed}

For our purposes, we will typically compute and tabulate a large list of irreducible forms of absolute discriminant bounded by a given positive number $X$ (of size up to $10^{12}$ of so, beyond which storage becomes problematical). In certain situations, however, we will want to compute all forms of a given fixed, larger discriminant (perhaps up to size $10^{15}$). To carry this out and find desired forms of the shape $ax^3+bx^2y+cxy^2+dy^3$, we can argue as in, for example, Cremona \cite{Cr}, to restrict our attention to $O(X^{3/4})$ triples $(a,b,c)$.
From (\ref{claire-bear}), the definition of $D_F$, we have that
$$
d = \frac{9abc-2b^3 \pm \sqrt{4 (b^2-3ac)^3-27 a^2 D_F}}{27 a^2}
$$
and hence it remains to check that the quantity $4 (b^2-3ac)^3-27 a^2 D_F$ is an integer square, that the relevant conditions modulo $27a^2$ are satisfied, and that a variety of further inequalities from \cite{Cr} are satisfied. The running time for finding forms with discriminants of absolute value of size $X$ via this approach is of order $X^{3/4}$.


% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %

\subsection{$\mbox{GL}_2(\mathbb{Z})$ vs $\mbox{SL}_2(\mathbb{Z})$}
\label{sec:mboxgl_2m-vs-mboxsl}

One last observation which is very important to make before we proceed, is that while $G_F^2$ is $\mbox{GL}_2(\mathbb{Z})$-covariant\index{covariants}, the same is not actually true for $G_F$ (it is, however, an $\mbox{SL}_2(\mathbb{Z})$-covariant). This may seem like a subtle point, but what it means for us in practice is that, having found our $\mbox{GL}_2(\mathbb{Z})$-representative forms $F$ and corresponding curves of the shape $E_{\mathcal{D}}$ from Theorem \ref{fisk}, we need, in every case, to also check to see if
$$
\tilde{E}_{\mathcal{D}} \; \; : \; \; 3^{[\beta_0/3]} y^2 = x^3 -27 \mathcal{D} ^2 H_F(u,v) x -27 \mathcal{D} ^3 G_F(u,v),
$$
the quadratic twist of $E_{\mathcal{D}}$ by $-1$, yields a curve of the desired conductor\index{conductor}.

%---------------------------------------------------------------------------------------------%
%---------------------------------------------------------------------------------------------%

\chapter{Towards Efficient Resolution of Thue-Mahler Equations}
\label{ch:EfficientTMSolver}

Let $c$ denote a nonzero integer and let $S=\{p_1,\dotsc,p_v\}$ be a set of rational primes. In this section, we specialize the results of \autoref{ch:AlgorithmsForTM} to the degree $3$ Thue--Mahler equation
\begin{equation} \label{Eq:TM1}
F(X,Y) = c_0 X^3 + c_1 X^{2}Y + c_2XY^2 + c_3Y^3 = c p_1^{Z_1}\cdots p_v^{Z_v},
\end{equation}
where $(X,Y) \in \mathbb{Z}^2$, $\gcd(X,Y)=1$, and $Z_i \geq 0$ for $i = 1, \dots, v$. In particular, to enumerate the set of solutions $\{X,Y, Z_1, \dots, Z_v\}$ to this equation, we follow \autoref{sec:FactorizationTM} to reduce the problem of solving \eqref{Eq:TM1} to solving finitely many so-called ``$S$-unit'' equations
\begin{equation} \label{eq:EfficientSunit}
\lambda = \delta_1 \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)^{n_i} \prod_{i = 1}^r\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right)^{a_i} - 1 = \delta_2 \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(i_0)}}{\gamma_i^{(j)}}\right)^{n_i}\prod_{i = 1}^{r}\left( \frac{\varepsilon_i^{(i_0)}}{\varepsilon_i^{(j)}}\right)^{a_i},
\end{equation}
where
\[\delta_1 = \frac{\theta^{(i_0)} - \theta^{(j)}}{\theta^{(i_0)} - \theta^{(k)}}\cdot\frac{\alpha^{(k)}\zeta^{(k)}}{\alpha^{(j)}\zeta^{(j)}}, \quad \delta_2 = \frac{\theta^{(j)} - \theta^{(k)}}{\theta^{(k)} - \theta^{(i_0)}}\cdot \frac{\alpha^{(i_0)}\zeta^{(i_0)}}{\alpha^{(j)}\zeta^{(j)}}\]
are constants. Here, we adopt the notation of \autoref{ch:AlgorithmsForTM} and recall that we reduce \eqref{Eq:TM1} to a homogenous equation of the form
\begin{equation} \label{eq:Efficientpoly}
f(x,y) = x^3 + C_1x^2y + C_2xy^2 + C_3y^3 = cp_1^{z_1}\cdots p_v^{z_v},
\end{equation}
where $\gcd(x,y) = 1$ and $\gcd(c,p_i) = 1$ for $i = 1, \dots, p_v$. Moreover, we set
\begin{equation} \label{eq:Efficientg}
g(t) = f(t,1) = t^3 + C_1t^2 + C_2t + C_3
\end{equation}
so that $K = \mathbb{Q}(\theta)$ with $g(\theta) = 0$. Recall that $\zeta$ in \eqref{eq:EfficientSunit} denotes a root of unity in $K$, while $\{\eps_1, \dots, \eps_r\}$ is a set of fundamental units of $\mathcal{O}_K$. In this case, as $K$ is a degree $3$ extension of $\mathbb{Q}$, we either have $3$ real embeddings of $K$ into $\mathbb{C}$, or one real embedding of $K$ into $\mathbb{C}$ and a pair of complex conjugate embeddings of $K$ into $\mathbb{C}$. Thus either $r = 1$ or $r = 2$.

In this chapter, we describe new techniques to solve equation~\eqref{eq:EfficientSunit} via a global Weil height.

%---------------------------------------------------------------------------------------------%

\section{Decomposition of the Weil height}
\label{sec:decomp-weil-height}

The sieves of \cite{TW3} involve logarithms which are of local nature. To obtain a global sieve, we work instead with the global logarithmic Weil height. This height is invariant under conjugation and admits a decomposition into local heights which can be related to complex and $p$-adic logarithms.

Let $n_1, \dots, n_{\nu}, a_1, \dots, a_r$ be a solution to \eqref{eq:EfficientSunit} and set $z = \frac{\delta_2}{\lambda}$, where
\[z = \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(j)}}{\gamma_i^{(i_0)}}\right)^{n_i}\prod_{i = 1}^{r}\left( \frac{\varepsilon_i^{(j)}}{\varepsilon_i^{(i_0)}}\right)^{a_i}.\]
Given the global Weil height of $z$, or all the local heights of $z$, we will construct several ellipsoids `containing' $n_1, \dots, n_{\nu}, a_1, \dots, a_r$ such that the volume of the ellipsoids are as small as possible. We begin by computing the height of $z$.

Let $L$ be the splitting field of $K$. Recall that for cubic extensions $K$, the Galois group $\Gal(L/\mathbb{Q})$ is isomorphic to either the alternating group $A_3$ or the symmetric group $S_3$.

\begin{lemma}\label{lem:cancellation}
Let $\mathfrak{p}$ be a prime ideal of $\mathcal{O}_K$ and let $\mathfrak{P}$ denote an ideal of $\mathcal{O}_L$ lying above it. Suppose $\sigma_{i_0}: L \to L$, $\theta \mapsto \theta^{(i_0)}$ and $\sigma_{j}: L \to L$, $\theta \mapsto \theta^{(j)}$ are two automorphisms of $L$ such that $(i_0,j,k)$ forms a subgroup of $\Gal(L/\mathbb{Q})$ of order $3$. Let $\mathfrak{P}^{(i_0)} = \sigma_{i_0}(\mathfrak{P})$ and $\mathfrak{P}^{(j)} = \sigma_{j}(\mathfrak{P})$ be the prime ideals lying over $\mathfrak{p}^{(i_0)}$, $\mathfrak{p}^{(j)}$ respectively. For $i = 1, \dots, \nu$,
\[\left( \frac{\gamma_i^{(j)}}{\gamma_i^{(i_0)}}\right)\mathcal{O}_L
	 = \left(\prod_{\mathfrak{P}\mid\mathfrak{p}_1} \frac{\mathfrak{P}^{(j) \ e(\mathfrak{P}^{(j)}\mid\mathfrak{p}_1^{(j)})}}{\mathfrak{P}^{(i_0) \ e(\mathfrak{P}^{(i_0)}\mid\mathfrak{p}^{(i_0)}_1)}}\right)^{a_{1i}} \cdots \left(\prod_{\mathfrak{P}\mid\mathfrak{p}_{\nu}} \frac{\mathfrak{P}^{(j) \ e(\mathfrak{P}^{(j)}\mid\mathfrak{p}^{(j)}_{\nu})}}{\mathfrak{P}^{(i_0) \ e(\mathfrak{P}^{(i_0)}\mid\mathfrak{p}^{(i_0)}_{\nu})}}\right)^{a_{\nu i}}\]
where $\mathfrak{P}^{(j)} \neq \mathfrak{P}^{(i_0)}$ for all $\mathfrak{P}$ lying above $\mathfrak{p}$ in $K$.
\end{lemma}

\begin{proof}
Since
\[(\gamma_i)\mathcal{O}_K = \mathfrak{p}_1^{a_{1i}} \cdots \mathfrak{p}_{\nu}^{a_{\nu i}},\]
for $i = 1, \dots, \nu$, where
\[\mathfrak{p}_i\mathcal{O}_L=\prod_{\mathfrak{P}\mid\mathfrak{p}_i} \mathfrak{P}^{e(\mathfrak{P}\mid\mathfrak{p}_i)},\]
it holds that
\[(\gamma_i)\mathcal{O}_L = \left(\prod_{\mathfrak{P}\mid\mathfrak{p}_1} \mathfrak{P}^{e(\mathfrak{P}\mid\mathfrak{p}_1)}\right)^{a_{1i}} \cdots \left(\prod_{\mathfrak{P}\mid\mathfrak{p}_{\nu}} \mathfrak{P}^{e(\mathfrak{P}\mid\mathfrak{p}_{\nu})}\right)^{a_{\nu i}}.\]

Let $\mathfrak{P}^{(i_0)},\mathfrak{P}^{(j)}$ denote the ideal $\mathfrak{P}$ under the automorphisms of $L$
\[\sigma_{i_0}: L \to L, \quad \theta \mapsto \theta^{(i_0)} \quad \text{ and } \quad \sigma_{j}: L \to L, \quad \theta \mapsto \theta^{(j)},\]
respectively. That is, $\mathfrak{P}^{(i_0)} = \sigma_{i_0}(\mathfrak{P})$ and $\mathfrak{P}^{(j)} = \sigma_{j}(\mathfrak{P})$. Then
\[\left( \frac{\gamma_i^{(j)}}{\gamma_i^{(i_0)}}\right)\mathcal{O}_L
	 = \left(\prod_{\mathfrak{P}\mid\mathfrak{p}_1} \frac{\mathfrak{P}^{(j) \ e(\mathfrak{P}^{(j)}\mid\mathfrak{p}_1^{(j)})}}{\mathfrak{P}^{(i_0) \ e(\mathfrak{P}^{(i_0)}\mid\mathfrak{p}^{(i_0)}_1)}}\right)^{a_{1i}} \cdots \left(\prod_{\mathfrak{P}\mid\mathfrak{p}_{\nu}} \frac{\mathfrak{P}^{(j) \ e(\mathfrak{P}^{(j)}\mid\mathfrak{p}^{(j)}_{\nu})}}{\mathfrak{P}^{(i_0) \ e(\mathfrak{P}^{(i_0)}\mid\mathfrak{p}^{(i_0)}_{\nu})}}\right)^{a_{\nu i}}.\]

To show that $\mathfrak{P}^{(j)} \neq \mathfrak{P}^{(i_0)}$ for all $\mathfrak{P}$ lying above $\mathfrak{p}$ in $K$, we consider the decomposition group of $\mathfrak{P}$,
\[D(\mathfrak{P}|p) = \{\sigma \in G \ : \ \sigma(\mathfrak{P}) = \mathfrak{P}\}.\]
Iterating through all possible decompositions of $\mathfrak{p}$ in $L$, we observe that $\mathfrak{P}^{(i_0)} \neq \mathfrak{P}^{(j)}$ whenever $D(\mathfrak{P}_i|p)$ does not have cardinality $2$. Since $(i_0,j,k)$ forms an order $3$ subgroup of $\Gal(L/\mathbb{Q})$, it cannot coincide with $D(\mathfrak{P}|p)$ and therefore cannot lead to $\mathfrak{P}^{(i_0)} = \mathfrak{P}^{(j)}$.
\end{proof}

For the remainder of this paper, we assume that $(i_0,j,k)$ are automorphisms of $L$ selected as in Lemma~\ref{lem:cancellation}.

\begin{lemma}\label{lem:ordpz}
Let $\mathfrak{p}$ be a prime ideal of $\mathcal{O}_K$ and let $\mathfrak{P}$ denote an ideal of $\mathcal{O}_L$ lying above it. Let $\mathfrak{P}^{(i_0)} = \sigma_{i_0}(\mathfrak{P})$ and $\mathfrak{P}^{(j)} = \sigma_{j}(\mathfrak{P})$ be the prime ideals lying over $\mathfrak{p}^{(i_0)}$, $\mathfrak{p}^{(j)}$ respectively. We have
\[\ord_{\mathfrak{P}}\left(\frac{\delta_2}{\lambda}\right)=
\begin{cases}
(u_l - r_l)e(\mathfrak{P}^{(j)}|\mathfrak{p}_l^{(j)})
	& \textnormal{ if } \mathfrak{P}^{(j)} \mid p_l , \ p_l \in \{p_1,\dots, p_{\nu}\}\\
(r_l - u_l)e(\mathfrak{P}^{(i_0)}|\mathfrak{p}_l^{(i_0)})
	& \textnormal{ if } \mathfrak{P}^{(i_0)}\mid p_l, \ p_l \in \{p_1,\dots, p_{\nu}\}\\
0 	& \textnormal{ otherwise}.
\end{cases}\]
\end{lemma}
\begin{proof}

By Lemma~\ref{lem:cancellation}, we have
\begin{align*}
\left(\frac{\delta_2}{\lambda}\right)\mathcal{O}_L
	& = \left( \frac{\gamma_1^{(j)}}{\gamma_1^{(i_0)}}\right)^{n_1}\cdots \left( \frac{\gamma_{\nu}^{(j)}}{\gamma_{\nu}^{(i_0)}}\right)^{n_{\nu}} \mathcal{O}_L\\
	& = \left(\prod_{\mathfrak{P}\mid\mathfrak{p}_1} \frac{\mathfrak{P}^{(j) \ e(\mathfrak{P}^{(j)}\mid\mathfrak{p}_1^{(j)})}}{\mathfrak{P}^{(i_0) \ e(\mathfrak{P}^{(i_0)}\mid\mathfrak{p}^{(i_0)}_1)}}\right)^{u_1 - r_1} \cdots \left(\prod_{\mathfrak{P}\mid\mathfrak{p}_{\nu}} \frac{\mathfrak{P}^{(j) \ e(\mathfrak{P}^{(j)}\mid\mathfrak{p}^{(j)}_{\nu})}}{\mathfrak{P}^{(i_0) \ e(\mathfrak{P}^{(i_0)}\mid\mathfrak{p}^{(i_0)}_{\nu})}}\right)^{u_{\nu} - r_{\nu}}.
\end{align*}
It follows that
\[\ord_{\mathfrak{P}}\left( \frac{\delta_2}{\lambda}\right)=
\begin{cases}
(u_l - r_l)e(\mathfrak{P}^{(j)}|\mathfrak{p}_l^{(j)})
	& \textnormal{ if } \mathfrak{P}^{(j)} \mid p_l , \ p_l \in \{p_1,\dots, p_{\nu}\}\\
(r_l - u_l)e(\mathfrak{P}^{(i_0)}|\mathfrak{p}_l^{(i_0)})
	& \textnormal{ if } \mathfrak{P}^{(i_0)}\mid p_l, \ p_l \in \{p_1,\dots, p_{\nu}\}\\
0 	& \textnormal{ otherwise}.
\end{cases}\]
\end{proof}

Let $\log^+(\cdot)$ denote the real valued function $\max(\log(\cdot), 0)$ on $\mathbb{R}_{\geq 0}$.

\begin{proposition}\label{prop:heightdecomp}
The height $h(z)$ admits a decomposition
\begin{equation} \label{eq:hdecomp}
h(z) = \frac{1}{[K:\mathbb{Q}]}\sum_{l = 1}^{\nu} \log(p_l)|u_l - r_l| + \frac{1}{[L:\mathbb{Q}]}\sum_{w :L \to \mathbb{C}} \log^+|w(z)|.
\end{equation}
In particular, when $\deg(g(t)) = 3$,
\[\sum_{w :L \to \mathbb{C}} \log^+|w(z)| \leq 2\max_{w:L\to \mathbb{C}} \log^+|w(z)|\] where this bound becomes an equality if $ \Gal(L/\mathbb{Q}) \cong S_3$.
\end{proposition}
For ease of notation, let $S^* = S \cup \{w : L \to \mathbb{C}\}$ and write
\begin{align*}
  h(z) & = \frac{1}{[K:\mathbb{Q}]}\sum_{l = 1}^{\nu} \log(p_l)|u_l - r_l| +
         \frac{1}{[L:\mathbb{Q}]}\sum_{w :L \to \mathbb{C}} \log^+|w(z)| \\
       & = \frac{1}{[K:\mathbb{Q}]}\sum_{l = 1}^{\nu} h_{p_l}(z) +
         \frac{1}{[K:\mathbb{Q}]}\sum_{w :L \to \mathbb{C}} h_w(z)
\end{align*}
so that
\[h(z) = \frac{1}{[K:\mathbb{Q}]}\sum_{v \in S^*}h_{v}(z).\]
By Proposition~\ref{prop:heightdecomp}, when $v = p_l$ is a finite place,
\[h_{v}(z) = \log(p_l)|u_l - r_l|,\]
whereas we write
\[h_{v}(z) = \frac{1}{[L:K]} \log^+|w(z)|\]
for all infinite places $v = w:L \to \mathbb{C}$. When $\deg(g(t)) = 3$, we may thus write
\begin{align*}
  h(z) & = \frac{1}{[K:\mathbb{Q}]}\sum_{l = 1}^{\nu} h_{p_l}(z) +
         \frac{1}{[K:\mathbb{Q}]}\sum_{w :L \to \mathbb{C}} h_w(z)\\
       & \leq \frac{1}{[K:\mathbb{Q}]}\left(\sum_{l = 1}^{\nu} h_{p_l}(z) +
         2\max_{w :L \to \mathbb{C}} h_w(z)\right).
\end{align*}

\begin{proof}[Proof of Proposition~\ref{prop:heightdecomp}]Since $z \in L$, the definition of the absolute logarithmic Weil height gives
\[h(z) = \frac{1}{[L:\mathbb{Q}]}\sum_{w \in M_L} \log^+ \|z\|_w\]
where $||z||_w$ and $M_L$ are the usual norms and set of inequivalent absolute values on $L$, respectively. In particular, if $w: L \to \mathbb{C}$ is an infinite place,
\[ \log^+ \|z\|_{w} = \log^+|w(z)|.\]
If $w = \mathfrak{P}$ is a finite place, we have
\[ \log^+ \|z\|_{w} = \log^+ \left(\frac{1}{N(\mathfrak{P})^{\ord_{\mathfrak{P}}(z)}} \right). \]
Let $p_l \in S$ and $\mathfrak{P}^{(j)}\mid p_l$. Applying Lemma~\ref{lem:ordpz}, we obtain
\begin{align*}
\log^+ \|z\|_{w}
 	& = \log^+ \left(\frac{1}{N(\mathfrak{P})^{(u_l - r_l)e(\mathfrak{P}^{(j)}\mid\mathfrak{p}_l^{(j)})}} \right)\\
	& = \max \left\{ -(u_l - r_l)f(\mathfrak{P}^{(j)}\mid p_l)e(\mathfrak{P}^{(j)}\mid\mathfrak{p}_l^{(j)})\log(p_l), 0\right\}.
\end{align*}
For each $p_l \in S$, there is only one unique prime ideal $\mathfrak{p}_l \in \mathcal{O}_K$ in the ideal equation \eqref{eq:TMfactored} lying above $p_l$. Hence, each $\mathfrak{P}$ lying over $p_l$ must also lie over $\mathfrak{p}_l$. Now, for $w = \mathfrak{P}^{(j)}$ lying over $p_l$,
\begin{align*}
\sum_{w \mid \mathfrak{p}_l^{(j)}} \log^+ \|z\|_{w}
	& = \max \left\{ (r_l - u_l)\log(p_l), 0\right\}f(\mathfrak{p}_l^{(j)}\mid p_l)[L:\mathbb{Q}(\theta^{(j)})]\\
	& = \max \left\{ (r_l - u_l)\log(p_l), 0\right\}f(\mathfrak{p}_l^{(j)}\mid p_l)[L:K],
\end{align*}
where the last inequality follows from $K = \mathbb{Q}(\theta) \cong \mathbb{Q}(\theta^{(j)})$.

Similarly, applying Lemma~\ref{lem:ordpz} to all $w = \mathfrak{P}^{(i_0)}$ lying over $p_l \in S$, we obtain
\[\sum_{w \mid \mathfrak{p}_l^{(i_0)}} \log^+\|z\|_w = \max \left\{ (u_l - r_l)\log(p_l), 0\right\}f(\mathfrak{p}_l^{(i_0)}\mid p_l)[L:K].\]

Lastly, if $w = \mathfrak{P}$ such that $\mathfrak{P} \neq \mathfrak{P}^{(i_0)},  \mathfrak{P}^{(j)}$, we have $\log^+\|z\|_w = 0$. Putting this all together yields the first result \eqref{eq:hdecomp}.

To prove the second statement, write $z$ as the quotient $z = d^{(j)}/d^{(i_0)} \in L$. The orbit of $z$ is
\[\begin{cases}
\left\{\frac{d^{(j)}}{d^{(i_0)}}, \frac{d^{(k)}}{d^{(j)}}, \frac{d^{(i_0)}}{d^{(k)}}, \frac{d^{(j)}}{d^{(k)}}, \frac{d^{(k)}}{d^{(i_0)}}, \frac{d^{(i_0)}}{d^{(j)}} \right\} & \text{ if } \Gal(L/\mathbb{Q}) \cong S_3\\
\left\{\frac{d^{(j)}}{d^{(i_0)}}, \frac{d^{(k)}}{d^{(j)}}, \frac{d^{(i_0)}}{d^{(k)}}\right\} & \text{ if } \Gal(L/\mathbb{Q}) \cong A_3.
\end{cases}\]
Choose $a,b,c\in\{i_0,j,k\}$ such that
\[|d^{(a)}| \geq |d^{(b)}| \geq |d^{(c)}|.\]
If $\Gal(L/\mathbb{Q}) \cong S_3$,
\begin{align*}
  \sum_{w:L \to \mathbb{C}} \log^+|w(z)|
  & = \log^+\left|\frac{d^{(a)}}{d^{(b)}}\right| + \log^+\left|\frac{d^{(b)}}{d^{(c)}}\right| +
    \log^+\left|\frac{d^{(c)}}{d^{(a)}}\right| \\
  & \quad +  \log^+\left|\frac{d^{(a)}}{d^{(c)}}\right| +
    \log^+\left|\frac{d^{(a)}}{d^{(c)}}\right| + \log^+\left|\frac{d^{(c)}}{d^{(b)}}\right|\\
  & = \log \left|\frac{d^{(a)}}{d^{(b)}}\right| + \log \left|\frac{d^{(b)}}{d^{(c)}}\right| +
    \log \left|\frac{d^{(a)}}{d^{(c)}}\right| \\
  & = 2\log \left|\frac{d^{(a)}}{d^{(c)}}\right|\\
  & = 2\max_{w:L \to \mathbb{C}} \log^+|w(z)|.
\end{align*}
Alternatively, if $\Gal(L/\mathbb{Q}) \cong A_3$,
\begin{align*}
  \sum_{w:L \to \mathbb{C}} \log^+|w(z)|
  & = \log^+\left|\frac{d^{(a)}}{d^{(b)}}\right| + \log^+\left|\frac{d^{(b)}}{d^{(c)}}\right| +
    \log^+\left|\frac{d^{(c)}}{d^{(a)}}\right| \\
  & = \log \left|\frac{d^{(a)}}{d^{(b)}}\right| + \log \left|\frac{d^{(b)}}{d^{(c)}}\right| \\
  & \leq 2\max_{w:L \to \mathbb{C}}  \log^+|w(z)|.
\end{align*}
\end{proof}

%---------------------------------------------------------------------------------------------%

\section{Initial height bounds}
\label{sec:InitialHeightBounds}

We seek solutions to equaition~\eqref{eq:EfficientSunit}. We recall this equation presently,
\begin{equation*}
\lambda = \delta_1 \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)^{n_i} \prod_{i = 1}^r\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right)^{a_i} - 1 = \delta_2 \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(i_0)}}{\gamma_i^{(j)}}\right)^{n_i}\prod_{i = 1}^{r}\left( \frac{\varepsilon_i^{(i_0)}}{\varepsilon_i^{(j)}}\right)^{a_i}.
\end{equation*}
To simplify notation, we write
\[\tilde{y} =  \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)^{n_i}\prod_{i = 1}^r\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right)^{a_i}, \quad
\tilde{x} = \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(i_0)}}{\gamma_i^{(j)}}\right)^{n_i}\prod_{i = 1}^{r}\left( \frac{\varepsilon_i^{(i_0)}}{\varepsilon_i^{(j)}}\right)^{a_i}\]
so that equation~\eqref{eq:EfficientSunit} becomes
\begin{equation} \label{eq:TrueSunit}
\delta_1\tilde{y} - \delta_2\tilde{x} = 1.
\end{equation}
Let $z= \frac{1}{\tilde{x}} = \frac{\delta_2}{\lambda}$ and denote by $\Sigma$ the set of pairs $(\tilde{x},\tilde{y})$ satisfying \eqref{eq:TrueSunit}. That is, $\Sigma$ denotes the set of tuples $(n_1, \dots, n_{\nu}, a_1, \dots, a_r)$ corresponding to $(\tilde{x},\tilde{y})$ which satisfy \eqref{eq:TrueSunit}.

Let $\mathbf{l},\mathbf{h}\in\mathbb{R}^{\nu + m}$ with $\mathbf{0}\leq \mathbf{l}\leq \mathbf{h}$. Then we define $\Sigma(\mathbf{l},\mathbf{h})$ as the set of all $(\tilde{x},\tilde{y}) \in \Sigma$ such that $\left(h_v(z)\right)\leq \mathbf{h}$ and such that $\left(h_v(z)\right)\nleq \mathbf{l}$, and write $\Sigma(\mathbf{h})=\Sigma(\mathbf{l},\mathbf{h})$ if $\mathbf{l}=\mathbf{0}$. Additionally, for each place $w$, we denote by $\Sigma_w(\mathbf{l},\mathbf{h})$ the set of all $(\tilde{x},\tilde{y})\in\Sigma(\mathbf{h})$ such that $h_w(z)>l_w$.

Recall the minimal polynomial $g(t)$ of $K$, \eqref{eq:Efficientg}, derived from
\[f(x,y) = x^3 + C_1 x^{2}y + C_2xy^2 + C_3y^3 = cp_1^{z_1}\cdots p_v^{z_v}.\]
For $S = \{p_1, \dots, p_v\}$, let $N_S = \prod_{p\in S}p$ and set
\[b_S	 = 1728 N_S^2 \prod_{p \notin S} p^{\min(2,\ord_p(b))}\]
for any integer $b$. In particular, we take $b = 432 \Delta c^2$ with $\Delta$ the discriminant of $f$. Denote by $h(f-c)$ the maximum logarithmic Weil heights of the coefficients of the polynomial $f - c$,
\[h(f-c) = \max(\log|C_1|, \log|C_2|, \log|C_3|, \log|c|).\]

Now, setting
\[\Omega' = 2b_S \log(b_S) + 172h(f-c),\]
we obtain, by Corollary J (ii) of \cite{KanMat}, the following height bound on any solution $(x,y)$ of \eqref{eq:Efficientpoly}
\[\max(h(x),h(y))\leq \Omega'.\]
To translate this result for use with our logarithmic Weil height \eqref{eq:hdecomp}, we have the following lemma.
\begin{lemma} \label{lem:TMinitialheight}
Let ${\mathbf{m} = (n_1, \dots, n_{\nu}, a_1, \dots, a_r) \in \mathbb{R}^{r + \nu}}$ be any solution of \eqref{eq:EfficientSunit} and let
\begin{equation} \label{eq:Omegaprime}
\Omega = [K:\mathbb{Q}](2h(\alpha) + 4\Omega' + 2h(\theta) + 2\log(2)).
\end{equation}
If $\mathbf{h} \in\mathbb{R}^{\nu + m}$ with $\mathbf{h} = (\Omega)$, then $\mathbf{m}\in \Sigma(h)$.
\end{lemma}

\begin{proof}
Let $(\tilde{x},\tilde{y}) \in \Sigma$. We show that the corresponding value $z = \frac{1}{\tilde{x}} = \frac{\delta_2}{\lambda}$ arising from this choice of $\tilde{x},\tilde{y}$ satisfies
\[\mathbf{0} < \left(h_v(z)\right)\leq \mathbf{h}.\]

As stated earlier, any solution $x,y$ of $f(x,y) = c p_1^{z_1}\cdots p_v^{z_v}$ satisfies
\[\max(h(x),h(y)) \leq \Omega'.\]
Taking the height of
\[\beta = x-y\theta = \alpha \zeta \varepsilon_1^{a_1} \cdots \varepsilon_r^{a_r}\cdot \gamma_1^{n_1}\cdots \gamma_{\nu}^{n_{\nu}},\]
we obtain
\[h(\beta) = h(x) + h(\theta) + h(y) + \log{2}  \leq 2\Omega' + h(\theta) + \log{2}.\]
In particular, as $h(\beta) = h(\beta^{(i)})$,
\[h(\beta^{(i)}) \leq 2\Omega' + h(\theta) + \log{2}.\]
Now,
\[\delta_2\tilde{x}
	= \frac{\theta^{(j)} - \theta^{(k)}}{\theta^{(k)} - \theta^{(i_0)}}\cdot \frac{\alpha^{(i_0)}\zeta^{(i_0)}}{\alpha^{(j)}\zeta^{(j)}} \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(i_0)}}{\gamma_i^{(j)}}\right)^{n_i}\prod_{i = 1}^{r}\left( \frac{\varepsilon_i^{(i_0)}}{\varepsilon_i^{(j)}}\right)^{a_i}
	= \frac{\theta^{(j)} - \theta^{(k)}}{\theta^{(k)} - \theta^{(i_0)}}\cdot \frac{\beta^{(i_0)}}{\beta^{(j)}},\]
meaning that $\tilde{x}$ may be written as
\[\tilde{x} =\frac{\beta^{(i_0)}}{\beta^{(j)}}\cdot \frac{\alpha^{(j)}\zeta^{(j)}}{\alpha^{(i_0)}\zeta^{(i_0)}}.\]
Hence,
\[h(\tilde{x})	 = 2h(\beta) + 2h(\alpha) \leq 4\Omega' + 2h(\theta) + 2\log{2} + 2h(\alpha).\]
Finally, we observer that
\[h(z) = h(1/\tilde{x}) \leq 4\Omega' + 2h(\theta) + 2\log{2} + 2h(\alpha).\]
Together with $\displaystyle \frac{1}{[K:\mathbb{Q}]}h_v(z) \leq h(z)$, this implies
\[h_v(z) \leq [K:\mathbb{Q}](4\Omega' + 2h(\theta) + 2\log{2} + 2h(\alpha)) = \Omega.\]
Of course, by definition, we have $h_v(z) \geq 0$, so that $(\tilde{x},\tilde{y}) \in \Sigma(h)$ as required.
\end{proof}

%---------------------------------------------------------------------------------------------%

\section{Coverings of $\Sigma$}
\label{sec:CoveringsofSigma}

From \autoref{sec:InitialHeightBounds}, we now know that all solutions $(\tilde{x},\tilde{y}) \in \Sigma$ satisfy $\mathbf{m}\in \Sigma(h)$ if ${\mathbf{h} = (\Omega')}$. In the notation of \autoref{sec:InitialHeightBounds}, we have the following result.

\begin{lemma}\label{lem:covering}
Let $\mathbf{l},\mathbf{h}\in\mathbb{R}^{\nu+m}$ with $\mathbf{0}\leq \mathbf{l}\leq \mathbf{h}$. It holds that $\Sigma(\mathbf{h})=\Sigma(\mathbf{l},\mathbf{h})\cup \Sigma(\mathbf{l})$ and $\Sigma(\mathbf{l},\mathbf{h})=\cup_{v \in S^*}\Sigma_v(\mathbf{l},\mathbf{h})$.
\end{lemma}

\begin{proof}
Suppose $(\tilde{x},\tilde{y}) \in \Sigma(\mathbf{h})$. By definition this means, $(h_v(z))\leq \mathbf{h}$ and that $h_v(z) > 0$ for at least one coordinate $v$. Since $\mathbf{0} \leq \mathbf{l} \leq \mathbf{h}$, it follows that either $(h_v(z))\leq \mathbf{l}$ or $(h_v(z))\nleq \mathbf{l}$. That is, either all coordinates satisfy $h_v(z) \leq l_v$, or there is at least one coordinate for which $h_v(z) > l_v$. This means that either $(\tilde{x},\tilde{y}) \in \Sigma(\mathbf{l})$ or $(\tilde{x},\tilde{y}) \in \Sigma(\mathbf{l},\mathbf{h})$, and so $\Sigma(\mathbf{h}) \subseteq \Sigma(\mathbf{l},\mathbf{h}) \cup \Sigma(\mathbf{l})$.

Conversely, suppose  $(\tilde{x},\tilde{y}) \in \Sigma(\mathbf{l},\mathbf{h}) \cup \Sigma(\mathbf{l})$. It follows that either $(h_v(z))\leq \mathbf{h} \text{ and } (h_v(z))\nleq \mathbf{l}$ or $(h_v(z))\leq \mathbf{l} \text{ and } (h_v(z))\nleq \mathbf{0}$. In either case, this means that $(h_v(z)) \leq \mathbf{h}$ and $(h_v(z)) \nleq \mathbf{0}$. Hence $(\tilde{x},\tilde{y}) \in \Sigma(\mathbf{h})$ and $\Sigma(\mathbf{h}) \supseteq \Sigma(\mathbf{l},\mathbf{h}) \cup \Sigma(\mathbf{l})$.

To prove the second equality, let $(\tilde{x},\tilde{y}) \in \Sigma(\mathbf{l},\mathbf{h})$. Then there exists $w\in S^*$ with $h_w(z)>l_w$ so that $(\tilde{x},\tilde{y})$ lies in $\Sigma_w(\mathbf{l},\mathbf{h})$. Hence $\Sigma(\mathbf{l},\mathbf{h}) \subseteq \cup_{v\in S^*}\Sigma_v(\mathbf{l},\mathbf{h})$. Lastly, since each set $\Sigma_v(\mathbf{l},\mathbf{h})$ is contained in $\Sigma(\mathbf{l},\mathbf{h})$ it follows that $\Sigma(\mathbf{l},\mathbf{h})=\cup_{v\in S^*}\Sigma_v(\mathbf{l},\mathbf{h})$ as required.
\end{proof}

Let $\mathbf{h}_0 = (\Omega', \dots, \Omega')$ denote the vector consisting of the initial bound $\Omega'$. By Proposition~\ref{lem:TMinitialheight}, every solution of \eqref{eq:EfficientSunit} is contained in $\mathbf{h}_0$. Therefore, we write $\Sigma = \Sigma(\mathbf{h}_0)$. Consider the pairs $(\mathbf{l}_n,\mathbf{h}_n)\in \mathbb{R}^{\nu + m}\times \mathbb{R}^{\nu + m}$ with $\mathbf{0}\leq \mathbf{l}_n\leq \mathbf{h}_n$ and $\mathbf{h}_{n+1}=\mathbf{l}_{n}$ for $n=0,\dotsc,N$. Then we can cover $\Sigma$:
$$\Sigma=\Sigma(\mathbf{l}_{N})\cup\bigl(\cup_{n=0}^{N}\cup_{v\in S^*}\Sigma_v(\mathbf{l}_n,\mathbf{h}_n)\bigl).$$
Indeed this follows directly by applying Lemma~\ref{lem:covering} $N$ times. In particular, Lemma~\ref{lem:covering} gives  $$\Sigma=\Sigma(\mathbf{h}_0), \quad \Sigma(\mathbf{h})=\Sigma(\mathbf{l},\mathbf{h})\cup \Sigma(\mathbf{l}) \quad \textnormal{and} \quad \Sigma(\mathbf{l},\mathbf{h})=\cup_{v\in S^*}\Sigma_v(\mathbf{l},\mathbf{h}).$$
After choosing a good sequence of lower and upper bounds $\mathbf{l}_n,\mathbf{h}_n$ covering the whole space $\Sigma$, we are reduced to computing $\Sigma_v(\mathbf{l},\mathbf{h})$ for each $v \in S^*$. In the following section, we construct the ellipsoids associated to each $\Sigma_v(\mathbf{l},\mathbf{h})$, after which we describe the sieve allowing us to compute the solutions of each $\Sigma_v(\mathbf{l},\mathbf{h})$.

%---------------------------------------------------------------------------------------------%

\section{Construction of the ellipsoids}
\label{sec:ConstructionofEllipsoids}

In \autoref{sec:CoveringsofSigma}, we establish that for a suitable pair of vectors $\mathbf{l}, \mathbf{h}$, solving \eqref{eq:EfficientSunit} reduces to computing $\Sigma_v(\mathbf{l},\mathbf{h})$ for each $v \in S^*$. In this section, we construct the ellipsoids associated to each $\Sigma_v(\mathbf{l},\mathbf{h})$, which will subsequently allow us to compute all solutions of $\Sigma_v(\mathbf{l},\mathbf{h})$.

We begin with the quadratic form $q_f=A^TD^2A$ on $\mathbb{Z}^{\nu}$, where $D$ is a $\nu \times \nu$ diagonal matrix with diagonal entries $\log^*(p_i)$ for $p_i \in S$. Here, by $\log^*(p_i)$ we mean the best continued fraction approximation $P_n/Q_n$ to $\log(p_i)$ as determined by the precision on $\log(p_i)$, and such that $P_n/Q_n \leq \log(p_i)$. That is, the convergent $P_n/Q_n$ has $n$ odd.

Recall that $A$ is the matrix generated in either \autoref{subsec:FactorizationTMwithoutOK} or \autoref{subsec:FactorizationTMwithoutOK}. As $A$ is invertible, our choice of entries in $D$ guarantees that this quadratic form is positive definite. This will become very important later in the sieve when we will need to apply many instances of the Fincke-Pohst algorithm.

\begin{lemma} \label{lem:boundqf}
For any solution $( n_1, \dots, n_{\nu}, a_1, \dots, a_r)$ of \eqref{eq:EfficientSunit} with $\mathbf{n} = (n_1, \dots, n_{\nu})$, we have
\[q_f(\mathbf{n}) \leq \sum_{l = 1}^{\nu}\log(p_l)^2|u_l -r_l|^2.\]
\end{lemma}

\begin{proof}
Recall from \autoref{subsec:FactorizationTMwithoutOK} and \autoref{subsec:FactorizationTMwithOK} that
\[A\mathbf{n} = \mathbf{u} - \mathbf{r}.\]
%Assume first that $2 \notin S$ so that
\begin{align*}
  q_f(\mathbf{n})
  = (A\mathbf{n})^{\text{T}}D^2A\mathbf{n}
  = (\mathbf{u} - \mathbf{r})^{\text{T}}D^2(\mathbf{u} - \mathbf{r})
  = \sum_{l = 1}^{\nu}\log^*(p_l)^2|u_l-r_l|^2
  \leq \sum_{l = 1}^{\nu}\log(p_l)^2|u_l-r_l|^2.
\end{align*}
% Multiplication by $\frac{\log(2)^2}{[K:\mathbb{Q}]}$ then gives
% \begin{align*}
% \frac{\log(2)^2}{[K:\mathbb{Q}]}q_f(\mathbf{n})
% 	& = \frac{\log(2)^2}{[K:\mathbb{Q}]}\sum_{l = 1}^{\nu} \left\lfloor\frac{\log(p_l)^2}{\log(2)^2}\right\rfloor|u_l -r_l|^2 \\
%  	& \leq \frac{1}{[K:\mathbb{Q}]}\sum_{l = 1}^{\nu}\log(p_l)^2|u_l -r_l|^2,
% \end{align*}
% where all terms in the summand are positive.

% If $2 \in S$, we have
% \begin{align*}
% q_f(\mathbf{n})
% 	 = (A\mathbf{n})^{\text{T}}D^2A\mathbf{n}
% 	 = |u_1 - r_1|^2 + \sum_{l = 2}^{\nu}\left\lfloor\frac{\log(p_l)^2}{\log(2)^2}\right\rfloor|u_l-r_l|^2.
% \end{align*}
% It follows that
% \begin{align*}
% \frac{\log(2)^2}{[K:\mathbb{Q}]}q_f(\mathbf{n})
% 	& \leq \frac{\log(2)^2}{[K:\mathbb{Q}]}\left( |u_1 - r_1|^2 + \sum_{l = 2}^{\nu} \frac{\log(p_l)^2}{\log(2)^2}|u_l -r_l|^2\right) \\
% 	& = \frac{1}{[K:\mathbb{Q}]}\sum_{l = 1}^{\nu}\log(p_l)^2|u_l -r_l|^2.
% \end{align*}
\end{proof}

%Following \autoref{sec:continued-fractions}, we recall that
%\[ |\log(p_l) - \log^*(p_l)| = \left|\log(p_l) - \frac{P_n}{Q_n}\right| < \frac{1}{Q_nQ_{n+1}}.\]

We now briefly re-examine the decomposition of $h(z)$ into local heights,
\begin{align*}
  h(z) & = \frac{1}{[K:\mathbb{Q}]}\sum_{l = 1}^{\nu} \log(p_l)|u_l - r_l| +
         \frac{1}{[L:\mathbb{Q}]}\sum_{w :L \to \mathbb{C}} \log^+|w(z)|\\
       & = \frac{1}{[K:\mathbb{Q}]}\left(\sum_{l = 1}^{\nu} \log(p_l)|u_l - r_l| +
         \frac{1}{[L:K]}\sum_{w :L \to \mathbb{C}} \log^+|w(z)|\right)\\
       & \leq \frac{1}{[K:\mathbb{Q}]}\left(\sum_{l = 1}^{\nu} \log(p_l)|u_l - r_l| +
         2\max_{w :L \to \mathbb{C}} \frac{\log^+|w(z)|}{[L:K]}\right)\\
\end{align*}

For every finite place $v$, Lemma~\ref{lem:boundqf} tells us that any set of bounds $\{h_v\}_{v \in S}$ on the set $\{h_v(z)\}_{v \in S}$ yields a bound on $q_f(\mathbf{n})$. In particular, we have
\[ q_f(\mathbf{n}) \leq \sum_{l = 1}^{\nu}\log(p_l)^2|u_l -r_l|^2 \leq \sum_{l = 1}^{\nu} h_l^2.\]
In the remainder of this section, we build analogous bounds on the exponents $a_1, \dots, a_r$ of the fundamental units.

Recall $r = 1$ or $r = 2$ for the degree $3$ Thue-Mahler equation~\eqref{eq:Efficientpoly} in question. Choose a set $I$ of embeddings $L \rightarrow \mathbb{C}$ of cardinality $r$. For $r = 1$, consider the matrix
\[R = \begin{pmatrix}
	\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_1}\right| \end{pmatrix},\]
where $I = \{\iota_1\}$. Clearly, as long as we choose $\iota_1$ such that $\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_1}\right| \neq 0$, this matrix is invertible.

When $r = 2$, we let $I$ be the set of embeddings $L \to \mathbb{C}$ of cardinality $2$ such that for any $\alpha \in K$, it holds that $I\alpha^{(i_0)} \cup I\alpha^{(j)} = \Gal(L/\mathbb{Q})\alpha$. For $I = \{\iota_1, \iota_2\}$, let $R$ be the $2 \times 2$ matrix
\[R = \begin{pmatrix}
	\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_1}\right| &
	\log\left|\left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_1}\right|\\
	\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_2}\right| &
	\log\left|\left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_2}\right|\\
	\end{pmatrix}.\]
\begin{lemma}
When $r = 2$, the matrix $R$ has an inverse,
\[R^{-1} = \begin{pmatrix}
	\overline{r}_{11} & \overline{r}_{12} \\
	\overline{r}_{21} & \overline{r}_{22}
\end{pmatrix}.\]
\end{lemma}

\begin{proof}
Suppose that $\mathbf{m}\in\mathbb{Z}^{2}$ satisfies $R\mathbf{m}=\mathbf{0}$. Then for each $\iota\in I$ it holds that
\[m_{1} \log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota}\right| + m_{2} \log\left|\left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota}\right| =0,\] and hence
\[\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota}\right|^{m_1}\cdot\left|\left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota}\right|^{m_2}=1.\]
This together with $I(i)\cup I(j)=Gal(L/\mathbb{Q})$ implies that all conjugates of $\alpha=\eps_1^{m_1}\eps_2^{m_2}$ have the same absolute value. Since all $\eps_i$ are units of $\mathcal{O}_K$, it follows that $|\alpha|^{[L:\mathbb{Q}]}=N(\alpha)=1$ and hence $\alpha$ is a root of unity in $K$. On using that  the elements $\eps_i$ are multiplicatively independent, we obtain that $\mathbf{m}=\mathbf{0}$.  Then linear algebra gives $R^{-1}\in\mathbb{R}^{2\times 2}$, completing the proof.
\end{proof}

For the remainder of this chapter, we specialize to the real case, $r = 2$. The setup for $r = 1$ follows closely the work described here, yet poses other difficulties when defining the corresponding sieves.

Now, for any solution $(n_1, \dots, n_{\nu}, a_1, a_2)$ of \eqref{eq:EfficientSunit}, set
\[\mathbf{\eps} = \begin{pmatrix} a_1 & a_2 \end{pmatrix}^{\text{T}}.\]
We have
\begin{align*}
  R{\varepsilon}
  & = \begin{pmatrix}
    \log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_1 \ a_1} \cdot
      \left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_1 \ a_2}\right| \\
    \log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_2\ a_2} \cdot
      \left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_2 \ a_2}\right|
  \end{pmatrix}.
\end{align*}
Since $R$ is invertible with $R^{-1} = (\overline{r}_{nm})$, we find
\begin{align*}
  {\varepsilon}
  & = \begin{pmatrix} \overline{r}_{11}\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_1 \ a_1} \cdot \left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_1 \ a_2}\right| +\overline{r}_{12}\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_2\ a_1}\cdot \left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_2 \ a_2}\right| \\
\overline{r}_{21}\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_1 \ a_1}\cdot \left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_1 \ a_2}\right| + \overline{r}_{22}\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_2\ a_1}\cdot \left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_2 \ a_2}\right|
  \end{pmatrix},
\end{align*}
giving
\[a_l = \overline{r}_{l1}\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_1 \ a_1}\cdot \left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_1 \ a_2}\right| +
\overline{r}_{l2}\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_2\ a_1}\cdot \left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_2 \ a_2}\right|\]
for $l = 1,2$.

To estimate $|a_l|$, we begin to estimate the sum on the right hand side. For this, we consider
\[z = \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(j)}}{\gamma_i^{(i_0)}}\right)^{n_i}\left( \frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{a_1}\left( \frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{a_2}.\]
For any embedding $\iota: L \to \mathbb{C}$, we have
\[(z)^{\iota} \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(i_0)}}{\gamma_i^{(j)}}\right)^{\iota \ n_i} =  \left( \frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota \ a_1}\left( \frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota \ a_2}.\]

In particular
\[\left|(z)^{\iota} \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(i_0)}}{\gamma_i^{(j)}}\right)^{\iota \ n_i}\right| = \left|\left( \frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota \ a_1}\left( \frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota \ a_2}\right|,\]
so that
\begin{align*}
\log\left|\left( \frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota \ a_1}\left( \frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota \ a_2}\right|
	& = \log|\iota(z)| - \log\left| \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(j)}}{\gamma_i^{(i_0)}}\right)^{\iota \ n_i}\right|.
\end{align*}

Hence, for $l =1,2$,
\begin{align*}
a_l	& = \overline{r}_{l1}\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_1 \ a_1} 		\cdot \left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_1 \ a_2}\right| +
	\overline{r}_{l2}\log\left|\left(\frac{\varepsilon_1^{(j)}}{\varepsilon_1^{(i_0)}}\right)^{\iota_2\ a_1}
	\cdot \left(\frac{\varepsilon_2^{(j)}}{\varepsilon_2^{(i_0)}}\right)^{\iota_2 \ a_2}\right|\\
	& = \overline{r}_{l1}\left( \log|\iota_1(z)| - \log\left| \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(j)}}{\gamma_i^{(i_0)}}\right)^{\iota_1 \ n_i}\right|\right) + \\
	& \quad \quad + \overline{r}_{l2}\left( \log|\iota_2(z)| - \log\left| \prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(j)}}{\gamma_i^{(i_0)}}\right)^{\iota_2 \ n_i}\right|\right)\\
	& = \overline{r}_{l1}\log|\iota_1(z)| + \overline{r}_{l2}\log|\iota_2(z)| - n_1\beta_{\gamma_1 l} - \dots - n_{\nu}\beta_{\gamma_{\nu} l},
\end{align*}
where
\[\beta_{\gamma_k l} = \left(\overline{r}_{l1} \log\left| \iota_1\left( \frac{\gamma_k^{(j)}}{\gamma_k^{(i_0)}}\right)\right|+ \overline{r}_{l2}\log\left| \iota_2\left( \frac{\gamma_k^{(j)}}{\gamma_k^{(i_0)}}\right)\right|\right)\]
for $k = 1, \dots, \nu$. Recall that $\mathbf{n} = A^{-1}(\mathbf{u} - \mathbf{r})$ and suppose $A^{-1} = (\overline{a}_{nm})$. We have
\[\mathbf{n}  = A^{-1}(\mathbf{u} - \mathbf{r})
	 = \begin{pmatrix} \sum_{k=1}^{\nu} \overline{a}_{1k}(u_k-r_k)\\  \vdots \\ \sum_{k=1}^{\nu} \overline{a}_{\nu k}(u_k-r_k) \end{pmatrix},\]
so that we may rewrite each $a_l$ as
\[a_l = \overline{r}_{l1}\log|\iota_1(z)| + \overline{r}_{l2}\log|\iota_2(z)| - \sum_{k=1}^{\nu}(u_k-r_k)\alpha_{\gamma l k},\]
where
\[\alpha_{\gamma l k} = \overline{a}_{1k}\beta_{\gamma_1 l} + \cdots + \overline{a}_{\nu k}\beta_{\gamma_{\nu} l}.\]

Taking absolute values, we obtain
\[|a_l| \leq |\overline{r}_{l1}||\log|\iota_1(z)|| + |\overline{r}_{l2}||\log|\iota_2(z)|| + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|.\]

Suppose $\log|\iota_1(z)| \geq 0$ and $\log|\iota_2(z)| \geq 0$. Then
\begin{align*}
|a_l| 	& \leq |\overline{r}_{l1}|\log|\iota_1(z)| + |\overline{r}_{l2}|\log|\iota_2(z)| + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|\\
	&  \leq \max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}\sum_{w: L \to \mathbb{C}}\log^+|w(z)| + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|.
\end{align*}
Applying Proposition \ref{prop:heightdecomp} yields
\[|a_l| \leq 2\max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}\max_{w:L\to \mathbb{C}} \log^+|w(z)| +  \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|.\]

Alternatively, suppose that both $\log|\iota_1(z)| < 0$ and $\log|\iota_2(z)| < 0$. We recall that $z$ is a quotient of elements which are conjugate to one another. By taking the norm of $z$ in $L$, we obtain $N(z) = 1.$ On the other hand, by definition, we have
\[1 = N(z) = \prod_{w : L \to \mathbb{C}}w(z).\]
Taking absolute values and logarithms,
\[0 = \sum_{w: L \to \mathbb{C}} \log|w(z)|\]
so that
\[ -\log|\iota(z)| = \sum_{\shortstack{\footnotesize $w: L \to \mathbb{C} $\\ \footnotesize $ w\neq \iota$}} \log|w(z)|.\]
In our present case, we use this equivalence to obtain a bound on $|a_l|$ as follows.
\begin{align*}
|a_l| 	& \leq |\overline{r}_{l1}|\sum_{\shortstack{\footnotesize $w: L \to \mathbb{C} $\\ \footnotesize $w \neq \iota_1$}} \log|w(z)| - |\overline{r}_{l2}|\log|\iota_2(z)| + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|\\
	& \leq 2\max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}\max_{w: L \to \mathbb{C}} \log^+|w(z)|  + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|.
\end{align*}
\edit{This bound is not correct in general, and there is something wrong...}

Here, the second inequality follows again by Proposition \ref{prop:heightdecomp}. Lastly, if, without loss of generality, we have $\log|\iota_1(z)| < 0$ and $\log|\iota_2(z)| \geq 0$, then
\begin{align*}
|a_l| 	& \leq |\overline{r}_{l1}|\sum_{\shortstack{\footnotesize $w: L \to \mathbb{C} $\\ \footnotesize $w \neq \iota_1$}} \log|w(z)| + |\overline{r}_{l2}|\log|\iota_2(z)| + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|\\
	& \leq 3\max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\}\max_{w: L \to \mathbb{C}} \log^+|w(z)| + \sum_{k=1}^{\nu}|u_k-r_k||\alpha_{\gamma l k}|.
\end{align*}

Now, let
\begin{equation} \label{eq:wepslk}
w_{\eps l} = 3\max\{|\overline{r}_{l1}|, |\overline{r}_{l2}|\},
\end{equation}
and
\begin{equation} \label{eq:wgammalk}
w_{\gamma l k} = \frac{|\alpha_{\gamma l k}|}{\log(p_k)},
\end{equation}
where
\[\alpha_{\gamma l k} = \overline{a}_{1k}\beta_{\gamma_1 l} + \cdots + \overline{a}_{\nu k}\beta_{\gamma_{\nu} l},\]
and
\[\beta_{\gamma_k l} = \left(\overline{r}_{l1} \log\left| \left( \frac{\gamma_k^{(j)}}{\gamma_k^{(i_0)}}\right)^{\iota_1}\right|+ \overline{r}_{l2}\log\left| \left( \frac{\gamma_k^{(j)}}{\gamma_k^{(i_0)}}\right)^{\iota_2}\right|\right)\]
for $k = 1, \dots, \nu$. We have proven the following lemma.
\begin{lemma}\label{lem:mepsbound}
For any solution $(n_1, \dots, n_{\nu},a_1, \dots, a_r)$ of \eqref{eq:EfficientSunit}, for $l =1,2$, we have
\[|a_l| \leq w_{\eps l}\max_{w:L \to \mathbb{C}} \log^+|w(z)| + \sum_{k = 1}^{\nu} w_{\gamma l k}\log(p_k)|u_k - r_k|.\]
%|a_l| & \leq  w_{\varepsilon l} \frac{b}{[L:\mathbb{Q}]} \max_{\sigma :L \to \mathbb{C}} \log \max \left\{ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} \\
%%&\leq \frac{1}{[L:\mathbb{Q}]}\sum_{\sigma :L \to \mathbb{C}} w_{\varepsilon l \sigma}\log \max \left\{ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} \\
%	& \quad \quad+ \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{\gamma l k}\log(p_k)|u_k - r_k|.
\end{lemma}

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %

\subsection{The Archimedean ellipsoid: the real case}
\label{subsec:ArchEllipsoid}

\edit{didn't update this section}

Let $\tau:L\to\mathbb{R} \subset \mathbb{C}$ be an embedding and let $l_\tau\geq c_\tau$ and $c>0$ be given real numbers for $c_\tau=\log^+(2|\tau(\delta_2)|)$. We define
\begin{equation} \label{eq:alpha0eps}
\alpha_0 = [c\log|\tau(\delta_1)|], \;  \; \alpha_{\varepsilon 1} =  \left[c\log\left|\tau\left(\frac{\varepsilon_1^{(k)}}{\varepsilon_1^{(j)}}\right)\right|\right],\ \  \alpha_{\varepsilon 2} =  \left[c\log\left|\tau\left(\frac{\varepsilon_2^{(k)}}{\varepsilon_2^{(j)}}\right)\right|\right].
\end{equation}
For $i = 1, \dots, \nu$, define
\begin{equation} \label{eq:alphagamma}
\alpha_{\gamma i} = \left[c\log\left|\tau\left(\frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)\right|\right].
\end{equation}
Here, $[ \ \cdot\  ]$ denotes the nearest integer function.

Let
\begin{equation} \label{eq:wsigma}
w_{\varepsilon} = \frac{w_{\varepsilon 1} + w_{\varepsilon 2}}{2}, \quad \quad w_{\gamma k} = \frac{w_{\gamma 1 k} + w_{\gamma 2 k}}{2} + \frac{1}{2\log(p_k)}\sum_{i=1}^{\nu}|\overline{a}_{ik}|
\end{equation}
for $k = 1, \dots, \nu$. Here $w_{\eps 1}, w_{\eps 2}$ and $w_{\gamma 1 k}, w_{\gamma 2 k}$ are the coefficients \eqref{eq:wepslk} and \eqref{eq:wgammalk}, respectively. Let $\kappa_{\tau} = 3/2$ and recall  that
\[h_{\tau}(z) = \frac{1}{[L:K]}\log^+|\tau(z)|\]
denotes the local height of $z$ at $\tau$ in the decomposition of $h(z)$.

\begin{lemma}\label{lem:archellest}
Let $(n_1, \dots, n_{\nu}, a_1, \dots, a_r)$ be any solution of \eqref{eq:EfficientSunit}. If $h_{\tau}(z) > c_{\tau}$, then
\begin{align*}
& \left|\alpha_0+\sum_{i = 1}^r a_i \alpha_{\varepsilon i} + \sum_{i = 1}^{\nu} n_i \alpha_{\gamma i}\right| \\
	& \quad \quad \leq \frac{1}{2} + w_{\eps} \max_{w :L \to \mathbb{C}}\log^+|w(z)| + \sum_{l = 1}^{\nu}w_{\gamma l} \log(p_l)|u_l - r_l| + c\kappa_{\tau}e^{-h_{\tau}(z)}
\end{align*}
\end{lemma}

\begin{proof}
Let
\[\alpha_{\tau} = \alpha_0+\sum_{i = 1}^r a_i \alpha_{\varepsilon i} + \sum_{i = 1}^{\nu} n_i \alpha_{\gamma i}\]
and
\[\Lambda_{\tau} = \log\left|\tau\left(\delta_1 \prod_{i = 1}^r\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right)^{a_i}\prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)^{n_i}\right)\right|.\]
We claim that
\[\tau\left(\delta_1 \prod_{i = 1}^r\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right)^{a_i}\prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)^{n_i}\right) > 0.\]
Indeed, $h_{\tau}(z) > c_\tau$ by assumption, hence
\[\max \left\{|\tau(z)|, 1\right\}  > \max\{2|\tau(\delta_2)|,1\}.\]
From this inequality, we must have that $\max \{|\tau(z)|,1\} = |\tau(z)|$ and so
\[2|\tau(\delta_2)| < |\tau(z)| = \frac{|\tau(\delta_2)|}{|\tau(\lambda)|} \implies |\tau(\lambda)| < \frac{1}{2}.\]
Recall that $\delta_1\tilde{y} - \delta_2\tilde{x} = 1$. This is the equation \eqref{eq:TrueSunit} defined earlier. In particular, observe that $\lambda = \delta_2\tilde{x}$ so that applying $\tau$ gives
\[\tau(\lambda) = \tau(\delta_2\tilde{x}) = \tau(\delta_1\tilde{y}) - 1.\]
Thus
\[|\tau(\lambda)| < \frac{1}{2} \implies \tau(\delta_1\tilde{y}) = \tau(\lambda) + 1 > 0.\]
This proves our claim
\[\tau(\delta_1\tilde{y}) = \tau\left(\delta_1 \prod_{i = 1}^r\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right)^{a_i}\prod_{i = 1}^{\nu} \left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)^{n_i}\right) > 0.\]
Having established this, we may now write
\[\Lambda_{\tau} = \log\left(\tau\left(\delta_1\right)\right) + \sum_{i=1}^r a_i\log\left(\tau\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right) \right) + \sum_{i=1}^{\nu}n_i\log \left(\tau\left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)\right).\]
By the triangle inequality,
\[|\alpha_{\tau}| \leq |\alpha_{\tau} - c\Lambda_{\tau}| + c|\Lambda_{\tau}|,\]
where
\begin{align*}
|\alpha_{\tau}-c\Lambda_\tau|
	& \leq \left| [c\log(\tau(\delta_1))] - c\log\left(\tau\left(\delta_1\right)\right)\right| \\
	& \quad \quad  + \sum_{i = 1}^r |a_i|\left| \left[c\log\left(\tau\left(\frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right)\right)\right] - c\log\left(\tau\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(j)}}\right) \right)\right|\\
	& \quad \quad +  \sum_{i = 1}^{\nu} |n_i|\left| \left[c\log\left(\tau\left(\frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)\right)\right] - c\log \left(\tau\left( \frac{\gamma_i^{(k)}}{\gamma_i^{(j)}}\right)\right)\right|.
\end{align*}
Since $[ \ \cdot \ ]$ denotes the nearest integer function, it is clear that $|[ \ c \ ] - c| \leq 1/2$ for any integer $c$,
\begin{align*}
|\alpha_{\tau}-c\Lambda_\tau|
	& \leq \frac{1}{2} + \frac{1}{2}\sum_{i = 1}^r |a_i| + \frac{1}{2}\sum_{i = 1}^{\nu} |n_i|\\
	& \leq \frac{1}{2}\left(1 + \sum_{i = 1}^r |a_i| + |u_1-r_1|\sum_{i=1}^{\nu}|\overline{a}_{i1}| + \cdots + |u_{\nu} - r_{\nu}| \sum_{i=1}^{\nu}|\overline{a}_{i\nu}|\right).
\end{align*}
Applying Lemma~\ref{lem:mepsbound}, this becomes
\begin{align*}
|\alpha_{\tau}-c\Lambda_\tau|
%	& \leq \frac{1}{2}\left(1 + |u_1-r_1|\sum_{i=1}^{\nu}|\overline{a}_{i1}| + \cdots + |u_{\nu} - r_{\nu}| \sum_{i=1}^{\nu}|\overline{a}_{i\nu}|\right) + \\
%	& \quad + \frac{1}{2}\left((w_{\eps 1} + w_{\eps 2})\max_{w:L \to \mathbb{C}} \log^+|w(z)|\right) +\\
%	& \quad + \frac{1}{2}\left(\sum_{k = 1}^{\nu} (w_{\gamma 1 k} + w_{\gamma 2 k})\log(p_k)|u_k - r_k|\right) \\
%	& \quad + \frac{1}{2}\left(\frac{1}{[L:\mathbb{Q}]}\sum_{\sigma :L \to \mathbb{C}} w_{\varepsilon_1 \sigma}\log \max \left\{ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} \right.\\
%	&\quad\quad \left.+ \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{\gamma_1 k}\log(p_k)|u_k - r_k| \right) + \\
%	&\quad + \frac{1}{2}\left(\frac{1}{[L:\mathbb{Q}]}\sum_{\sigma :L \to \mathbb{C}} w_{\varepsilon_2 \sigma}\log \max \left\{ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} \right.\\
%	&\quad\quad \left.+ \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{\gamma_2 k}\log(p_k)|u_k - r_k| \right) \\
	& \leq \frac{1}{2} + \frac{(w_{\varepsilon 1} + w_{\varepsilon_2})}{2}\max_{w :L \to \mathbb{C}} \log^+|w(z)| + \\
	& \quad + \log(p_1)|u_1 - r_1|\left( \frac{(w_{\gamma 1 1} + w_{\gamma 2 1})}{2} + \frac{1}{2\log(p_1)}\sum_{i=1}^{\nu}|\overline{a}_{i1}|\right) + \cdots \\
	& \quad + \log(p_{\nu})|u_{\nu} - r_{\nu}|\left( \frac{(w_{\gamma 1 {\nu}} + w_{\gamma 2 {\nu}})}{2} + \frac{1}{2\log(p_{\nu})}\sum_{i=1}^{\nu}|\overline{a}_{i{\nu}}|\right).
\end{align*}
In the notation of \eqref{eq:wsigma}, this inequality reduces to
\[|\alpha_{\tau}-c\Lambda_\tau| \leq \frac{1}{2} + w_{\eps} \max_{w :L \to \mathbb{C}}\log^+|w(z)| + \sum_{l = 1}^{\nu}w_{\gamma l} \log(p_l)|u_l - r_l|.\]

Now the following upper bound for $|\Lambda_\tau|$ implies the statement. On using power series definition of exponential function, we obtain $$\Lambda_\tau(1+\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!)=\Lambda_\tau+\sum_{n\geq 2} (\Lambda_\tau)^n/n!=e^{\Lambda_\tau}-1=\tau(\lambda).$$
If $\Lambda_\tau\geq 0$ then $1+\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!>1$ which implies that $|\Lambda_\tau|\leq |\tau(\lambda)|.$ Suppose now that $\Lambda_\tau<0$. Our assumption $h_{\tau}(z)\geq \log^+ (2|\lambda_0|)$ means that $|\tau(\lambda)|\leq 1/2$ and thus $|\Lambda_\tau|=-\log (\tau(\lambda)+1)\leq -\log(1/2)=\log 2.$ Therefore, the absolute value of $\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!$ is at most $$\sum_{n\geq 2} |\Lambda_\tau|^{n-1}/n!=\sum_{n\geq 1} |\Lambda_\tau|^{n}/(n+1)!\leq \tfrac{1}{2}\sum_{n\geq 1} |\Lambda_\tau|^{n}/n!\leq
\tfrac{1}{2}e^{\log 2}-1/2=1/2.$$
More precisely, for any even $N\geq 2$, we obtain
\begin{align*}
|\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!|
	& =|\sum_{n\geq 1} (\Lambda_\tau)^{n}/(n+1)!|\\
	&\leq |\sum_{N\geq n\geq 1} (\Lambda_\tau)^{n}/(n+1)!|+\tfrac{1}{N+2}|\sum_{n>N} (\Lambda_\tau)^{n}/n!|\\
	&\leq |\sum_{N\geq n\geq 1} (\Lambda_\tau)^{n}/(n+1)!|+\tfrac{1}{N+2}e^{|\Lambda_\tau|}\\
	& \leq |\sum_{N\geq n\geq 1} (\Lambda_\tau)^{n}/(n+1)!|+\tfrac{2}{N+2}:=k_N.
\end{align*}
We now give an upper bound for $k_N$. Since $\Lambda_\tau<0$, we obtain
$$\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!=\sum_{N\geq n\geq 1} (\Lambda_\tau)^{n}/(n+1)!=\sum_{N\geq n\geq 2, \, 2\mid n}\tfrac{|\Lambda_\tau|^n}{(n+1)!}-\tfrac{|\Lambda_\tau|^{n-1}}{n!}$$
$$=\sum_{N\geq n\geq 2, \, 2\mid n}\tfrac{|\Lambda_\tau|^{n-1}}{n!}(\tfrac{|\Lambda_\tau|}{n+1}-1)=\tfrac{|\Lambda_\tau|}{2}(\tfrac{|\Lambda_\tau|}{3}-1)+\sum_{N\geq n\geq 4, \, 2\mid n}\tfrac{|\Lambda_\tau|^{n-1}}{n!}(\tfrac{|\Lambda_\tau|}{n+1}-1)$$
$$\geq \tfrac{\log 2}{2}(\tfrac{\log 2}{4}-1)+\sum_{N\geq n\geq 4, \, 2\mid n}\tfrac{(\log 2)^{n-1}}{n!}(\tfrac{3/4(\log 2)}{n+1}-1):=-k_N.$$
The last inequality follows by distinguishing two cases whether  $|\Lambda_\tau|\leq 3/4\cdot \log 2$ or not; note that $\ln(2)/2\cdot(\ln(2)/4-1)/(-\ln (2)\cdot3/8)\geq 1$.  Now, on using that $-k_N$ is negative, it follows that
\[|1+\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!|\geq 1-|\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!|\geq 1-k_N\]
and thus
$$|\Lambda_\tau|\leq \kappa_\tau|\tau(x)|, \quad \kappa_\tau=\tfrac{1}{1-k_N}|\tau(\lambda_0)|,  \quad c_\tau=\log^+(2|\lambda_0|).$$
The constant $\kappa_\tau$ depends on $N$ which can be taken arbitrarily as long as $N\geq 2$ is even. Further, the value $k_N$ can be slightly improved when one finds the maximum of the functions $x^{n-1}(\tfrac{x}{n+1}-1)$ on the interval $[0,\log 2]$ for each even $n\geq 2$. This is our reason for taking $\kappa_{\tau} = \frac{3}{2}$. Currently this is not the optimal choice of $\kappa_{\tau}$, but it suffices for our present case.

Finally, we have
\[|\alpha_{\tau}| \leq \frac{1}{2} + w_{\eps} \max_{w :L \to \mathbb{C}}\log^+|w(z)| + \sum_{l = 1}^{\nu}w_{\gamma l} \log(p_l)|u_l - r_l| + c\kappa_{\tau}e^{-h_{\tau}(z)}.\]

%
%If $v=p$ then Lemma~\ref{} gives optimal $c_v$ and $\kappa_v$. In the real case, if $v=\tau:L\to \mathbb{C}$ then we can take $\kappa_\tau$ as defined in \eqref{} and $c_v=\log 2$.
%
%Let now  $v=\tau$. Suppose first that we are in the real case. It holds that $\mu-1=\lambda$ and $\Lambda_\tau=\log \tau (\mu)$. Then, on using power series definition of exponential function, we obtain $$\Lambda_\tau(1+\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!)=\Lambda_\tau+\sum_{n\geq 2} (\Lambda_\tau)^n/n!=e^{\Lambda_\tau}-1=\tau(\lambda).$$
%If $\Lambda_\tau\geq 0$ then $1+\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!>1$ which implies that $|\Lambda_\tau|\leq |\tau(\lambda)|.$ Suppose now that $\Lambda_\tau<0$. Our assumption $h_v(z)\geq \log 2$ means that $|\tau(z)|\leq 1/2$ and thus $|\Lambda_\tau|=-\log (\tau(z)+1)\leq -\log(1/2)=\log 2.$ Therefore, the absolute value of $\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!$ is at most $$\sum_{n\geq 2} |\Lambda_\tau|^{n-1}/n!=\sum_{n\geq 1} |\Lambda_\tau|^{n}/(n+1)!\leq \tfrac{1}{2}\sum_{n\geq 1} |\Lambda_\tau|^{n}/n!\leq
%\tfrac{1}{2}e^{\log 2}-1/2=1/2.$$
%More precisely, for any even $N\geq 2$, we obtain
%$$|\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!|=|\sum_{n\geq 1} (\Lambda_\tau)^{n}/(n+1)!|\leq |\sum_{N\geq n\geq 1} (\Lambda_\tau)^{n}/(n+1)!|+\tfrac{1}{N+2}|\sum_{n>N} (\Lambda_\tau)^{n}/n!|$$
%$$\leq |\sum_{N\geq n\geq 1} (\Lambda_\tau)^{n}/(n+1)!|+\tfrac{1}{N+2}e^{|\Lambda_\tau|}\leq |\sum_{N\geq n\geq 1} (\Lambda_\tau)^{n}/(n+1)!|+\tfrac{2}{N+2}:=k_N.$$
%We now give an upper bound for $k_N$. Since $\Lambda_\tau<0$, we obtain
%$$\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!=\sum_{N\geq n\geq 1} (\Lambda_\tau)^{n}/(n+1)!=\sum_{N\geq n\geq 2, \, 2\mid n}\tfrac{|\Lambda_\tau|^n}{(n+1)!}-\tfrac{|\Lambda_\tau|^{n-1}}{n!}$$
%$$=\sum_{N\geq n\geq 2, \, 2\mid n}\tfrac{|\Lambda_\tau|^{n-1}}{n!}(\tfrac{|\Lambda_\tau|}{n+1}-1)=\tfrac{|\Lambda_\tau|}{2}(\tfrac{|\Lambda_\tau|}{3}-1)+\sum_{N\geq n\geq 4, \, 2\mid n}\tfrac{|\Lambda_\tau|^{n-1}}{n!}(\tfrac{|\Lambda_\tau|}{n+1}-1)$$
%$$\geq \tfrac{\log 2}{2}(\tfrac{\log 2}{4}-1)+\sum_{N\geq n\geq 4, \, 2\mid n}\tfrac{(\log 2)^{n-1}}{n!}(\tfrac{3/4(\log 2)}{n+1}-1):=-k_N.$$
%The last inequality follows by distinguishing two cases whether  $|\Lambda_\tau|\leq 3/4\cdot \log 2$ or not; note that $ln(2)/2*(ln(2)/4-1)/(-ln (2)*3/8)\geq 1$.  Now, on using that $-k_N$ is negative, it follows that $|1+\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!|\geq 1-|\sum_{n\geq 2} (\Lambda_\tau)^{n-1}/n!|\geq 1-k_N$ and thus
%$$|\Lambda_\tau|\leq \kappa_\tau|\tau(z)|, \quad \kappa_\tau=\tfrac{1}{1-k_N},  \quad c_\tau=\log 2.$$
%The constant $\kappa_\tau$ depends on $N$ which can be taken arbitrarily as long as $N\geq 2$ is even. Further, the value $k_N$ can be slightly improved when one finds the maximum of the functions $x^{n-1}(\tfrac{x}{n+1}-1)$ on the interval $[0,\log 2]$ for each even $n\geq 2$.
\end{proof}

To summarize the results of this section, let $\mathbf{m} = (n_1, \dots, n_{\nu}, a_1, \dots, a_r) \in \mathbb{R}^{r + \nu}$ be any solution of \eqref{eq:EfficientSunit} with corresponding vector $\mathbf{n} = (n_1, \dots, n_{\nu})$. Take $\mathbf{l},\mathbf{h}\in\mathbb{R}^{\nu+m}$ such that $\mathbf{0} \leq \mathbf{l} \leq \mathbf{h}$ and suppose $h_v(z)\leq h_v$ for all $v\in S^*$. By Lemma~\ref{lem:boundqf}, we deduce
\begin{equation} \label{def:bbound}
q_f(\mathbf{n}) \leq \frac{1}{\log(2)^2}\sum_{k = 1}^{\nu} \log(p_k)^2|u_k -r_k|^2 \leq \frac{1}{\log(2)^2}\sum_{k = 1}^{\nu} h_k^2=:b_{\gamma}.
\end{equation}

For $l = 1, 2$, Lemma~\ref{lem:mepsbound} gives us
\begin{align}\label{def:bepsbound}
|a_l|^2 &\leq \left(w_{\eps l}\max_{w:L \to \mathbb{C}} \log^+|w(z)| + \sum_{k = 1}^{\nu} w_{\gamma l k}\log(p_k)|u_k - r_k|\right)^2\\
	&\leq \left([L:K]w_{\eps l}\max_{w:L \to \mathbb{C}} h_w + \sum_{k = 1}^{\nu} w_{\gamma l k}h_k\right)^2 =: b_{\eps_l}.
\end{align}
Finally, suppose in addition that
\[h_{\tau}(z) \geq l_{\tau} > c_{\tau}.\]
Then by Lemma~\ref{lem:archellest}, we obtain
\begin{align} \label{def:bepstarbound}
& \left|\alpha_0+\sum_{i = 1}^r a_i \alpha_{\varepsilon i} + \sum_{i = 1}^{\nu} n_i \alpha_{\gamma i}\right|^2 \\
	& \quad \leq \left(\frac{1}{2} + w_{\eps} \max_{w :L \to \mathbb{C}}\log^+|w(z)| + \sum_{k = 1}^{\nu}w_{\gamma k} \log(p_k)|u_k - r_k| + c\kappa_{\tau}e^{-h_{\tau}(z)}\right)^2\\
	& \quad \leq \left(\frac{1}{2} + [L:K]w_{\eps} \max_{w :L \to \mathbb{C}}h_w + \sum_{k = 1}^{\nu}w_{\gamma k} h_k + c\kappa_{\tau}e^{-l_{\tau}}\right)^2 =:b_{\eps_l^*}.
\end{align}

It is of particular importance to note that the assumptions $h_{\tau}(z) \geq l_{\tau}$ and  $h_v(z)\leq h_v$ for all $v\in S^*$ are not arbitrary. Indeed, for the vectors $\mathbf{l}, \mathbf{h}$, these conditions imply precisely that $(\tilde{x},\tilde{y}) \in \Sigma_{\tau}(\mathbf{l}, \mathbf{h})$, where $(\tilde{x},\tilde{y})$ are solutions to \eqref{eq:EfficientSunit} corresponding to $\mathbf{m}$.


%
%\begin{align*}
%& \left|\alpha_0+\sum_{i = 1}^r a_i \alpha_{\varepsilon i} + \sum_{i = 1}^{\nu} n_i \alpha_{\gamma i}\right| ^2 \\ & \leq
%\begin{cases}
%\left( \frac{2}{[L:\mathbb{Q}]}\max_{\sigma:L\to \mathbb{C}} w_{\sigma}h_{\sigma}  + \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{k}h_k + \frac{1}{2} + c\kappa_{\tau}e^{-l_{\tau}}\right)^2 & \text{ if } \sqrt{\Delta}\notin\mathbb{Q} \\
%\left( \frac{1}{[L:\mathbb{Q}]}\max_{\sigma:L\to \mathbb{C}} w_{\sigma}h_{\sigma}  + \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{k}h_k + \frac{1}{2} + c\kappa_{\tau}e^{-l_{\tau}}\right)^2 & \text{ if } \sqrt{\Delta}\in\mathbb{Q}.\\
%\end{cases}
%\end{align*}

%We now fix $\epsilon^*\in\unit_\infty$ and we take $h\in\RR^{S^*}$ with $h\geq 0$.  Let $(x,y)\in\Sigma$ with $m\in\ZZ^\unit$ and $h_\tau(z)\geq l_\tau$, and suppose that $h_v(z)\leq h_v$ for all $v\in S^*$. Then, on combining Lemma~\ref{lem:archellest} with \eqref{eq:hvjbound}, we see that  $\left|\alpha_0+\sum_{u\in\unit}m_u\alpha_u\right|^2$ is at most
%\begin{equation}\label{def:bepsstarbound}
%b_{\epsilon^*}=\left(\sum_{v:L\to\CC}w_{v}h_v+\sum_{v\in T}\max\bigl(w_{v}h_v,w_{v^{(j)}}a_p\log N(v^{(j)})\bigl)+c\kappa_\tau e^{-l_{\tau}}\right)^2.
%\end{equation}
%By Remark~\ref{rem:i12}, we can replace $\sum_{v:L\to\CC}w_{v}h_v$ by $3[L:K]\|r_\epsilon\|_\infty\max_{v:L\to\CC}h_v$ if $|I|=2$.
%

We are finally in position to define the ellipsoid corresponding to $\Sigma_{\tau}(\mathbf{l}, \mathbf{h})$. Fix any $\eps_l^* \in \{\varepsilon_1, \dots, \varepsilon_r\}$.
For each $\varepsilon_l$ in $\{\varepsilon_1, \dots, \varepsilon_r\}$ such that $\varepsilon_l \neq \varepsilon_l^*$, we associate the bound $b_{\eps_l}$. For $\varepsilon_l$, we associate the value $b_{\eps_l^*}$.
%
%\[b_{\varepsilon_l} =
%\begin{cases}
%\left( \frac{2}{[L:\mathbb{Q}]}\max_{\sigma:L\to \mathbb{C}} w_{\sigma}h_{\sigma}  + \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{k}h_k + \frac{1}{2} + c\kappa_{\tau}e^{-l_{\tau}}\right)^2 & \text{ if } \sqrt{\Delta}\notin\mathbb{Q} \\
%\left( \frac{1}{[L:\mathbb{Q}]}\max_{\sigma:L\to \mathbb{C}} w_{\sigma}h_{\sigma}  + \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{k}h_k + \frac{1}{2} + c\kappa_{\tau}e^{-l_{\tau}}\right)^2 & \text{ if } \sqrt{\Delta}\in\mathbb{Q}\\
%\end{cases}\]
%where
%\begin{align*}
%\left|\alpha_0+\sum_{i = 1}^r a_i \alpha_{\varepsilon i} + \right.& \left.\sum_{i = 1}^{\nu} n_i \alpha_{\gamma i}\right| ^2
%	\leq b_{\varepsilon_l} \\
%\\ & =
%\begin{cases}
%\left( \frac{2}{[L:\mathbb{Q}]}\max_{\sigma:L\to \mathbb{C}} w_{\sigma}h_{\sigma}  + \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{k}h_k + \frac{1}{2} + c\kappa_{\tau}e^{-l_{\tau}}\right)^2 & \text{ if } \sqrt{\Delta}\notin\mathbb{Q} \\
%\left( \frac{1}{[L:\mathbb{Q}]}\max_{\sigma:L\to \mathbb{C}} w_{\sigma}h_{\sigma}  + \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{k}h_k + \frac{1}{2} + c\kappa_{\tau}e^{-l_{\tau}}\right)^2 & \text{ if } \sqrt{\Delta}\in\mathbb{Q}.\\
%\end{cases}
%\end{align*}

Let
\[\mathbf{x} = (x_1, \dots, x_{\nu}, x_{\varepsilon_1}, \dots, x_{\varepsilon_{r}}) \in \mathbb{R}^{\nu + r}.\]
Then we define the ellipsoid $\mathcal{E_\tau}\subseteq \mathbb{R}^{r+\nu}$ by
\begin{align}\label{def:ellreal}
& \mathcal{E_\tau}=\{q_\tau(\mathbf{x})\leq (1 + r)(b_{\gamma}b_{\varepsilon_1}\cdots b_{\varepsilon_r}); \ \mathbf{x}\in\mathbb{R}^{r+\nu}\}\end{align}
where
\[q_{\tau}(\mathbf{x})= (b_{\varepsilon_1}\cdots b_{\varepsilon_r})\left( q_f(x_1, \dots, x_{\nu}) + \sum_{i = 1}^r\frac{b_{\gamma}}{b_{\varepsilon_i}}x_{\varepsilon_i}^2\right)\]
and
\[q_f(\mathbf{y}) = (A\mathbf{y})^{\text{T}}D^2A\mathbf{y}.\]

We associate to this ellipsoid a matrix. More precisely, we let $M=M_\tau$ be the matrix defining the ellipsoid $\mathcal{E}_{\tau}$. Explicitly, this is the matrix
\begin{align*}
M &=\sqrt{b_{\varepsilon_1}\cdots b_{\varepsilon_r}}\begin{pmatrix}
	DA & 0 & \dots & 0 & 0\\
	0 & \sqrt{\frac{b_{\gamma}}{b_{\varepsilon 1}}} & \dots & 0 & 0\\
	0 & 0  & \sqrt{\frac{b_{\gamma}}{b_{\varepsilon 2}}} & \dots & 0\\
	\vdots & \vdots &0 &  \ddots & \vdots\\
	0 & 0 & \dots & \dots & \sqrt{\frac{b_{\gamma}}{b_{\varepsilon^*}}} \\
	\end{pmatrix}.
\end{align*}
Note that we never need to compute $M$, but rather $M^TM$ so that we only ever work with integral matrices. In this case,
\begin{align*}
M^TM &= b_{\varepsilon_1}\cdots b_{\varepsilon_r}\begin{pmatrix}
	A^TD^2A & 0 & \dots & 0 & 0\\
	0 & \frac{b_{\gamma}}{b_{\varepsilon 1}} & \dots & 0 & 0\\
	0 & 0  & \frac{b_{\gamma}}{b_{\varepsilon 2}} & \dots & 0\\
	\vdots & \vdots &0 &  \ddots & \vdots\\
	0 & 0 & \dots & \dots & \frac{b_{\gamma}}{b_{\varepsilon^*}} \\
	\end{pmatrix}.
\end{align*}

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %

\subsection{The non-Archimedean ellipsoid}
\label{subsec:nonArchEllipsoid}

We now restrict our attention to those $p_v \in \{p_1, \dots, p_{\nu}\}$ and define the corresponding ellipsoid. As before, let $\mathbf{m} = (n_1, \dots, n_{\nu}, a_1, \dots, a_r) \in \mathbb{R}^{r + \nu}$ be any solution of \eqref{eq:EfficientSunit} with corresponding vector $\mathbf{n} = (n_1, \dots, n_{\nu})$. Take $\mathbf{l},\mathbf{h}\in\mathbb{R}^{\nu+m}$ such that $\mathbf{0} \leq \mathbf{l} \leq \mathbf{h}$ and suppose $h_v(z)\leq h_v$ for all $v\in S^*$.

Now, Lemma~\ref{lem:boundqf} and Lemma~\ref{lem:mepsbound} still hold here. In particular, we let $b$, $b_{\eps_l}$ be defined as in \eqref{def:bbound} and \eqref{def:bepsbound}, respectively, where $l = 1, \dots, r$:
\begin{equation}
q_f(\mathbf{n}) \leq \sum_{k = 1}^{\nu} \log(p_k)^2|u_k -r_k|^2 \leq \sum_{k = 1}^{\nu} h_k^2=:b.
\end{equation}
For $l = 1, 2$, Lemma~\ref{lem:mepsbound} gives us
\edit{These are off and I need to go back and re-edit the bound on $|a_l|$ in the previous section - but is there a reason that we take the square value?}
\begin{align}
|a_l|^2 &\leq \left(\frac{1}{[L:\mathbb{Q}]}\sum_{\sigma :L \to \mathbb{C}} w_{\varepsilon l \sigma}\log \max \left\{ \left|\sigma\left(\frac{\delta_2}{\lambda}\right)\right|, 1\right\} \right.\\
	& \quad \quad+ \left. \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{\gamma l k}\log(p_k)|u_k - r_k|\right)^2\\
	&\leq \left( \frac{1}{[K:\mathbb{Q}]}\sum_{k = 1}^{\nu} w_{\gamma l k}h_k + \frac{1}{[L:\mathbb{Q}]}\sum_{\sigma:L\to \mathbb{C}} w_{\varepsilon l \sigma}h_{\sigma}\right)^2 =: b_{\eps_l}.
\end{align}
\edit{ Or is this one?
\[|a_l| \leq w_{\eps l}\max_{w:L \to \mathbb{C}} \log^+|w(z)| + \sum_{k = 1}^{\nu} w_{\gamma l k}\log(p_k)|u_k - r_k|.\]}
We do not distinguish any $\varepsilon_l^*$. Instead, we will see later that the condition $h_{v}(z) \geq l_{v}$ corresponding to the set $\Sigma_v(\mathbf{l}, \mathbf{h})$ will be used elsewhere.

Let $b:= \text{lcm}\left(\sqrt{b_{\varepsilon_1}}, \dots, \sqrt{b_{\varepsilon_r}},Q_{n_1}, \dots, Q_{n_{\nu}}\right)$, where $Q_{n_1}, \dots, Q_{n_{\nu}}$ correspond to the denominators of the convergents of $\log^*(p_1), \dots, \log^*(p_{\nu})$ respectively. Recall that $b_{\varepsilon_i}$ is a square so that $\sqrt{b_{\varepsilon_i}}$ is an integer. We define the ellipsoid $\mathcal{E}_v \subseteq \mathbb{R}^{\nu + r}$ by
\begin{align}\label{def:ellp}
  & \mathcal{E}_v= \{q_v(\mathbf{x})\leq b^2(b_{\gamma}+r); \ \mathbf{x}\in\mathbb{R}^{r+\nu}\},
\end{align}
where
\[q_v(\mathbf{x})= b^2\left( q_f(x_1, \dots, x_{\nu}) +
    \sum_{i = 1}^r\frac{1}{b_{\varepsilon_i}}x_{\varepsilon_i}^2\right)\]
and
\[q_f(\mathbf{y}) = (A\mathbf{y})^{\text{T}}D^2A\mathbf{y}.\]

Similar to the Archimedean case, we let $M=M_v$ be the matrix defining the ellipsoid $\mathcal{E}_{v}$. Explicitly, this is the matrix
\begin{align*}
  M & = b \begin{pmatrix}
    DA & 0 & \dots & 0 & 0\\
    0 & \sqrt{\frac{1}{b_{\varepsilon 1}}} & \dots & 0 & 0\\
    0 & 0  & \sqrt{\frac{1}{b_{\varepsilon 2}}} & \dots & 0\\
    \vdots & \vdots &0 &  \ddots & \vdots\\
    0 & 0 & \dots & \dots & \sqrt{\frac{1}{b_{\varepsilon}}} \\
  \end{pmatrix}
  = \begin{pmatrix}
    bDA & 0 & \dots & 0 & 0\\
    0 & \frac{b}{\sqrt{b_{\varepsilon_1}}} & \dots & 0 & 0\\
    0 & 0  & \frac{b}{\sqrt{b_{\varepsilon_2}}} & \dots & 0\\
    \vdots & \vdots &0 &  \ddots & \vdots\\
    0 & 0 & \dots & \dots & \frac{b}{\sqrt{b_{\varepsilon_r}}}
  \end{pmatrix}.
\end{align*}
By definition of $b$, it follows that $M$ is an integral matrix.
% As before, we never need to compute $M$, but rather $M^TM$ so that we only ever work with integral matrices. In this case,
% \begin{align*}
% M^TM &= b_{\varepsilon_1}\cdots b_{\varepsilon_r}\begin{pmatrix}
% 	A^TD^2A & 0 & \dots & 0 & 0\\
% 	0 & \frac{b_{\gamma}}{b_{\varepsilon 1}} & \dots & 0 & 0\\
% 	0 & 0  & \frac{b_{\gamma}}{b_{\varepsilon 2}} & \dots & 0\\
% 	\vdots & \vdots &0 &  \ddots & \vdots\\
% 	0 & 0 & \dots & \dots & \frac{b_{\gamma}}{b_{\varepsilon}} \\
% 	\end{pmatrix}.
% \end{align*}

%---------------------------------------------------------------------------------------------%

\section{The Archimedean sieve: the real case}
\label{sec:archsieve}

Let $\tau:L\to\mathbb{C}$ be an embedding. We take $\mathbf{l},\mathbf{h} \in \mathbb{R}^{m+\nu}$ with $\mathbf{0}\leq \mathbf{l}\leq \mathbf{h}$ and $l_\tau\geq \log 2$. Let $c$ be a constant the size of $e^{l_\tau}$ and let $\alpha_0, \alpha_{\varepsilon 1}, \dots, \alpha_{\varepsilon {r}}, \alpha_{\gamma 1}, \dots, \alpha_{\gamma {\nu}}$ be defined as in \eqref{eq:alpha0eps} and \eqref{eq:alphagamma}.

Define the $(\nu+r) \times (\nu +r)$-dimensional matrix $A_{\tau}$ as
\[A_{\tau} = \begin{pmatrix}
	1 & 0 & \dots &  \dots & 0 & 0\\
	0 & 1	& \dots & \dots & 0 & 0\\
	\vdots & \vdots & \ddots & \dots & \vdots & \vdots \\
	0 & 0 & \dots &  \dots & 1 & 0\\
	\alpha_{\gamma 1} & \dots &\alpha_{\gamma {\nu}} & \alpha_{\varepsilon 1} & \dots & \alpha_{\varepsilon {r}}
\end{pmatrix}\]
and consider the lattice defined by its columns. Let $\mathbf{w} = (0,\dotsc,0,\alpha_0)$ be a vector of length $(\nu + r)$. We now consider the translated lattice $\Gamma_{\tau}$ defined by $A_{\tau}\mathbf{x} + \mathbf{w}$, where $\mathbf{x}$ is an arbitrary coordinate vector.

%for some fixed $\epsilon^*\in\unit_\infty$ and whose row indexed by $\epsilon^*$ is given by $(\alpha_u)\in\ZZ^\unit$.
Let $\mathcal E_{\tau}=\mathcal E_{\tau}(h,l_{\tau})$ be the ellipsoid constructed in \eqref{def:ellreal}. Let
\[\mathbf{m} = (n_1, \dots, n_{\nu}, a_1, \dots, a_r) \in \mathbb{R}^{r + \nu}\]
be any solution of \eqref{eq:EfficientSunit}. We say that $\mathbf{m}$ is determined by some $\mathbf{y} \in \Gamma_{\tau}$ if
\[\mathbf{y} = (y_1, \dots, y_{r+ \nu}) = \left(n_1, \dots, n_{\nu}, a_1, \dots, a_{r-1}, \alpha_0+\sum_{i = 1}^r a_i \alpha_{\varepsilon i} + \sum_{i = 1}^{\nu} n_i \alpha_{\gamma i}\right)\]
where the missing element $a_{l}$ corresponds to $\varepsilon_l^*$.

\begin{lemma}\label{lem:archsieve}
Let ${\mathbf{m} = (n_1, \dots, n_{\nu}, a_1, \dots, a_r) \in \mathbb{R}^{r + \nu}}$ be any solution of \eqref{eq:EfficientSunit} which lies in $\Sigma_\tau(l,h)$. Then $\mathbf{m}$ is determined by some $\mathbf{y}\in \Gamma_\tau\cap\mathcal E_\tau.$
\end{lemma}

\begin{proof}
Let
\[\mathbf{y} = \left(n_1, \dots, n_{\nu}, a_1, \dots, a_{r-1}, \alpha_0+\sum_{i = 1}^r a_i \alpha_{\varepsilon i} + \sum_{i = 1}^{\nu} n_i \alpha_{\gamma i}\right).\]
Then $\mathbf{y} \in \Gamma_\tau$ and \eqref{def:bepstarbound} implies that $y_{\eps_l^*}^2\leq b_{\eps_l^*}$. Further $q_f(y_1, \dots, y_{\nu})\leq b$ by \eqref{def:bbound} and \eqref{def:bepsbound} provides that $y_{\eps_l}^2\leq b_{\eps_l}$ for $l = 1, \dots, r$ with $\eps_l \neq \eps_l^*$. It follows that
\[q_\tau(\mathbf{y}) = (b_{\varepsilon_1}\cdots b_{\varepsilon_r})\left( q_f(y_1, \dots, y_{\nu}) + \sum_{i = 1}^r\frac{b}{b_{\varepsilon_i}}y_{\varepsilon_i}^2\right) \leq (1+r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r}).\]
This proves that $\mathbf{y}\in\mathcal E_\tau$ and hence the statement follows.
\end{proof}
%
We now explicitly determine $ \Gamma_\tau\cap \mathcal E_\tau$. Suppose that $\mathbf{y}\in \Gamma_\tau\cap \mathcal E_\tau$. Let $M=M_\tau$ be the matrix defining the ellipsoid $\mathcal{E}_{\tau}$.
Since $\mathbf{y}\in \Gamma_\tau\cap \mathcal E_\tau$, there exists $\mathbf{x}\in \mathbb{R}^{r + \nu}$ such that $\mathbf{y}= A_\tau \mathbf{x}+\mathbf{w}$ and ${\mathbf{y}^tM^tM\mathbf{y}\leq (1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})}$. We thus have
\[(A_\tau \mathbf{x}+\mathbf{w})^tM^tM(A_\tau \mathbf{x}+\mathbf{w}) \leq (1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r}).\]
As $A_{\tau}$ is clearly invertible, with matrix inverse
\[A_{\tau}^{-1} = \begin{pmatrix}
	1 & 0 & \dots &  \dots & 0 & 0\\
	0 & 1	& \dots & \dots & 0 & 0\\
	\vdots & \vdots & \ddots & \dots & \vdots & \vdots \\
	0 & 0 & \dots &  \dots & 1 & 0\\
	-\frac{\alpha_{\gamma 1}}{\alpha_{\varepsilon {r}}} & \dots &-\frac{\alpha_{\gamma {\nu}}}{\alpha_{\varepsilon {r}}} & -\frac{\alpha_{\varepsilon 1}}{\alpha_{\varepsilon {r}}} & \dots & \frac{1}{\alpha_{\varepsilon {r}}}
\end{pmatrix},\]
we can find a vector $\mathbf{c}$ such that $A_{\tau}\mathbf{c} = -\mathbf{w}$. Indeed, this vector is
\[\mathbf{c} = A_{\tau}^{-1}\mathbf{w} =\begin{pmatrix}
	0 \\ 0 \\ \vdots \\ 0 \\ -\frac{\alpha_0}{\alpha_{\varepsilon r}}
\end{pmatrix}.\]
Now,
\begin{align*}
(1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})
	& \geq (A_\tau \mathbf{x}+\mathbf{w})^tM^tM(A_\tau \mathbf{x}+\mathbf{w}) \\
	& = (A_\tau (\mathbf{x}-\mathbf{c}))^TM^TM(A_\tau (\mathbf{x}-\mathbf{c}))\\
	& = (\mathbf{x}-\mathbf{c})^T(MA_{\tau})^TMA_\tau(\mathbf{x}-\mathbf{c})\\
	& = (\mathbf{x}-\mathbf{c})^TB^TB(\mathbf{x}-\mathbf{c})
\end{align*}
where $B = MA_\tau$. That is, we are left to solve
\[(\mathbf{x}-\mathbf{c})^TB^TB(\mathbf{x}-\mathbf{c}) \leq (1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r}).\]
Now, finding all vectors satisfying this inequality amounts to computing all solutions to \eqref{eq:EfficientSunit} contained in $\Sigma_{\tau}(\mathbf{l}, \mathbf{h})$. The set of vectors $\mathbf{x}$ can be found using the Fincke-Pohst algorithm outlined in \autoref{subsec:FinckePohst}.
%Here we observe that the vector $c$ is likely not an integral vector; that is, $-\frac{\alpha_0}{\alpha_{\varepsilon r}} \notin \mathbb{Z}$. To amend this, we modify the bound as follows
%\begin{align*}
%\alpha_{\varepsilon r}^2(x-c)^tB^tB(x-c) & \leq \alpha_{\varepsilon r}^2(1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})\\
%(\alpha_{\varepsilon r}x-\alpha_{\varepsilon r}c)^tB^tB(\alpha_{\varepsilon r}x-\alpha_{\varepsilon r}c) & \leq \alpha_{\varepsilon r}^2(1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})\\
%(z-d)^tB^tB(z-d) & \leq \alpha_{\varepsilon r}^2(1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})
%\end{align*}
%where $d = (0 \dots 0 -\alpha_0)$ and $z = \alpha_{\varepsilon r}x$.
%Is this necessary? Our thing should work over the rationals regardless


%---------------------------------------------------------------------------------------------%
%---------------------------------------------------------------------------------------------%

%
%
%
%
%
%
% Since
%\[M\gamma=M(\Gamma_\tau x+w) = M\Gamma_{\tau} x + Mw.\]
%Here, it is clear that $M$ is invertible, with inverse
%
%
%
%, it is also invertible. Hence we can find a vector $c$ such that $Bc = v$.
%
%\begin{align*}
%B = &M\Gamma_{\tau} =\sqrt{b_{\varepsilon_1}\cdots b_{\varepsilon_r}}\begin{pmatrix}
%	DA & 0 & \dots & 0 & 0\\
%	0 & \sqrt{\frac{b}{b_{\varepsilon 1}}} & \dots & 0 & 0\\
%	0 & 0  & \sqrt{\frac{b}{b_{\varepsilon 2}}} & \dots & 0\\
%	\vdots & \vdots &0 &  \ddots & \vdots\\
%	0 & 0 & \dots & \dots & \sqrt{\frac{b}{b_{\varepsilon^*}}} \\
%	\end{pmatrix}
%	\begin{pmatrix}
%	1 & 0 & \dots &  \dots & \dots & 0 & 0\\
%	0 & 1	& \dots & \dots & \dots & 0 & 0\\
%	\vdots & \vdots & \ddots & \dots & \dots & \vdots & \vdots \\
%	0 & 0 & \dots &  \dots & \dots & 1 & 0\\
%	\alpha_0 & \alpha_{\gamma 1} & \dots &\alpha_{\gamma {\nu}} & \alpha_{\varepsilon 1} & \dots & \alpha_{\varepsilon^*}
%	\end{pmatrix}\\
%& = \sqrt{b_{\varepsilon_1}\cdots b_{\varepsilon_r}}\begin{pmatrix}
%	DA & \dots & \dots & \dots& 0 & 0\\
%	 0  & \sqrt{\frac{b}{b_{\varepsilon 1}}}& \dots & \dots & \vdots & \vdots \\
%	\vdots & \vdots &\vdots & \ddots & \vdots & \vdots\\
%	0 & 0  & \dots & \dots & \sqrt{\frac{b}{b_{\varepsilon r-1}}} &0\\
%	\alpha_0 \sqrt{\frac{b}{b_{\varepsilon^*}}}  & \dots & \dots & \alpha_{\varepsilon 1}\sqrt{\frac{b}{b_{\varepsilon^*}}} & \dots & \alpha_{\varepsilon^*}\sqrt{\frac{b}{b_{\varepsilon^*}}}
%	\end{pmatrix}\\
%	& =\begin{pmatrix}
%	 \sqrt{b_{\varepsilon_1}\cdots b_{\varepsilon_r}}DA & \dots & \dots & \dots& 0 & 0\\
%	 0  &  \sqrt{bb_{\varepsilon_2}\cdots b_{\varepsilon_r}}& \dots & \dots & \vdots & \vdots \\
%	\vdots & \vdots &\vdots & \ddots & \vdots & \vdots\\
%	0 & 0  & \dots & \dots &  \sqrt{bb_{\varepsilon_1}\cdots b_{\varepsilon_{r-2}}b_{\varepsilon_{r}}} &0\\
%	\alpha_0 \sqrt{bb_{\varepsilon_1}\cdots b_{\varepsilon_{r-1}}}  & \dots & \dots & \alpha_{\varepsilon 1}\sqrt{bb_{\varepsilon_1}\cdots b_{\varepsilon_{r-1}}} & \dots & \alpha_{\varepsilon^*}\sqrt{bb_{\varepsilon_1}\cdots b_{\varepsilon_{r-1}}}
%	\end{pmatrix}.
%\end{align*}
%
%It follows that
%\begin{align*}
%(1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})
%	& \geq \gamma^tM^tM\gamma \\
%	& = (M\gamma)^tM\gamma \\
%	& = (Bx + v)^t(Bx + v).
%%	& = ((Bx)^t+v^t)(Bx+v)\\
%%	& = (x^tB^t + v^t)(Bx+v)\\
%%	& = x^tB^tBx + (Bx)^tv+v^tBx+v^tv.
%\end{align*}
%Now, since $B$ is positive-definite, it is also invertible. Hence we can find a vector $c$ such that $Bc = v$.
%
%Now,
%\[(Bx)^tv = (M\gamma - v)^tv = (M\gamma)^tv -v^tv\]
%and
%\[v^tBx = v^t(M\gamma - v) = v^t(M\gamma) -v^tv\]
%and thus
%\begin{align*}
%(1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})
%	& \geq x^tB^tBx + (Bx)^tv+v^tBx+v^tv\\
%	& = x^tB^tBx + (M\gamma)^tv -v^tv + v^t(M\gamma) -v^tv +v^tv\\
%	& = x^tB^tBx + (M\gamma)^tv + v^t(M\gamma) -v^tv \\
%	& = x^tB^tBx + 2(v^t(M\gamma)) -v^tv.
%\end{align*}
%Next, we observe that
%\begin{align*}
%|v^t(M\gamma)|
%	& = |(Mw)^t(M\gamma)|\\
%	& = |wM^TM\gamma|\\
%	& = |\alpha_0 bb_{\varepsilon_1}\cdots b_{\varepsilon_{r-1}} \gamma_n|\\
%	& \leq |\alpha_0| bb_{\varepsilon_1}\cdots b_{\varepsilon_{r-1}} \sqrt{b_{\varepsilon}^*},
%\end{align*}
%%
%%
%%\[|v^t(M\gamma)| \leq \frac{b}{b_{\epsilon^*}^{1/2}}|\alpha_0|\]
%and thus
%\[x^tB^tBx\leq (1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})+v^tv - 2v^t(M\gamma)\]
%so that
%\begin{align*}
%|x^tB^tBx|
%	& \leq |(1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})+v^tv - 2v^t(M\gamma)|\\
% 	& \leq |(1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})+ v^tv| + 2|v^t(M\gamma)|\\
%	& \leq \left|(1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})+ v^tv\right| + 2 |\alpha_0| bb_{\varepsilon_1}\cdots b_{\varepsilon_{r-1}} \sqrt{b_{\varepsilon}^*}.
%\end{align*}
%
%Now, following the steps of the Fincke-Pohst algorithm, we first generate the matrix $R$ via Cholesky decomposition applied to $B^{\text{T}}B$. In particular, this means that we don't need to know $B$ explicitly, but rather $B^TB$, where
%\[B^TB = (M\Gamma_{\tau})^T(M\Gamma_{\tau}) = \Gamma_{\tau}^T(M^TM)\Gamma_{\tau}\]
%where both $M^TM$ and $\Gamma_{\tau}$ are integral matrices.
%
%
%\subsection{Non-Archimedean sieve}
%%Let $v\in T$. To simplify our exposition, we slightly abuse notation and we write $v=\ord_p:\bar{\QQ}_p\to\QQ$. We take $l,h\in\RR^{S^*}$ with $0\leq l\leq h$ and $l_v/\log p\geq \max\bigl(\tfrac{1}{p-1},v(\mu_0)\bigl)-v(\lambda_0)$, and then we consider the
%%translated lattice $\Gamma_v\subset \ZZ^\unit$ defined below.  We say that $(x,y)\in\Sigma$ with $m\in\ZZ^{\unit}$ is determined by some $\gamma\in \Gamma_v$ if the entries of $\gamma$ are a (fixed) permutation of the entries of $m$. Let $\mathcal E_v\subseteq \RR^\unit$ be the ellipsoid constructed in \eqref{def:ellnonarch}.
%%\begin{lemma}\label{lem:nonarchsieve}
%%Any $(x,y)\in\Sigma_v(l,h)$ is determined by some $\gamma\in \Gamma_v\cap\mathcal E_v.$
%%\end{lemma}
%%
%%In the remaining of this section we prove this lemma.
%
%---------------------------------------------------------------------------------------------%
%---------------------------------------------------------------------------------------------%

%---------------------------------------------------------------------------------------------%

\section{The non-Archimedean Sieve}
\label{sec:nonArchSieve}

In this section, we describe the $p$-adic reduction procedure. Throughout this section, we let $v \in \{1, \dots, \nu\}$, and we denote by $\mathbf{h} = (h_v)$ the vector containing the best current upper bounds on the solution vector $(h_v(z))$.

Recall that $\Sigma(\mathbf{h}) = \Sigma(\mathbf{l},\mathbf{h}) \cup \Sigma(\mathbf{l})$ for $\mathbf{0} \leq \mathbf{l} \leq \mathbf{h}$ a vector in $\mathbb{R}^{\nu + m}$ and moreover, that
$\Sigma(\mathbf{l},\mathbf{h}) = \cup_{v \in S^*}\Sigma_v(\mathbf{l},\mathbf{h})$. In this section, we determine all solutions $(\tilde{x}, \tilde{y}) \in \Sigma_v(\mathbf{l},\mathbf{h})$ for some appropriately chosen vector $\mathbf{l}$. We should note that in this section, we only choose the $v^{\text{th}}$ coordinate of this vector $\mathbf{l}$. However, by applying the non-Archimedean sieve on the remaining rational primes, as well as the Archimedean sieve, we will obtain the vector $\mathbf{l}$, and subsequently obtain all solutions in $\Sigma(\mathbf{l},\mathbf{h})$.

We begin by applying the results of \autoref{sec:SmallBoundForSpecialCase}. In particular, we consider the form
\[\Lambda_v = \sum_{i = 1}^{1+\nu+r} b_i\alpha_i\]
where
\[b_1 = 1, \quad b_{1+i} = n_i \ \text{ for } i \in \{1, \dots, \nu\},\]
\[ b_{1 + \nu+i} = a_i \ \text{ for } i \in \{1, \dots, r\},\]
and
\[\alpha_1 = \log_{p_v} \delta_1, \quad \alpha_{1+i} = \log_{p_v}\left( \frac{\gamma_i^{(k)}}{\gamma_i^{(l)}}\right)  \ \text{ for } i \in \{1, \dots, \nu\},\]
\[\alpha_{1+ \nu+i} = \log_{p_v}\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(l)}}\right)
\ \text{ for } i \in \{1, \dots, r\}.\]

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %

\subsection{Applying Lemma~\ref{lem:Delta1}}
\label{sec:apply-lemma-refl-1}

We apply Lemma~\ref{lem:Delta1} by which $\sum_{j = 1}^{\nu} n_ja_{vj}$ can be computed directly provided ${\ord_{p_v}(\delta_1) \neq 0}$. If this is the case \edit{then what? We need to incorporate this data into the information of the known bounds so that we may reduce the rank and subsequently remove $p_{v}$ from the set of unbounded rational primes. But how?}

\edit{However, we speculate that this actually will never happen...}

Thus, we assume for the remainder of this chapter that $\ord_{p_v}(\delta_1) = 0$.

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %

\subsection{Applying Lemma~\ref{lem:specialcase}}
\label{sec:apply-lemma-refl}

We now apply Lemma~\ref{lem:specialcase} to obtain a small bound on $\sum_{j = 1}^{\nu} n_ja_{vj}$ when ${\ord_{p_v}(\alpha_1) < \displaystyle \min_{2 \leq i \leq 1+\nu+r} \ord_{p_v}(\alpha_i)}$. If this lemma holds, we may reduce the bound $h_v$ on $h_v(z)$ as follows. Let $B$ denote the bound obtained in Lemma~\ref{lem:specialcase} so that
\[\sum_{j = 1}^{\nu} n_ja_{vj} \leq B.\]
Recall that
\[ u_v = \sum_{j = 1}^{\nu} n_ja_{vj} + r_v,\]
where $u_v$ and $r_v$ are positive integers. It therefore follows that
\[ -r_v \leq u_v - r_v = \sum_{j = 1}^{\nu} n_ja_{vj} \leq B.\]
Now, if $B < - r_v$ so that $B < 0$, we obtain a contradiction and may thus discard this entire $S$-unit equation. Conversely, if $B \geq -r_v$ ($B$ may be positive or negative), we obtain
\[|u_v - r_v| = \left| \sum_{j = 1}^{\nu} n_ja_{vj} \right| \leq \max\{B,r_v\}.\]
It follows then that
\[h_v(z) = \log(p_v)|u_v - r_v| \leq \log(p_v)\max\{B,r_v\},\]
and we may thus upgrade the bound $h_v$ on $h_v(z)$ to be
\[h_v = \log(p_v)\max\{B,r_v\}.\]

% - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - %

\subsection{The reduction procedure}
\label{sec:reduction-procedure}

Now, if the above lemmatta do not hold, we are in the situation that
\[\ord_{p_v}(\delta_1) = 0 \quad \text{ and } \quad \ord_{p_v}(\alpha_1) \geq
  \displaystyle \min_{2 \leq i \leq 1+\nu+r} \ord_{p_v}(\alpha_i).\]
Indeed, we assume this for the remainder of this chapter.

We now set some notation and give some preliminaries for the $p_v$-adic reduction procedures. Let $I$ be the set of all indices $i' \in \{2, \dots, 1+ \nu + r\}$ for which
\[\ord_{p_v}(\alpha_{i'}) = \min_{2\leq i\leq 1+ \nu+ r} \ord_{p_v}(\alpha_i).\]
Following \cite{Ham}, we are always in the case where there exists an index $i' \in I$ such that $\alpha_i/\alpha_{i'} \in \mathbb{Q}_{p_v}$ for $i = 1, \dots, 1+ \nu+ r$. Thus, let $\hat{i}$ denote this index. We define
\[\beta_i = - \frac{\alpha_i}{\alpha_{\hat{i}}} \quad i = 1, \dots, 1+ \nu+ r,\]
and
\[\Lambda'_v = \frac{1}{\alpha_{\hat{i}}}\Lambda_v = \sum_{i = 1}^{1+ \nu+ r} b_i(-\beta_i).\]
Now, we have $\beta_i \in \mathbb{Z}_{p_v}$ for $i = 1, \dots, 1+ \nu+ r$.

\begin{lemma} \label{Lem:19.1}
Suppose $\ord_{p_v}(\delta_1) = 0$ and
\[\sum_{i = 1}^{\nu} n_{i}a_{li} > \frac{1}{p_v-1} - \ord_{p_v}(\delta_2).\]
Then
\[\ord_{p_v}(\Lambda_v') = \sum_{i = 1}^{\nu} n_{i}a_{li} + \ord_{p_l}(\delta_2) - \ord_{p_l}(\alpha_{\hat{i}}).\]
\end{lemma}

\begin{proof}
Immediate from Lemma \ref{lem:DiscG} and Lemma \ref{lem:Lambda}.
\end{proof}

Fix $l_v \in \mathbb{Z}$ such that
\[\frac{l_v}{\log(p_v)} \geq \max\left(0,\max\left( \frac{1}{p_v-1}, \ord_{p_v}(\delta_1)\right) - \ord_{p_v}(\delta_2)\right).\]
Now, let $\mu$ be the largest element of $\mathbb{Z}_{\geq 0}$ at most
\[\mu \leq \frac{l_v}{\log(p_v)} - \ord_{p_v}(\alpha_{\hat{i}}) + \ord_{p_v}(\delta_2).\]

\begin{lemma}
  \label{lem:lambdap}
  Suppose $\ord_{p_v}(\delta_1) = 0$ and $\displaystyle \sum_{i = 1}^{\nu} n_{i}a_{vi} > \frac{1}{p_v-1} - \ord_{p_v}(\delta_2).$
  Then
  \[ \sum_{i = 1}^{\nu} n_{i}a_{vi}  \geq \mu - \ord_{p_v}(\delta_2) +
    \ord_{p_v}(\alpha_{\hat{i}}) \quad \text{ if and only if } \quad
    \ord_{p_v}(\Lambda_v') \geq \mu\]
\end{lemma}

\begin{proof}
By Lemma \ref{Lem:19.1}, the assumptions mean that
\[\ord_{p_v}(\Lambda_v') = \sum_{i = 1}^{\nu} n_{i}a_{vi} + \ord_{p_v}(\delta_2) - \ord_{p_v}(\alpha_{\hat{i}}).\]

Now, suppose
\[\sum_{i = 1}^{\nu} n_{i}a_{vi}  \geq \mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}}).\]
We thus have
\begin{align*}
\ord_{p_v}(\Lambda_v')
	& = \sum_{i = 1}^{\nu} n_{i}a_{vi} + \ord_{p_v}(\delta_2) - \ord_{p_v}(\alpha_{\hat{i}})\\
	& \geq  \mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}}) + \ord_{p_v}(\delta_2) - \ord_{p_v}(\alpha_{\hat{i}})\\
	& = \mu.
\end{align*}
Conversely, suppose $\ord_{p_v}(\Lambda_v') \geq \mu$. Then
\[\mu \leq \ord_{p_v}(\Lambda_v') = \sum_{i = 1}^{\nu} n_{i}a_{vi} + \ord_{p_v}(\delta_2) - \ord_{p_v}(\alpha_{\hat{i}}).\]
That is,
\[\sum_{i = 1}^{\nu} n_{i}a_{vi} \geq \mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}}).\]
Hence, it follows that $\displaystyle \sum_{i = 1}^{\nu} n_{i}a_{vi} \geq \mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}})$ if and only if $\ord_{p_v}(\Lambda_v') \geq \mu$.
\end{proof}

For each $x \in \mathbb{Z}_{p_v}$, let $x^{\{\mu\}}$ denote the unique rational integer in $[0,p_v^{\mu} - 1]$ such that $\ord_{p_v}(x - x^{\mu}) \geq \mu$ (ie. $x \equiv x^{\{\mu\}} \pmod{p_v^{\mu}}$).

Let $\Gamma_{v}$ be the $(\nu+r)$-dimensional lattice determined by column vectors of the matrix $MA_{v}$, where $M$ is the matrix defining the ellipsoid $\mathcal{E}_v$ of \autoref{subsec:nonArchEllipsoid} and $A_{v}$ is the diagonal matrix having $\hat{i}^{\text{th}}$ row
\[\left(\beta_2^{\{\mu\}}, \cdots, \beta_{\hat{i} - 1}^{\{\mu\}}, p_v^{\mu}, \beta_{\hat{i} + 1}^{\{\mu\}}, \cdots, \beta_{1+ \nu+ r}^{\{\mu\}}\right) \in \mathbb{Z}^{\nu+r}.\]
Here, $p_v^{\mu}$ is the $(\hat{i},\hat{i})$ entry of $A_{v}$. That is,
\[A_{v} =
  \begin{pmatrix}
    1 &		&		&		&		&		&	\\
    & \ddots	& 		&		& 0		& 		&	\\
    &		& 1		&		&		&		&	\\
    \beta_2^{\{\mu\}}& \cdots & \beta_{\hat{i} - 1}^{\{\mu\}} & p_v^{\mu} & \beta_{\hat{i} + 1}^{\{\mu\}}& \cdots &\beta_{1+ \nu+ r}^{\{\mu\}}\\
    & 		& 		& 		& 1		&		&	\\
    & 0		& 		& 		&		& \ddots	&	\\
    & 		& 		& 		&		& 		& 1	\\
  \end{pmatrix}.\]
Additionally, let
\[\lambda = \frac{1}{p_v^{\mu}}\sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}}),\]
and set
\[\mathbf{w} = M(0, \dots 0, -\beta_1^{\{\mu\}},0, \dots, 0)^T \in \mathbb{Z}^{\nu + r}\]
to be the product of $M$ and the vector whose only non-zero entry is the $\hat{i}^{\text{th}}$ element, $ -\beta_1^{\{\mu\}}$. Of course, we must compute the $\beta_i$ to $p_v$-adic precision at least $\mu$ in order to avoid errors here.

Choose a vector $\mathbf{z} \in \Gamma_v$ that is close to $\mathbf{w}$. An efficient way to do this is as follows. Compute the matrix $B_v$ whose column vectors $\mathbf{c_1},\dots, \mathbf{c_{\nu + r}}$ form an LLL-reduced basis for $\Gamma_v$ and write
\[\mathbf{w} = s_1\mathbf{c_1} + \cdots + s_{\nu + r}\mathbf{c}_{\nu + r}, \quad s_i \in \mathbb{R}.\]
In other words, compute $(s_1, \dots, s_{\nu + r})^T = B_v^{-1}\mathbf{w}$. Choose $\mathbf{t} \in \mathbb{Z}^{\nu + r}$ such that $|t_i - s_i| \leq 1$ for all $i$ and $|\mathbf{w} - B_v\mathbf{t}|$ is minimal. Then $B_v\mathbf{t}$ is likely the closes lattice vector to $\mathbf{w}$, so we take $\mathbf{z} = B_v\mathbf{t}$.

\edit{change the vector $\mathbf{r}$ to be negative, maybe for the next part?}

\begin{lemma}
  \label{lem:nonarch1}
  Let $(b_2, \dots, b_{1+\nu+r})$ be any solution of \eqref{eq:EfficientSunit} and set
  \[\mathbf{x} = MA_v(b_2, \dots, b_{\hat{i} - 1}, \lambda, b_{\hat{i}+1}, \dots, b_{1+\nu+r})^T.\]
  If $\ord_{p_v}(\delta_1) = 0,$ $\displaystyle \sum_{i = 1}^{\nu} n_{i}a_{vi} > \frac{1}{p_v-1} - \ord_{p_v}(\delta_2),$ and
\[\sum_{i = 1}^{\nu} n_{i}a_{vi}  \geq \mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}}),\]
  then $\mathbf{x} - \mathbf{z} \in \Gamma_{v}$ and
\[|\mathbf{x} - \mathbf{z}| \leq b\sqrt{b_{\gamma} + r} + |\mathbf{w} - \mathbf{z}|.\]
\end{lemma}

Here, we

\begin{proof}
  We claim $(b_2, \dots, b_{\hat{i} - 1}, \lambda, b_{\hat{i}+1}, \dots, b_{1+\nu+r})^T \in \mathbb{Z}^{\nu + r}$. That is, $\lambda \in \mathbb{Z}$, meaning that $\sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}})$ is divisible by $p_v^{\mu}$, or equivalently,
  \[\ord_{p_v}\left(\sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}})\right) \geq \mu.\]
  Indeed, since
  \[\ord_{p_{v}}\left(\beta_{i}^{\{\mu\}}-\beta_{i}\right) \geq \mu \quad \text { for } i=1, \dots, 1+\nu+r,\]
  by definition, it follows that $\beta_{i}^{\{\mu\}}$ and $\beta_{i}$ share the first $\mu - 1$ terms and thus $\ord_{p_v}(\beta_i) = \ord_{p_v}(\beta_i^{\{\mu\}})$.
  Now, to compute this order, we only need to concern ourselves with the first non-zero term in the series expansion of $\sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}})$. Since $\beta_{i}^{\{\mu\}}$ and $\beta_{i}$ share the first $\mu - 1$ terms, it follows that showing
  \[\ord_{p_v}\left(\sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}})\right) \geq \mu\]
  is equivalent to showing that
  \[\ord_{p_l}(\Lambda_l') \geq \mu.\]
  Of course, this latter inequality is true by Lemma~\ref{lem:lambdap}. Thus $\lambda \in \mathbb{Z}$. It follows that $\mathbf{x} \in \Gamma_v$ and thus $\mathbf{x} - \mathbf{z} \in \Gamma_v$.

  Now,
  \begin{align*}
    \mathbf{x} - \mathbf{w}
    & = MA_v(b_2, \dots, b_{\hat{i} - 1}, \lambda, b_{\hat{i}+1}, \dots, b_{1+\nu+r})^T -
      M(0, \dots 0, -\beta_1^{\{\mu\}},0, \dots, 0)^T \\
    & = M\left(
      \begin{pmatrix}
        1 &		&		&		&		&		&\\
        & \ddots	& 		&		& 0		& 		&\\
        &		& 1		&		&		&		&\\
        \beta_2^{\{\mu\}}& \cdots & \beta_{\hat{i} - 1}^{\{\mu\}} & p_v^{\mu} & \beta_{\hat{i} + 1}^{\{\mu\}}& \cdots &\beta_{1+ \nu+ r}^{\{\mu\}}\\
        & 		& 		& 		& 1		&		&\\
        & 0		& 		& 		&		& \ddots	&\\
        & 		& 		& 		&		& 		& 1\\
      \end{pmatrix}
    \begin{pmatrix}
      b_2 \\ \vdots \\ b_{\hat{i} -1} \\ \lambda \\ b_{\hat{i} +1} \\ \vdots \\ b_{\nu+r+1} \\
    \end{pmatrix}
    -
    \begin{pmatrix}
      0 \\ \vdots \\ 0 \\ -\beta_1^{\{\mu\}} \\ 0 \\ \vdots \\ 0 \\
    \end{pmatrix}
    \right)\\
    & = M\left(
      \begin{pmatrix}
        b_2 \\ \vdots \\ b_{\hat{i} -1} \\ b^* \\ b_{\hat{i} +1} \\ \vdots \\ b_{\nu+r+1} \\
      \end{pmatrix}
    -
    \begin{pmatrix}
      0 \\ \vdots \\ 0 \\ -\beta_1^{\{\mu\}} \\ 0 \\ \vdots \\ 0 \\
    \end{pmatrix}
    \right).
  \end{align*}
  Here,
  \begin{align*}
    b^* & =b_2\beta_2^{\{\mu\}} + \cdots + b_{\hat{i} - 1}\beta_{\hat{i} - 1}^{\{\mu\}} + \lambda
          p_l^{\mu} + b_{\hat{i} + 1}\beta_{\hat{i} + 1}^{\{\mu\}} + \cdots +
          b_{\nu+r+ 1}\beta_{1+\nu+r}^{\{\mu\}}\\
        & = b_2\beta_2^{\{\mu\}} + \cdots + b_{\hat{i} - 1}\beta_{\hat{i} - 1}^{\{\mu\}} +
          p_l^{\mu} \frac{1}{p_v^{\mu}}\sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}}) +
          b_{\hat{i} + 1}\beta_{\hat{i} + 1}^{\{\mu\}} + \cdots +
          b_{\nu+r+ 1}\beta_{1+\nu+r}^{\{\mu\}}\\
        & = b_2\beta_2^{\{\mu\}} + \cdots + b_{\hat{i} - 1}\beta_{\hat{i} - 1}^{\{\mu\}} +
          \sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}}) +
          b_{\hat{i} + 1}\beta_{\hat{i} + 1}^{\{\mu\}} + \cdots +
          b_{\nu+r+ 1}\beta_{1+\nu+r}^{\{\mu\}}\\
        & = b_1(-\beta_1^{\{\mu\}}) + b_{\hat{i}}(-\beta_{\hat{i}}^{\{\mu\}})\\
        & = -\beta_1^{\{\mu\}} + b_{\hat{i}}
  \end{align*}
where the last equality follows from the fact that $b_1 = 1$ and
\[-\beta_i = \frac{\alpha_{\hat{i}}}{\alpha_{\hat{i}}} =1.\]

Thus,
  \begin{align*}
    \mathbf{x} - \mathbf{w}
    & = M\left(
      \begin{pmatrix}
        b_2 \\ \vdots \\ b_{\hat{i} -1} \\ b^* \\ b_{\hat{i} +1} \\ \vdots \\ b_{\nu+r+1} \\
      \end{pmatrix}
    -
    \begin{pmatrix}
      0 \\ \vdots \\ 0 \\ -\beta_1^{\{\mu\}} \\ 0 \\ \vdots \\ 0 \\
    \end{pmatrix}
    \right)\\
    & = M\left(
      \begin{pmatrix}
        b_2 \\ \vdots \\ b_{\hat{i} -1} \\ b_{\hat{i}} -\beta_1^{\{\mu\}} \\ b_{\hat{i} +1} \\ \vdots
        \\ b_{\nu+r+1} \\
      \end{pmatrix}
    -
    \begin{pmatrix}
      0 \\ \vdots \\ 0 \\ -\beta_1^{\{\mu\}} \\ 0 \\ \vdots \\ 0 \\
    \end{pmatrix}
    \right)\\
    & = M \begin{pmatrix}
      b_2 \\ \vdots \\ b_{\hat{i} -1} \\ b_{\hat{i}}  \\ b_{\hat{i} +1} \\ \vdots  \\ b_{\nu+r+1} \\
    \end{pmatrix}.
  \end{align*}
  Taking the vector norm, we obtain
  \begin{align*}
    |\mathbf{x} - \mathbf{w}| =
    & |M(b_2, \dots, b_{\nu+r+1})^T| \\
    & = \sqrt{(M(b_2, \dots, b_{\nu+r+1})^T)^TM(b_2, \dots, b_{\nu+r+1})^T}\\
    & = \sqrt{(b_2, \dots, b_{\nu+r+1})M^TM(b_2, \dots, b_{\nu+r+1})^T}\\
    & = \left((b_2, \dots, b_{\nu+r+1})b^2
      \begin{pmatrix}
        A^TD^2A & 0 & \dots & 0 & 0\\
        0 & \frac{1}{b_{\varepsilon_1}} & \dots & 0 & 0\\
        0 & 0  & \frac{1}{b_{\varepsilon_2}} & \dots & 0\\
        \vdots & \vdots &0 &  \ddots & \vdots\\
        0 & 0 & \dots & \dots & \frac{1}{b_{\varepsilon_r}}\\
      \end{pmatrix}(b_2, \dots, b_{\nu+r+1})^T \right)^{1/2}\\
    & = b\sqrt{b_{\gamma} + r}.
  \end{align*}
  Hence the lattice vector $\mathbf{x} - \mathbf{z}$ must satisfy
  \[|\mathbf{x} - \mathbf{z}| = |\mathbf{x} - \mathbf{w}| + |\mathbf{w} - \mathbf{z}|
    \leq b\sqrt{b_{\gamma}+r} + |\mathbf{w} - \mathbf{z}| .\]
\end{proof}

\edit{need a consistent way to refer to $h_v$, equivalently $h_{p_v}$}

\textbf{Remark.} We claim that
\begin{align*} \ord_{p_v}(\delta_1) = 0 \quad \text{ and } &  \quad \displaystyle \sum_{i = 1}^{\nu} n_{i}a_{vi} > \frac{1}{p_v-1} - \ord_{p_v}(\delta_2)  \\
&  \iff \sum_{i = 1}^{\nu} n_{i}a_{vi} > \max\left\{\frac{1}{p_v-1},\ord_{p_v}(\delta_1)\right\} - \ord_{p_v}(\delta_2).
\end{align*}
\begin{proof}
  Indeed if
  \[\ord_{p_v}(\delta_1) = 0 \quad \text{ and } \quad \displaystyle \sum_{i = 1}^{\nu} n_{i}a_{vi}
    > \frac{1}{p_v-1} - \ord_{p_v}(\delta_2),\]
  then $\max\left\{\frac{1}{p_v-1},\ord_{p_v}(\delta_1)\right\} = \frac{1}{p-1} > 0$ so
  \begin{align*}
    \sum_{i = 1}^{\nu} n_{i}a_{vi}
    & > \frac{1}{p_v-1} - \ord_{p_v}(\delta_2)\\
    & = \max\left\{\frac{1}{p_v-1},\ord_{p_v}(\delta_1)\right\} - \ord_{p_v}(\delta_2).
  \end{align*}

  Conversely, suppose
  \[\sum_{i = 1}^{\nu} n_{i}a_{vi} > \max\left\{\frac{1}{p_v-1},\ord_{p_v}(\delta_1)\right\} - \ord_{p_v}(\delta_2).\]
  If $\ord_{p_v}(\delta_1) = 0$, we obtain the desired result trivially. If $\ord_{p_v}(\delta_1) \neq 0$, we instead obtain that
  \[\sum_{i = 1}^{\nu} n_{i}a_{vi} + \ord_{p_v}(\delta_2) = \min\{\ord_{p_v}(\delta_1),0\}.\]
  If $\ord_{p_v}(\delta_1) < 0$, then
  \[\max\left\{\frac{1}{p_v-1},\ord_{p_v}(\delta_1)\right\} = \frac{1}{p_v-1} > 0 \]
  so that
  \begin{align*}
    \sum_{i = 1}^{\nu} n_{i}a_{vi}
    & > \max\left\{\frac{1}{p_v-1},\ord_{p_v}(\delta_1)\right\} - \ord_{p_v}(\delta_2)\\
    & = \frac{1}{p_v-1} - \ord_{p_v}(\delta_2)
  \end{align*}
  hence
  \[\sum_{i = 1}^{\nu} n_{i}a_{vi} + \ord_{p_v}(\delta_2) = \min\{\ord_{p_v}(\delta_1),0\} = \ord_{p_v}(\delta_1) > \frac{1}{p_v-1},\]
  a contradiction.
  Similarly, if $\ord_{p_v}(\delta_1) > 0$, then
  \[\sum_{i = 1}^{\nu} n_{i}a_{vi} + \ord_{p_v}(\delta_2) = \min\{\ord_{p_v}(\delta_1),0\} = 0.\]
  It follows that
  \[ 0 = \sum_{i = 1}^{\nu} n_{i}a_{vi} + \ord_{p_v}(\delta_2)
    > \max\left\{\frac{1}{p_v-1},\ord_{p_v}(\delta_1)\right\},\]
  a contradiction, as both $\frac{1}{p_v-1},\ord_{p_v}(\delta_1)$ are strictly positive numbers.
  It follows that $\ord_{p_v}(\delta_1) = 0$, completing the proof.
\end{proof}

\begin{corollary} \label{cor:hvequiv}
  Let $(b_2, \dots, b_{1+\nu+r})$ be any solution of \eqref{eq:EfficientSunit} satisfying
  \[h_{p_v}(z) > l_v,\]
  and set
  \[\mathbf{x} = MA_v(b_2, \dots, b_{\hat{i} - 1}, \lambda, b_{\hat{i}+1}, \dots, b_{1+\nu+r})^T.\]
  Then $\mathbf{x} - \mathbf{z} \in \Gamma_{v}$ and
  \[|\mathbf{x} - \mathbf{z}| \leq b\sqrt{b_{\gamma} + r} + |\mathbf{w} - \mathbf{z}|.\]
\end{corollary}

\begin{proof}
  Under the above assumption, $h_{p_v}(z) > l_v$, we prove that
  \[\ord_{p_v}(\delta_1) = 0, \quad \displaystyle \sum_{i = 1}^{\nu} n_{i}a_{vi} > \frac{1}{p_v-1} - \ord_{p_v}(\delta_2),\]
  and
  \[\sum_{i = 1}^{\nu} n_{i}a_{vi}  \geq \mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}}).\]
  Then the result follows from Lemma~\ref{lem:nonarch1}.

  Recall that $l_v$ is an integer such that
  \[\frac{l_v}{\log(p_v)} \geq \max\left(0,\max\left( \frac{1}{p_v-1}, \ord_{p_v}(\delta_1)\right) - \ord_{p_v}(\delta_2)\right).\]
  That is
  \[l_v\geq \max\left(0,\log(p_v)\left(\max\left\{ \frac{1}{p_v-1}, \ord_{p_v}(\delta_1)\right\}
        - \ord_{p_v}(\delta_2)\right)\right),\]
  so that $l_v \geq 0$ and
  \[l_v > \log(p_v)\left(\max\left\{ \frac{1}{p_v-1}, \ord_{p_v}(\delta_1)\right\} -
      \ord_{p_v}(\delta_2)\right).\]
  Now, by assumption, we have
  \[h_{p_v}(z) > l_v > \log(p_v)\left(\max\left\{ \frac{1}{p_v-1}, \ord_{p_v}(\delta_1)\right\} -
      \ord_{p_v}(\delta_2)\right),\]

Recall from Proposition~\ref{prop:heightdecomp} that
\[h_{p_v}(z) =
\begin{cases}
\log(p_v)|u_v - r_v| \\
0
\end{cases}.\]
Since $h_{p_v}(z) > l_v > 0$, it follows that $h_{p_v}(z) = \log(p_v)|u_v - r_v|$. Hence the assumption becomes
\[\log(p_v)|u_v - r_v| = h_{p_v}(z) > \log p_v\left(\max\left(\tfrac{1}{p_v-1},\ord_{p_v}(\delta_1)\right)-\ord_{p_v}(\delta_2)\right),\]
or equivalently,
\[\left|\sum_{j = 1}^{\nu}n_ja_{vj}\right| > \max\left(\tfrac{1}{p_v-1},\ord_{p_v}(\delta_1)\right)-\ord_{p_v}(\delta_2),\]
that is
\[\sum_{j = 1}^{\nu}n_ja_{vj} > \left(\max\left(\tfrac{1}{p_v-1},\ord_{p_v}(\delta_1)\right)-\ord_{p_v}(\delta_2)\right).\]
\edit{This part doesn't make sense if $\left|\sum_{j = 1}^{\nu}n_ja_{vj}\right|$ is negative. We'll have to force the vector $\mathbf{r}$ to be negative so that we force this absolute value to be positive. What else would change though? Does this mean anything if $\ord_{p_v}(\delta_1) \neq 0$, ie how do we end up with a positive value?}

By the previous Remark, this means that
$\ord_{p_v}(\delta_1) = 0$ and $\displaystyle \sum_{i = 1}^{\nu} n_{i}a_{vi} > \frac{1}{p_v-1} - \ord_{p_v}(\delta_2)$.
It remains to prove that
\[\sum_{i = 1}^{\nu} n_{i}a_{vi}  \geq \mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}}).\]
Recall that $\mu$ is the largest element of $\mathbb{Z}_{\geq 0}$ at most
\[\mu \leq \frac{l_v}{\log(p_v)} - \ord_{p_v}(\alpha_{\hat{i}}) + \ord_{p_v}(\delta_2).\]
That is
\[\frac{l_v}{\log(p_v)} \geq \mu + \ord_{p_v}(\alpha_{\hat{i}}) - \ord_{p_v}(\delta_2)\]
so that
\[h_v(z) > l_v \geq \log(p_v)\left(\mu + \ord_{p_l}(\alpha_{\hat{i}}) - \ord_{p_v}(\delta_2)\right).\]
Equivalently,
\[\log(p_v)|u_v - r_v| = h_{p_v}(z) > \log(p_v)\left(\mu + \ord_{p_l}(\alpha_{\hat{i}}) - \ord_{p_v}(\delta_2)\right)\]
and thus
\[\left|\sum_{j = 1}^{\nu}n_ja_{vj}\right| > \mu - \ord_{p_v}(\delta_2) +
  \ord_{p_l}(\alpha_{\hat{i}})\]
from which we obtain \edit{again, how do we obtain this without assuming that this is always positive? This needs to be fixed here}
\[\sum_{j = 1}^{\nu}n_ja_{vj} > \mu - \ord_{p_v}(\delta_2) + \ord_{p_l}(\alpha_{\hat{i}}),\]
as desired. It follows from Lemma~\ref{lem:mainnonarch} that $\mathbf{x} - \mathbf{z} \in \Gamma_{v}$ and
\[|\mathbf{x} - \mathbf{z}| \leq b\sqrt{b_{\gamma} + r} + |\mathbf{w} - \mathbf{z}|,\]
completing the proof.
\end{proof}

We are now in position to state the main result of this section. Let $\mathbf{l},\mathbf{h} \in \mathbb{Z}^{\nu+r}$ be vectors such that $\mathbf{0} \leq \mathbf{l} \leq \mathbf{h}$, with
\[\frac{l_v}{\log(p_v)} \geq \max\left(0,\max\left( \frac{1}{p_v-1}, \ord_{p_v}(\delta_1)\right)
    - \ord_{p_v}(\delta_2)\right).\]
\begin{corollary}
  Let $p_v \in S$ and $(\tilde{x},\tilde{y}) \in \Sigma_v(\mathbf{l},\mathbf{h})$. Set $\mathbf{z},\mathbf{w}$ as above and
  \[\mathbf{x} = MA_v(b_2, \dots, b_{\hat{i} - 1}, \lambda, b_{\hat{i}+1}, \dots, b_{1+\nu+r})^T,\]
  where $(b_2,\dots, b_{1+\nu+r}\}$ corresponds $(\tilde{x},\tilde{y})$ which satisfy \eqref{eq:TrueSunit} and
  \[\lambda = \frac{1}{p_v^{\mu}}\sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}}).\]
  Then $\mathbf{x} - \mathbf{z} \in \Gamma_{v}$ and
  \[|\mathbf{x} - \mathbf{z}| \leq b\sqrt{b_{\gamma} + r} + |\mathbf{w} - \mathbf{z}|.\]
\end{corollary}

\begin{proof}
  Let $(\tilde{x},\tilde{y}) \in \Sigma_v(\mathbf{l},\mathbf{h})$ and let $(b_1, \dots, b_{1+\nu+r})$ be a solution of \eqref{eq:EfficientSunit} corresponding to $(\tilde{x},\tilde{y})$.
  By definition of $\Sigma_v(\mathbf{l},\mathbf{h})$, we have that $(h_w(z)) \leq \mathbf{h}$ and $h_v(z) > l_v$. The result now follows from the previous corollary.
\end{proof}

The above result tells us that all solutions in $\Sigma_v(\mathbf{l},\mathbf{h})$ satisfy
\[|\mathbf{x} - \mathbf{z}| \leq b\sqrt{b_{\gamma} + r} + |\mathbf{w} - \mathbf{z}|.\]
We use Fincke-Pohst to find all vectors $\mathbf{u}\in \Gamma_v$ such that
\[\mathbf{u} \leq b\sqrt{b_{\gamma} + r} + |\mathbf{w} - \mathbf{z}|.\]
Each $\mathbf{u}$ is a candidate for $\mathbf{u} = \mathbf{x} - \mathbf{z}$. This assumption lets us write $\mathbf{x} - \mathbf{w} = \mathbf{u} + \mathbf{z} - \mathbf{w}$, and since we explicitly know $\mathbf{w}, \mathbf{u},$ and $\mathbf{z}$, we can recover our solution $(b_2, \dots, b_{1+\nu+r})$ via
\[(b_1,\dots, b_{1+\nu+r})^T = M^{-1}(\mathbf{x} - \mathbf{w}) = M^{-1}(\mathbf{u} + \mathbf{z} - \mathbf{w}).\]

\edit{Add p67-68}.




% Let $v \in \{1, \dots, \nu\}$. We take vectors $\mathbf{l},\mathbf{h} \in \mathbb{R}^{\nu+r}$ with $\mathbf{0} \leq \mathbf{l} \leq \mathbf{h}$ and
% \[\frac{l_v}{\log(p)} \geq \max\left( \frac{1}{p-1}, \ord_{p_v}(\delta_1)\right) - \ord_{p_v}(\delta_2)\]
% and then consider the translated lattice $\Gamma_v \subseteq \mathbb{Z}^{\nu + r}$ defined below.


% We say that ${\mathbf{m} = (n_1, \dots, n_{\nu}, a_1, \dots, a_r) \in \mathbb{R}^{r + \nu}}$ is determined by some $\mathbf{y} \in \Gamma_v$ if the entries of $\mathbf{y}$ are a (fixed) permutation of the entries of $\mathbf{m}$. Let $\mathcal{E}_v$ be the ellipsoid constructed in \eqref{def:ellp}.

% \begin{lemma} \label{lem:mainnonarch}
% Any $(\tilde{x},\tilde{y}) \in \Sigma_v(l,h)$ is determined by some $\mathbf{y} \in \Gamma_v \cap \mathcal{E}_v$.
% \end{lemma}

% In the remainder of this section, we prove this lemma.

% % We begin by applying the results of \autoref{sec:SmallBoundForSpecialCase}. In particular, we consider the form
% % \[\Lambda_v = \sum_{i = 1}^{1+\nu+r} b_i\alpha_i\]
% % where
% % \[b_1 = 1, \quad b_{1+i} = n_i \ \text{ for } i \in \{1, \dots, \nu\},\]
% % \[ b_{1 + \nu+i} = a_i \ \text{ for } i \in \{1, \dots, r\},\]
% % and
% % \[\alpha_1 = \log_{p_l} \delta_1, \quad \alpha_{1+i} = \log_{p_l}\left( \frac{\gamma_i^{(k)}}{\gamma_i^{(l)}}\right)  \ \text{ for } i \in \{1, \dots, \nu\},\]
% % \[\alpha_{1+ \nu+i} = \log_{p_l}\left( \frac{\varepsilon_i^{(k)}}{\varepsilon_i^{(l)}}\right)
% % \ \text{ for } i \in \{1, \dots, r\}.\]

% % We apply Lemma~\ref{lem:Delta1} by which $\sum_{j = 1}^{\nu} n_ja_{vj}$ can be computed directly provided ${\ord_{p_v}(\delta_1) \neq 0}$. In doing so, we assume for the remainder of this chapter that $\ord_{p_v}(\delta_1) = 0$. Furthermore, we apply Lemma~\ref{Lem:specialcase} to obtain a small bound on $\sum_{j = 1}^{\nu} n_ja_{vj}$ when $\ord_{p_v}(\alpha_1) < \displaystyle \min_{2 \leq i \leq 1+\nu+r} \ord_{p_v}(\alpha_i)$. Again, in doing so, we assume
% % \[\ord_{p_v}(\alpha_1) \geq \displaystyle \min_{2 \leq i \leq 1+\nu+r} \ord_{p_v}(\alpha_i)\]
% for the remainder of this chapter.

% We now set some notation and give some preliminaries for the $p_l$-adic reduction procedures. Let $I$ be the set of all indices $i' \in \{2, \dots, 1+ \nu + r\}$ for which
% \[\ord_{p_v}(\alpha_{i'}) = \min_{2\leq i\leq 1+ \nu+ r} \ord_{p_v}(\alpha_i).\]
% Following \cite{Ham}, we are always in the case where there exists an index $i' \in I$ such that $\alpha_i/\alpha_{i'} \in \mathbb{Q}_{p_l}$ for $i = 1, \dots, 1+ \nu+ r$. Thus, let $\hat{i}$ denote this index. We define
% \[\beta_i = - \frac{\alpha_i}{\alpha_{\hat{i}}} \quad i = 1, \dots, 1+ \nu+ r,\]
% and
% \[\Lambda'_v = \frac{1}{\alpha_{\hat{i}}}\Lambda_v = \sum_{i = 1}^{1+ \nu+ r} b_i(-\beta_i).\]
% Now, we have $\beta_i \in \mathbb{Z}_{p_v}$ for $i = 1, \dots, 1+ \nu+ r$.

% \begin{lemma} \label{Lem:19.1}
% Suppose $\ord_{p_v}(\delta_1) = 0$ and
% \[\sum_{i = 1}^v n_{i}a_{li} > \frac{1}{p_v-1} - \ord_{p_v}(\delta_2).\]
% Then
% \[\ord_{p_v}(\Lambda_v') = \sum_{i = 1}^v n_{i}a_{li} + \ord_{p_l}(\delta_2) - \ord_{p_l}(\alpha_{\hat{i}}).\]
% \end{lemma}

% \begin{proof}
% Immediate from Lemma \ref{lem:DiscG} and Lemma \ref{lem:Lambda}.
% \end{proof}

% We now describe the $p_v$-adic reduction procedure. Recall that $l_v$ is a constant such that
% \[\frac{l_v}{\log(p)} \geq \max\left( \frac{1}{p_v-1}, \ord_{p_v}(\delta_1)\right) - \ord_{p_v}(\delta_2).\]
% Now, let $\mu$ be the largest element of $\mathbb{Z}_{\geq 0}$ at most
% \[\mu \leq \frac{l_v}{\log(p)} - \ord_{p_l}(\alpha_{\hat{i}}) + \ord_{p_l}(\delta_2).\]

% For each $x \in \mathbb{Z}_{p_l}$, let $x^{\{\mu\}}$ denote the unique rational integer in $[0,p_l^{\mu} - 1]$ such that $\ord_{p_l}(x - x^{\mu}) \geq \mu$ (ie. $x \equiv x^{\{\mu\}} \pmod{p_l^{\mu}}$).

% Let $\Gamma_{v}$ be the $(\nu+r)$-dimensional lattice determined by $A_{v}\mathbf{x} + \mathbf{w}$, where $A_{v}$ is the diagonal matrix having $\hat{i}^{\text{th}}$ row
% \[\left(\beta_2^{\{\mu\}}, \cdots, \beta_{\hat{i} - 1}^{\{\mu\}}, p_l^{\mu}, \beta_{\hat{i} + 1}^{\{\mu\}}, \cdots, \beta_{1+ \nu+ r}^{\{\mu\}}\right) \in \mathbb{Z}^{\nu+r}.\]
% Here, $p_l^{\mu}$ is the $(\hat{i},\hat{i})$ entry of $A_{v}$. That is,
% \[A_{v} =
% \begin{pmatrix}
% 1	& 		&		&		&		&		&	\\
% 	& \ddots	& 		&		& 0		& 		&	\\
% 	&		& 1		&		&		&		&	\\
% 	\beta_2^{\{\mu\}}& \cdots & \beta_{\hat{i} - 1}^{\{\mu\}} & p_l^{\mu} & \beta_{\hat{i} + 1}^{\{\mu\}}& \cdots &\beta_{1+ \nu+ r}^{\{\mu\}}\\
% 	& 		& 		& 		& 1		&		&	\\
% 	& 0		& 		& 		&		& \ddots	&	\\
% 	& 		& 		& 		&		& 		& 1	\\
% \end{pmatrix}.\]
% Additionally, $\mathbf{w}$ is the vector whose only non-zero entry is the $\hat{i}^{\text{th}}$ element, $ \beta_1^{\{\mu\}}$,
% \[\mathbf{w} = (0, \dots 0, \beta_1^{\{\mu\}},0, \dots, 0)^T \in \mathbb{Z}^{\nu + r}.\]

%Of course, we must compute the $\beta_i$ to $p_l$-adic precision at least $\mu$ in order to avoid errors here.
% Let $\mathbf{y} = (n_1, \dots, n_{\nu}, a_1, \dots, a_r) \in \mathbb{R}^{\nu + r}$ denote a solution to \eqref{eq:EfficientSunit}.

% \begin{lemma}
% Suppose $\ord_{p_v}(\delta_1) = 0$ and
% \[\sum_{i = 1}^{\nu} n_{i}a_{vi} > \frac{1}{p_v-1} - \ord_{p_v}(\delta_2).\]
% Then the following equivalence holds:
% \begin{align*}
% \sum_{i = 1}^{\nu} n_{i}a_{vi}  \geq \mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}})
% 	& \quad \text{ if and only if } \quad \ord_{p_v}(\Lambda_v') \geq \mu \\
% 	& \quad \text{ if and only if } \quad \mathbf{y} \in\Gamma_v.
% \end{align*}
% \end{lemma}

% \begin{proof}
% By Lemma \ref{Lem:19.1}, the assumption means that
% \[\ord_{p_v}(\Lambda_v') = \sum_{i = 1}^{\nu} n_{i}a_{vi} + \ord_{p_v}(\delta_2) - \ord_{p_v}(\alpha_{\hat{i}}).\]

% Now, suppose
% \[\sum_{i = 1}^{\nu} n_{i}a_{vi}  \geq \mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}}).\]
% We thus have
% \begin{align*}
% \ord_{p_v}(\Lambda_v')
% 	& = \sum_{i = 1}^{\nu} n_{i}a_{vi} + \ord_{p_v}(\delta_2) - \ord_{p_v}(\alpha_{\hat{i}})\\
% 	& \geq  \mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}}) + \ord_{p_v}(\delta_2) - \ord_{p_v}(\alpha_{\hat{i}})\\
% 	& = \mu.
% \end{align*}
% Conversely, suppose $\ord_{p_v}(\Lambda_v') \geq \mu$. Then
% \[\mu \leq \ord_{p_v}(\Lambda_v') = \sum_{i = 1}^{\nu} n_{i}a_{vi} + \ord_{p_v}(\delta_2) - \ord_{p_v}(\alpha_{\hat{i}}).\]
% That is,
% \[\sum_{i = 1}^{\nu} n_{i}a_{vi} \geq \mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}}).\]
% Hence, it follows that $\displaystyle \sum_{i = 1}^{\nu} n_{i}a_{vi} \geq \mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}})$ if and only if $\ord_{p_v}(\Lambda_v') \geq \mu$.

% Now, suppose $\mathbf{y}= (n_1, \dots, n_{\nu}, a_1, \dots, a_r) \in \mathbb{R}^{\nu + r}$ is a solution to \eqref{eq:EfficientSunit}. Suppose further that $\displaystyle \sum_{i = 1}^{\nu} n_{i}a_{vi} \geq \mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}})$ so that $\ord_{p_v}(\Lambda_v') \geq \mu$. Let
% \[\lambda = \frac{1}{p_v^{\mu}}\sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}})\]
% and consider the $(\nu + r)$-dimensional vector
% \[\mathbf{x}= (n_1, \dots, n_{\hat{i} -1}, \lambda, n_{\hat{i} +1}, \dots, n_{\nu}, a_1, \dots, a_r).\]
% We claim $\mathbf{x} \in \mathbb{Z}^{\nu + r}$. That is, $\lambda \in \mathbb{Z}$, meaning that $\sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}})$ is divisible by $p_v^{\mu}$, or equivalently,
% \[\ord_{p_v}\left(\sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}})\right) \geq \mu.\]
% Indeed, since
% \[\ord_{p_{v}}\left(\beta_{i}^{\{\mu\}}-\beta_{i}\right) \geq \mu \quad \text { for } i=1, \dots, 1+\nu+r,\]
% by definition, it follows that $\beta_{i}^{\{\mu\}}$ and $\beta_{i}$ share the first $\mu - 1$ terms and thus $\ord_{p_v}(\beta_i) = \ord_{p_v}(\beta_i^{\{\mu\}})$.
% Now, to compute this order, we only need to concern ourselves with the first non-zero term in the series expansion of $\sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}})$. Since $\beta_{i}^{\{\mu\}}$ and $\beta_{i}$ share the first $\mu - 1$ terms, it follows that showing
% \[\ord_{p_v}\left(\sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}})\right) \geq \mu\]
% is equivalent to showing that
% \[\ord_{p_l}(\Lambda_l') \geq \mu.\]
% Of course, this latter inequality is true by assumption. Thus $\lambda \in \mathbb{Z}$.

% Then, computing $A_{v}\mathbf{x} + \mathbf{w}$ yields
% \begin{align*}
%  A_{v}\mathbf{x} + \mathbf{w} &
% & = \begin{pmatrix}
% b_2 \\ \vdots \\ b_{\hat{i} -1} \\
%  b^* \\
% b_{\hat{i} +1} \\ \vdots \\ b_{\nu+r+1} \\
% \end{pmatrix},
% \end{align*}
% where
% \[b^* =b_2\beta_2^{\{\mu\}} + \cdots + b_{\hat{i} - 1}\beta_{\hat{i} - 1}^{\{\mu\}} + \lambda p_l^{\mu} + b_{\hat{i} + 1}\beta_{\hat{i} + 1}^{\{\mu\}} + \cdots + b_{\nu+r+ 1}\beta_{1+\nu+r}^{\{\mu\}} + \beta_1^{\{\mu\}}.\]
% Now,
% \[ \lambda p_v^{\mu} = p_v^{\mu}\frac{1}{p_v^{\mu}}\sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}}) = \sum_{i = 1}^{\nu + r + 1}b_i(-\beta_i^{\{\mu\}}),\]
% hence
% \begin{align*}
% & b_2\beta_2^{\{\mu\}} + \cdots + b_{\hat{i} - 1}\beta_{\hat{i} - 1}^{\{\mu\}} + b_{\hat{i} + 1}\beta_{\hat{i} + 1}^{\{\mu\}} + \cdots + b_{\nu+r+ 1}\beta_{1+\nu+r}^{\{\mu\}} + \lambda p_l^{\mu} + \beta_1^{\{\mu\}}\\
% & = b_{\hat{i}}(-\beta_{\hat{i}}^{\{\mu\}})\\
% & = b_{\hat{i}}
% \end{align*}
% where the last equality follows from the fact that
% \[-\beta_i = \frac{\alpha_{\hat{i}}}{\alpha_{\hat{i}}} =1.\]
% Thus,
% \[A_{v}\mathbf{x} + \mathbf{w} = \begin{pmatrix}
% b_2 \\ \vdots \\ b_{\hat{i} -1} \\ b_{\hat{i}} \\ b_{\hat{i} +1} \\ \vdots \\ b_{\nu+r+1}
% \end{pmatrix} =
% \begin{pmatrix}
% n_1 \\ \vdots \\ n_{\nu} \\ a_1 \\ \vdots \\ a_r \end{pmatrix} = \mathbf{y}.\]
% and $\mathbf{y} \in \Gamma_v$.

%Our assumption gives $n_p-a_p\geq \max(0,\ord_p(\mu_0))-\ord_p(\lambda_0)$ and then Lemma~\ref{lem:padiccomp} implies that $\ord_p(\mu_0)=0$. Therefore, on using again our assumption which assures that $n_p-a_p> \tfrac{1}{p-1}-\ord_p(\lambda_0)$, we see that an application of Lemma~\ref{lem:padiccomp}  gives  $$(n_p-a_p)+\ord_p(\lambda_0)=\ord_p(\Lambda_p)=\ord_p(\Lambda'_p)+\ord_p(\xi_p).$$
%Thus $n_p-a_p\geq l_v'-\ord_p(\xi_p/\lambda_0)$ if and only if $\ord_p(\Lambda'_p)\geq l_v'$. Further, the TdW arguments show that $\ord_p(\Lambda'_p)\geq l_v'$ if and only if $m'\in\Gamma_v$. On combining we deduce the lemma.
%\end{proof}


%
%
%
%
%
%
%
%
%
%
%
%Put
%\[Q = \sum_{i = 2}^{v+2} W_i^2 B_i^2.\]
%
%\begin{lem} \label{lem:LLL}
%If $\ell(\Gamma_{\mu},\mathbf{y}) > Q^{1/2}$ then
%\[\sum_{i = 1}^v n_{i}a_{li} \leq \max\left\{ \frac{1}{p_l-1} - \ord_{p_l}(\delta_2), \mu - d_l - 1,0\right\}\]
%\end{lem}
%
%\begin{proof}
%We prove the contrapositive. Assume
%\[\sum_{i = 1}^v n_{i}a_{li} > \frac{1}{p_l-1} - \ord_{p_l}(\delta_2), \quad \sum_{i = 1}^v n_{i}a_{li} > \mu - d_l
%\quad \text{ and } \quad \sum_{i = 1}^v n_{i}a_{li} > 0.\]
%Consider the vector
%\[\mathbf{x} = A_{\mu}
%\begin{pmatrix}
%b_2\\
%\vdots\\
%b_{\hat{i}-1}\\
%b_{\hat{i}+1}\\
%\vdots\\
%b_{v+2}\\
%\lambda
%\end{pmatrix}
%=
%\begin{pmatrix}
%W_2b_2\\
%\vdots\\
%W_{\hat{i}-1}b_{\hat{i}-1}\\
%W_{\hat{i}+1}b_{\hat{i}+1}\\
%\vdots\\
%W_{v+2}b_{v+2}\\
%-W_{\hat{i}}b_{\hat{i}}
%\end{pmatrix}
%+ \mathbf{y}.\]
%By Lemma~\ref{Lem:19.1},
%\[\ord_{p_l}\left( \sum_{i=1}^{v+2}b_i(-\beta_i)\right) = \ord_{p_l}(\Lambda_l') \geq\sum_{i = 1}^v n_{i}a_{li} + d_l \geq \mu.\]
%Since $\ord_{p_l}(\beta_i^{\{\mu\}} - \beta_i) \geq \mu$ for $i = 1, \dots, v+2$, it follows that
%\[\ord_{p_l}\left( \sum_{i=1}^{v+2}b_i(-\beta_i^{\{\mu\}})\right) \geq \mu,\]
%so that $\lambda \in \mathbb{Z}$. Hence $\mathbf{x} \in \Gamma_{\mu}$. Now $\sum_{i = 1}^v n_{i}a_{li} > 0$ so that there exists some $i$ such that $n_ia_{li} \neq 0$, and in particular, $b_{1+i} = n_i \neq 0$. Thus we cannot have $\mathbf{x} = \mathbf{y}$. Therefore,
%\[\ell(\Gamma_{\mu}, \mathbf{y})^2 \leq |\mathbf{x} - \mathbf{y}|^2 = \sum_{i = 2}^{v+2}W_i^2 b_i^2
%\leq  \sum_{i = 2}^{v+2}W_i^2 |b_i|^2 \leq  \sum_{i = 2}^{v+2}W_i^2 B_i^2 = Q.\]
%\end{proof}

%The reduction procedure works as follows. Taking $A_{\mu}$ as input, we first compute an LLL-reduced basis for $\Gamma_{\mu}$. Then, we find a lower bound for $\ell(\Gamma_{\mu}, \mathbf{y})$. If the lower bound is not greater than $Q^{1/2}$ so that Lemma \ref{lem:LLL} does not give a new upper bound, we increase $\mu$ and try the procedure again. If we find that several increases of $\mu$ have failed to yield a new upper bound $N_l$ and that the value of $\mu$ has become significantly larger than it was initially, we move onto the next $l \in \{1, \dots, v\}$.
%
%If the lower bound is greater than $Q^{1/2}$, Lemma \ref{lem:LLL} gives a new upper bound $N_l$ for $\sum_{i = 1}^v n_{i}a_{li}$ and hence for $m$
%\[m = \frac{\sum_{j = 1}^{v}n_ja_{lj} + r_l + t_l}{\alpha_l} < \frac{N_l+ r_l + t_l}{\alpha_l} = M.\]
%If $M < 3000$, we exit the algorithm and enter the brute force search. Otherwise, we update the bounds $N_1, \dots, N_{l-1}, N_{l+1}, \dots, N_v$ via
%\[\sum_{j=1}^v n_ja_{ij} = m\alpha_i - r_i - t_i \leq M\alpha_i - r_i - t_i = N_i.\]
%Then using
%\[|n_l| \leq \max_{1 \leq i \leq v}|n_i| \leq ||A^{-1}||_{\infty}\max_{1 \leq i\leq v}\sum_{j = 1}^v n_j a_{ij}
%\leq ||A^{-1}||_{\infty} \max_{1 \leq i\leq v}(N_i) = B_{l+1}.\]
%we update the $B_i$ and repeat the above procedure until $M < 3000$ or until no further improvement can be made on the $B_i$, in which case we move onto the next $l \in \{1, \dots, v\}$.

% Define
% \[c_{p_v}=\log p_v\left(\max\left(\tfrac{1}{p_v-1},\ord_{p_v}(\delta_1)\right)-\ord_{p_v}(\delta_2)\right).\]

% \begin{corollary} \label{lem:cpequiv}
% Assume that $h_{p_v}(z)>\max(0,c_{p_v})$. Then the following equivalence holds:
% \[h_{p_v}(z)\geq \log{p_v}\left(\mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}})\right) \quad \text{ if and only if } \quad \mathbf{y} \in\Gamma_v.\]
% \end{corollary}
% \begin{proof}
% Recall from Proposition~\ref{prop:heightdecomp} that
% \[h_{p_v}(z) =
% \begin{cases}
% \log(p_v)|u_v - r_v| \\
% 0
% \end{cases}.\]
% Since $h_{p_v}(z) > 0$, it follows that $h_{p_v}(z) = \log(p_v)|u_v - r_v|$. Hence the assumption becomes
% \[\log(p_v)|u_v - r_v| = h_{p_v}(z) > \log p_v\left(\max\left(\tfrac{1}{p_v-1},\ord_{p_v}(\delta_1)\right)-\ord_{p_v}(\delta_2)\right),\]
% or equivalently,
% \[\sum_{j = 1}^{\nu}n_ja_{vj} > \left(\max\left(\tfrac{1}{p_v-1},\ord_{p_v}(\delta_1)\right)-\ord_{p_v}(\delta_2)\right).\]
% Moreover, the conclusion is equivalent to
% \[\log(p_v)|u_v - r_v| \geq \log{p_v}\left(\mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}})\right)
% 	\quad \text{ if and only if } \quad \mathbf{y} \in\Gamma_v,\]
% or,
% \[\sum_{j = 1}^{\nu}n_ja_{vj} \geq \left(\mu - \ord_{p_v}(\delta_2) + \ord_{p_v}(\alpha_{\hat{i}})\right)
% 	\quad \text{ if and only if } \quad \mathbf{y} \in\Gamma_v,\]
% which is the previous lemma.

% %This follows from the above lemma, since Proposition~\ref{prop:heightdecomp} together with $h_p(z)>0$ implies that $h_p(z)=\log p(n_p-a_p)$.
% \end{proof}

% We now prove Lemma~\ref{lem:mainnonarch}.

% \begin{proof}[Proof of Lemma~\ref{lem:mainnonarch}]
% If $(n_1, \dots, n_{\nu}, a_1, \dots, a_r) \in \mathbb{R}^{r+\nu}$ is a solution of \eqref{eq:EfficientSunit}, then, by definition, it corresponds to a solution $(\tilde{x},\tilde{y}) \in \Sigma_v(\mathbf{l},\mathbf{h})$.
% Hence $h_v(z)>l_v$, where $l_v$ is a constant such that
% \[\frac{l_v}{\log(p_v)} \geq \max\left( \frac{1}{p_v-1}, \ord_{p_v}(\delta_1)\right) - \ord_{p_v}(\delta_2).\]
% That is,
% \[h_v(z) > l_v \geq \log(p_v)\left(\max\left( \frac{1}{p_v-1}, \ord_{p_v}(\delta_1)\right) - \ord_{p_v}(\delta_2)\right) = c_p.\]
% Now, recall that $\mathbf{l} \geq \mathbf{0}$ so that $l_v \geq 0$. It thus follows that
% \[h_v(z) > l_v \geq
% \begin{cases}
% 0\\
% c_p
% \end{cases}
% \implies h_v(z) >\max(0,c_p).\]
% In other words, the conditions of Corollary~\ref{lem:cpequiv} are satisfied.

% Now, recall that $\mu$ is the largest element of $\mathbb{Z}_{\geq 0}$ at most
% \[\mu \leq \frac{l_v}{\log(p_v)} - \ord_{p_v}(\alpha_{\hat{i}}) + \ord_{p_v}(\delta_2).\]
% That is
% \[\frac{l_v}{\log(p_v)} \geq \mu + \ord_{p_v}(\alpha_{\hat{i}}) - \ord_{p_v}(\delta_2)\]
% so that
% \[h_v(z) > l_v \geq \log(p_v)\left(\mu + \ord_{p_l}(\alpha_{\hat{i}}) - \ord_{p_v}(\delta_2)\right).\]
% Now, by Corollary~\ref{lem:cpequiv}, we must have $\mathbf{y} \in \Gamma_v$. This shows that $(\tilde{x},\tilde{y})$ is determined by $\mathbf{y}=\mathbf{m}'\in\Gamma_v$, which proves Lemma~\ref{lem:mainnonarch}.
% %
%If $h_v(z)>l_v$ then $h_v(z)>\max(0,c_p)$ since $l\geq 0$ and $l_v\geq c_p$ by assumption. Further, it holds that $l_v/\log p\geq l_v'-v(\xi_p/\lambda_0)$ by the definition of $l_v'$. Hence $h_v(z)\geq \log p(l_v'-v(\xi_p/\lambda_0))$ and then the above corollary implies that $m'\in\Gamma_v$. This shows that $(x,y)$ is determined by $\gamma=m'\in\Gamma_v$, which proves Lemma~\ref{lem:nonarchsieve}.
%\end{proof}

% Finally, suppose that $\mathbf{y}\in \Gamma_v\cap \mathcal E_v$. Let $M=M_v$ be the matrix defining the ellipsoid $\mathcal{E}_v$. That is
% \begin{align*}
% M &=\sqrt{b_{\varepsilon_1}\cdots b_{\varepsilon_r}}\begin{pmatrix}
% 	DA & 0 & \dots & 0 & 0\\
% 	0 & \sqrt{\frac{b}{b_{\varepsilon 1}}} & \dots & 0 & 0\\
% 	0 & 0  & \sqrt{\frac{b}{b_{\varepsilon 2}}} & \dots & 0\\
% 	\vdots & \vdots &0 &  \ddots & \vdots\\
% 	0 & 0 & \dots & \dots & \sqrt{\frac{b}{b_{\varepsilon}}} \\
% 	\end{pmatrix}.
% \end{align*}
% Recall that $A_{v}\mathbf{x} + \mathbf{w}$ defines the lattice $\Gamma_v$. In particular, since $\mathbf{y}\in \Gamma_v\cap \mathcal E_v$, there exists $\mathbf{x}\in \mathbb{R}^{r + \nu}$ such that $\mathbf{y}=A_v \mathbf{x}+\mathbf{w}$ and ${\mathbf{y}^TM^TM\mathbf{y}\leq (1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})}$. We thus have
% \[(A_v \mathbf{x}+\mathbf{w})^TM^TM(A_v \mathbf{x}+\mathbf{w}) \leq (1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r}).\]
% As $A_{v}$ is clearly invertible, with matrix inverse
% \[A_{v}^{-1} = \begin{pmatrix}
% 1	& 		&		&		&		&		&	\\
% 	& \ddots	& 		&		& 0		& 		&	\\
% 	&		& 1		&		&		&		&	\\
% 	-\frac{\beta_2^{\{\mu\}}}{p_l^{\mu}} & \cdots & -\frac{\beta_{\hat{i} - 1}^{\{\mu\}}}{p_l^{\mu}} & \frac{1}{p_l^{\mu}} & -\frac{\beta_{\hat{i} + 1}^{\{\mu\}}}{p_l^{\mu}}& \cdots &-\frac{\beta_{1+ \nu+ r}^{\{\mu\}}}{p_l^{\mu}}\\
% 	& 		& 		& 		& 1		&		&	\\
% 	& 0		& 		& 		&		& \ddots	&	\\
% 	& 		& 		& 		&		& 		& 1	\\
% 	\end{pmatrix},\]
% we can find a vector $\mathbf{c}$ such that $A_{v}\mathbf{c} = -\mathbf{w}$. Indeed, this vector is $\mathbf{c} = A_{v}^{-1}(-\mathbf{w})$, where
% \[\mathbf{c}=\begin{pmatrix}
% 	0 \\ \vdots \\ 0 \\-\frac{\beta_1^{\{\mu\}}}{p^{\{\mu\}}} \\ 0 \\ \vdots \\ 0
% \end{pmatrix}.\]
% Now,
% \begin{align*}
% (1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r})
% 	& \geq (A_v \mathbf{x}+\mathbf{w})^TM^TM(A_v \mathbf{x}+\mathbf{w}) \\
% 	& = (A_v \mathbf{x}-A_v\mathbf{c})^TM^TM(A_v \mathbf{x}-A_v\mathbf{c})\\
% 	& = (\mathbf{x}-\mathbf{c})^T(MA_v)^TMA_v(\mathbf{x}-\mathbf{c})\\
% 	& = (\mathbf{x}-\mathbf{c})^TB^TB(\mathbf{x}-\mathbf{c})
% \end{align*}
% where $B = MA_v$. That is, we are left to solve
% \[(\mathbf{x}-\mathbf{c})^TB^TB(\mathbf{x}-\mathbf{c}) \leq (1 + r)(bb_{\varepsilon_1}\cdots b_{\varepsilon_r}).\]
% As in \autoref{sec:archsieve} finding all vectors satisfying this inequality amounts to computing all solutions to \eqref{eq:EfficientSunit} contained in $\Sigma_{v}(\mathbf{l}, \mathbf{h})$. The set of vectors $\mathbf{x}$ can be found using the Fincke-Pohst algorithm outlined in \autoref{subsec:FinckePohst}.

%---------------------------------------------------------------------------------------------%



\end{document}
